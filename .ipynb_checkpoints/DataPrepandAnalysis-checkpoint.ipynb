{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Basic Text Analysis - Topic Modeling Pt. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1. Zotero API + PDF Text Miner\n",
    "We need this so we don't have to bring down all of the pdfs in our library to our local machines, and we can always run our data prep on the most up-to-date corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import ftfy\n",
    "import nltk.corpus\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoteroCrawler(key, groupid):\n",
    "    multiplier = 0\n",
    "    zoterogroup = []\n",
    "    # get number of items in group\n",
    "    headers = {\"Zotero-API-Version\":\"3\",'Connection':'close', \"Zotero-API-Key\":key}\n",
    "    checkurl = \"https://api.zotero.org/groups/\" +groupid\n",
    "    rcheck = requests.get(checkurl, headers=headers)\n",
    "    items = rcheck.json()['meta']['numItems']\n",
    "    print(items)\n",
    "    pages = math.ceil((items/100))\n",
    "    while pages > 0:\n",
    "        url = \"https://api.zotero.org/groups/\" +groupid + \"/items\" + \"?limit=100&start=\" + str(multiplier)\n",
    "        print(url)\n",
    "        r = requests.get(url, headers=headers)\n",
    "        rj = r.json() #jsonified version of our Zotero group\n",
    "        print(len(rj))\n",
    "        for i in rj:\n",
    "            zoterogroup.append(i)\n",
    "        multiplier = multiplier + 100\n",
    "        pages = pages - 1\n",
    "    return zoterogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"N6yPwqH9VQFt8ZKBKCAFf8KV\"\n",
    "group_id = \"2808857\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=0\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=100\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=200\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=300\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=400\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=500\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=600\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=700\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=800\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=900\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=1000\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=1100\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "rj= zoteroCrawler(api_key, group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)    \n",
    "    file = open(filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# now what? get the attachments\n",
    "# inputs are jsonified version of your zotero group, base url to zotero group items, and api key\n",
    "# going to have to loop through and run this for every page I think\n",
    "def attachmentGrabber(rj, url, key):\n",
    "    counter = 0\n",
    "    to_extract = []\n",
    "    citation_list = []\n",
    "    for i in rj:\n",
    "        if counter < 50:\n",
    "            try:\n",
    "                item_key = rj[counter][\"key\"]\n",
    "                headers = {\"Zotero-API-Version\":\"3\",'Connection':'close', \"Zotero-API-Key\":key}\n",
    "                attach = requests.get(url + item_key + \"/file\", headers=headers)\n",
    "                if \"200\" in str(attach):\n",
    "                    download_file(attach.url, f'Document_{item_key}')\n",
    "                    to_extract.append(f'Document_{item_key}.pdf')\n",
    "                    print(\"GOOD\" + \" 1 \" + str(item_key))\n",
    "                else:\n",
    "                    attach = requests.get(rj[counter]['links']['attachment']['href'] + \"/file\", headers=headers)\n",
    "                    print(attach)\n",
    "                    if \"200\" in str(attach):\n",
    "                        download_file(attach.url, f'Document_{item_key}')\n",
    "                        to_extract.append(f'Document_{item_key}.pdf')\n",
    "                        print(\"GOOD\" + \" \" + str(item_key))\n",
    "                    else:\n",
    "                        print(\"that didn't work\" + \" \" + attach.url)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            counter +=1\n",
    "    return to_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOD 1 47GCMTBN\n",
      "<Response [200]>\n",
      "GOOD 3X676VED\n",
      "GOOD 1 QCQS4ST2\n",
      "<Response [200]>\n",
      "GOOD JBHVWUZE\n",
      "<Response [200]>\n",
      "GOOD JI4B2NX5\n",
      "GOOD 1 P3ZBU43W\n",
      "<Response [200]>\n",
      "GOOD JFQB362K\n",
      "GOOD 1 DUDUGGU3\n",
      "<Response [200]>\n",
      "GOOD TMZ5ADAT\n",
      "GOOD 1 TF4SN283\n",
      "<Response [200]>\n",
      "GOOD RU3DU96U\n",
      "GOOD 1 M22IF67B\n",
      "<Response [200]>\n",
      "GOOD XRPE4C5V\n",
      "GOOD 1 DSCUFYAG\n",
      "<Response [200]>\n",
      "GOOD A72X8Q5P\n",
      "GOOD 1 DHKVRINE\n",
      "<Response [200]>\n",
      "GOOD UW8IXCF9\n",
      "GOOD 1 6ES6XHAP\n",
      "<Response [200]>\n",
      "GOOD KW9E2UTE\n",
      "GOOD 1 MWQEBJBU\n",
      "<Response [200]>\n",
      "GOOD 79SRZNQ3\n",
      "GOOD 1 FPBF5IKX\n",
      "<Response [200]>\n",
      "GOOD J7HBXYBQ\n",
      "GOOD 1 2LRB28HQ\n",
      "GOOD 1 SX39863M\n",
      "<Response [200]>\n",
      "GOOD 9JV4R9EW\n",
      "GOOD 1 Q73YL96D\n",
      "GOOD 1 XVX4XMR2\n",
      "<Response [200]>\n",
      "GOOD PKB9CB7I\n",
      "<Response [200]>\n",
      "GOOD 7TIFU594\n",
      "GOOD 1 TAAJRZEP\n",
      "GOOD 1 RH5JP7XX\n",
      "GOOD 1 LTZN6E4P\n",
      "<Response [200]>\n",
      "GOOD D6YVIFBC\n",
      "GOOD 1 3E578E54\n",
      "GOOD 1 IB7PWZVG\n",
      "GOOD 1 TMFT472T\n",
      "GOOD 1 YJRJLQSA\n",
      "<Response [200]>\n",
      "GOOD UTLT344I\n",
      "<Response [200]>\n",
      "GOOD DMKRZS8E\n",
      "<Response [200]>\n",
      "GOOD ZFPUQZNE\n",
      "<Response [200]>\n",
      "GOOD SYN9YTMS\n",
      "<Response [200]>\n",
      "GOOD G4923VSV\n",
      "<Response [200]>\n",
      "GOOD BTK3PPG8\n",
      "<Response [200]>\n",
      "GOOD EV273D9P\n",
      "<Response [200]>\n",
      "GOOD PDUA89RL\n",
      "<Response [200]>\n",
      "GOOD VZGACXNN\n",
      "<Response [200]>\n",
      "GOOD YGFJAA5F\n",
      "<Response [200]>\n",
      "GOOD KN8U5AXF\n",
      "<Response [200]>\n",
      "GOOD NDH25D7X\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.zotero.org/groups/2808857/items/\"\n",
    "to_extract  = attachmentGrabber(rj, url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('to_extract_backup.txt', 'w') as f:\n",
    " #   f.write(json.dumps(to_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('to_extract_backup.txt', 'r', encoding='utf-8') as f:\n",
    " #   data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_extract = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attachments have been procured. Let's do something with them. Thanks to [PDF Text Miner](https://github.com/prldc/pdf_text_miner) for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def extract_pdfs(list):  # You can easily extract a list from a .csv with pandas.\n",
    "    d = {'file_name': ['dummy'], 'file_text': ['dummy'], 'ocr': [False]}\n",
    "    df = pd.DataFrame(d, columns=['file_name', 'file_text', 'ocr'])\n",
    "    count = 1\n",
    "    for pdf in list:\n",
    "        try:\n",
    "            ext = os.path.splitext(pdf)[1][1:].strip()  # Gets file extension.\n",
    "            if ext == 'pdf':  # Guarantees that the file is a .pdf, otherwise the program will crash when extracting text.\n",
    "                ocr = False\n",
    "                name = pdf.split('.pdf')[0]\n",
    "                doc = fitz.open(f\"{name}.pdf\")\n",
    "                text_file = open(f\"{name}.txt\", 'w')\n",
    "                number_of_pages = doc.page_count\n",
    "                for page_n in range(number_of_pages):  # Extracts text from each page.\n",
    "                    page = doc.load_page(page_n)\n",
    "                    page_content = page.get_text(\"text\")\n",
    "                    text_file.write(page_content)\n",
    "                if os.stat(\n",
    "                        f\"{name}.txt\").st_size < 2000:  # Assumes file lacks OCR based on .txt file size, starts Tesseract.\n",
    "                    ocr = True\n",
    "                    os.remove(f\"{name}.txt\")  # Removes the previously scraped .txt.\n",
    "                    tess_file = f\"{name}.pdf\"\n",
    "                    pages = convert_from_path(tess_file, 500)\n",
    "                    image_counter = 1\n",
    "                    for page in pages:  # Converts the PDF to image.\n",
    "                        filename = f\"{name}page_{str(image_counter)}.jpg\"\n",
    "                        page.save(filename, 'JPEG')\n",
    "                        image_counter = image_counter + 1\n",
    "                    filelimit = image_counter - 1\n",
    "                    outfile = f\"{name}.txt\"\n",
    "                    f = open(outfile, \"a\")\n",
    "                    for i in range(1, filelimit + 1):  # Applies OCR to each image, saves text file.\n",
    "                        filename = f\"{name}page_{str(i)}.jpg\"\n",
    "                        text = str((pytesseract.image_to_string(Image.open(filename), lang=\"por\")))\n",
    "                        text = text.replace('-\\n', '')\n",
    "                        f.write(text)\n",
    "                    f.close()\n",
    "                text = open(f\"{name}.txt\", 'r')\n",
    "                txt = \" \".join(text.readlines())\n",
    "                df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)    \n",
    "                end = datetime.datetime.now()\n",
    "                print(\n",
    "                    f\"Finished {name} at {end}. OCR = {ocr}. {count} files read. {round(count * 100 / len(list), 2)}% done.\")\n",
    "        except Exception as e:\n",
    "            print(f'Did not finish {pdf}... check out that one.')\n",
    "            print(e)\n",
    "        count = count + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_47GCMTBN at 2023-03-11 20:09:55.965608. OCR = False. 1 files read. 2.0% done.\n",
      "Finished Document_3X676VED at 2023-03-11 20:09:56.070147. OCR = False. 2 files read. 4.0% done.\n",
      "Finished Document_QCQS4ST2 at 2023-03-11 20:09:56.152057. OCR = False. 3 files read. 6.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_JBHVWUZE at 2023-03-11 20:09:56.238575. OCR = False. 4 files read. 8.0% done.\n",
      "Finished Document_JI4B2NX5 at 2023-03-11 20:09:56.280914. OCR = False. 5 files read. 10.0% done.\n",
      "Finished Document_P3ZBU43W at 2023-03-11 20:09:56.349306. OCR = False. 6 files read. 12.0% done.\n",
      "Finished Document_JFQB362K at 2023-03-11 20:09:56.412955. OCR = False. 7 files read. 14.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_DUDUGGU3 at 2023-03-11 20:09:56.494918. OCR = False. 8 files read. 16.0% done.\n",
      "Finished Document_TMZ5ADAT at 2023-03-11 20:09:56.575519. OCR = False. 9 files read. 18.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_TF4SN283 at 2023-03-11 20:09:56.715992. OCR = False. 10 files read. 20.0% done.\n",
      "Finished Document_RU3DU96U at 2023-03-11 20:09:56.855343. OCR = False. 11 files read. 22.0% done.\n",
      "Finished Document_M22IF67B at 2023-03-11 20:09:56.914763. OCR = False. 12 files read. 24.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_XRPE4C5V at 2023-03-11 20:09:56.976731. OCR = False. 13 files read. 26.0% done.\n",
      "Finished Document_DSCUFYAG at 2023-03-11 20:09:57.079972. OCR = False. 14 files read. 28.0% done.\n",
      "Finished Document_A72X8Q5P at 2023-03-11 20:09:57.168285. OCR = False. 15 files read. 30.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_DHKVRINE at 2023-03-11 20:09:57.255777. OCR = False. 16 files read. 32.0% done.\n",
      "Finished Document_UW8IXCF9 at 2023-03-11 20:09:57.339895. OCR = False. 17 files read. 34.0% done.\n",
      "Finished Document_6ES6XHAP at 2023-03-11 20:09:57.410901. OCR = False. 18 files read. 36.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_KW9E2UTE at 2023-03-11 20:09:57.495916. OCR = False. 19 files read. 38.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_MWQEBJBU at 2023-03-11 20:09:57.809604. OCR = False. 20 files read. 40.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_79SRZNQ3 at 2023-03-11 20:09:58.129663. OCR = False. 21 files read. 42.0% done.\n",
      "Finished Document_FPBF5IKX at 2023-03-11 20:09:58.273525. OCR = False. 22 files read. 44.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_J7HBXYBQ at 2023-03-11 20:09:58.402847. OCR = False. 23 files read. 46.0% done.\n",
      "Did not finish Document_2LRB28HQ.pdf... check out that one.\n",
      "cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_SX39863M at 2023-03-11 20:09:58.618008. OCR = False. 25 files read. 50.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_9JV4R9EW at 2023-03-11 20:09:58.875258. OCR = False. 26 files read. 52.0% done.\n",
      "Did not finish Document_Q73YL96D.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_XVX4XMR2 at 2023-03-11 20:09:59.027622. OCR = False. 28 files read. 56.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_PKB9CB7I at 2023-03-11 20:09:59.098689. OCR = False. 29 files read. 58.0% done.\n",
      "Finished Document_7TIFU594 at 2023-03-11 20:09:59.153605. OCR = False. 30 files read. 60.0% done.\n",
      "Finished Document_TAAJRZEP at 2023-03-11 20:09:59.207205. OCR = False. 31 files read. 62.0% done.\n",
      "Did not finish Document_RH5JP7XX.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_LTZN6E4P at 2023-03-11 20:09:59.291235. OCR = False. 33 files read. 66.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_D6YVIFBC at 2023-03-11 20:09:59.373722. OCR = False. 34 files read. 68.0% done.\n",
      "Did not finish Document_3E578E54.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_IB7PWZVG at 2023-03-11 20:09:59.433626. OCR = False. 36 files read. 72.0% done.\n",
      "Did not finish Document_TMFT472T.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_YJRJLQSA at 2023-03-11 20:09:59.567517. OCR = False. 38 files read. 76.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_UTLT344I at 2023-03-11 20:09:59.707676. OCR = False. 39 files read. 78.0% done.\n",
      "Finished Document_DMKRZS8E at 2023-03-11 20:09:59.788718. OCR = False. 40 files read. 80.0% done.\n",
      "Finished Document_ZFPUQZNE at 2023-03-11 20:09:59.886059. OCR = False. 41 files read. 82.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_SYN9YTMS at 2023-03-11 20:09:59.988169. OCR = False. 42 files read. 84.0% done.\n",
      "Finished Document_G4923VSV at 2023-03-11 20:10:00.045462. OCR = False. 43 files read. 86.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_BTK3PPG8 at 2023-03-11 20:10:00.316764. OCR = False. 44 files read. 88.0% done.\n",
      "Finished Document_EV273D9P at 2023-03-11 20:10:00.437132. OCR = False. 45 files read. 90.0% done.\n",
      "Finished Document_PDUA89RL at 2023-03-11 20:10:00.505788. OCR = False. 46 files read. 92.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_VZGACXNN at 2023-03-11 20:10:00.635382. OCR = False. 47 files read. 94.0% done.\n",
      "Finished Document_YGFJAA5F at 2023-03-11 20:10:00.755323. OCR = False. 48 files read. 96.0% done.\n",
      "Finished Document_KN8U5AXF at 2023-03-11 20:10:00.803000. OCR = False. 49 files read. 98.0% done.\n",
      "Finished Document_NDH25D7X at 2023-03-11 20:10:00.852258. OCR = False. 50 files read. 100.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_19137/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "out = extract_pdfs(to_extract) # look at the frame.append method and change to concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_text</th>\n",
       "      <th>ocr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Document_47GCMTBN</td>\n",
       "      <td>Managing future urbanization\\n growth patterns...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Document_QCQS4ST2</td>\n",
       "      <td>Smart city re-imagined: City planning and GeoA...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Document_JI4B2NX5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Document_P3ZBU43W</td>\n",
       "      <td>Using Natural Language\\n Processing to Read Pl...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Document_DUDUGGU3</td>\n",
       "      <td>Contents lists available at ScienceDirect\\n Ci...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Document_TF4SN283</td>\n",
       "      <td>Incorporating planning intelligence into deep ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Document_M22IF67B</td>\n",
       "      <td>Supervised Machine Learning Approaches to Mode...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Document_DSCUFYAG</td>\n",
       "      <td>Vol.:(0123456789)\\n 1 3\\n AI &amp; SOCIETY \\n http...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Document_DHKVRINE</td>\n",
       "      <td>7\\n ARTIFICIAL INTELLIGENCE AND THE\\n RISE OF ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Document_6ES6XHAP</td>\n",
       "      <td>(IJACSA) International Journal of Advanced Com...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Document_MWQEBJBU</td>\n",
       "      <td>Citation: Lee, J.; Kim, D.; Park, J. A\\n Machi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Document_FPBF5IKX</td>\n",
       "      <td>Reviewing the application of machine learning ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Document_SX39863M</td>\n",
       "      <td>\\n Available online at www.ijournalse.org \\n ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Document_XVX4XMR2</td>\n",
       "      <td>Contents lists available at ScienceDirect\\n Co...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Document_7TIFU594</td>\n",
       "      <td>Applied Geography, Vol. 18, No. 1, pp. 83-96, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Document_LTZN6E4P</td>\n",
       "      <td>Contents lists available at ScienceDirect\\n Ci...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Document_IB7PWZVG</td>\n",
       "      <td>History and Theory 0, no. 0 (July 2022), 1–20\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Document_YJRJLQSA</td>\n",
       "      <td>Cities 129 (2022) 103925\\n Available online 15...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Document_DMKRZS8E</td>\n",
       "      <td>\\n  \\n  \\n  \\n Electronic Delivery Cover Shee...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Document_ZFPUQZNE</td>\n",
       "      <td>Will You Accept an Imperfect AI? Exploring Des...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Document_SYN9YTMS</td>\n",
       "      <td>When (ish) is My Bus? User-centered Visualizat...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Document_G4923VSV</td>\n",
       "      <td>What are Data Insights to Professional Visuali...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Document_BTK3PPG8</td>\n",
       "      <td>\\n  \\n Visual interactive \\n urban design in ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Document_EV273D9P</td>\n",
       "      <td>Urban Planning (ISSN: 2183–7635)\\n 2020, Volum...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Document_PDUA89RL</td>\n",
       "      <td>Visual Analytics of Urban Informality\\n and In...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Document_VZGACXNN</td>\n",
       "      <td>Visual Analytics in Urban Computing:\\n An Over...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Document_YGFJAA5F</td>\n",
       "      <td>Visual Analytics in Deep Learning: An\\n Interr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Document_KN8U5AXF</td>\n",
       "      <td>Computing in Civil Engineering 2019 \\n 328 \\n ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Document_NDH25D7X</td>\n",
       "      <td>637\\n BUILT  ENVIRONMENT   VOL  46   NO  4\\n V...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name                                          file_text  \\\n",
       "0               dummy                                              dummy   \n",
       "1   Document_47GCMTBN  Managing future urbanization\\n growth patterns...   \n",
       "3   Document_QCQS4ST2  Smart city re-imagined: City planning and GeoA...   \n",
       "5   Document_JI4B2NX5                                                ...   \n",
       "6   Document_P3ZBU43W  Using Natural Language\\n Processing to Read Pl...   \n",
       "8   Document_DUDUGGU3  Contents lists available at ScienceDirect\\n Ci...   \n",
       "10  Document_TF4SN283  Incorporating planning intelligence into deep ...   \n",
       "12  Document_M22IF67B  Supervised Machine Learning Approaches to Mode...   \n",
       "14  Document_DSCUFYAG  Vol.:(0123456789)\\n 1 3\\n AI & SOCIETY \\n http...   \n",
       "16  Document_DHKVRINE  7\\n ARTIFICIAL INTELLIGENCE AND THE\\n RISE OF ...   \n",
       "18  Document_6ES6XHAP  (IJACSA) International Journal of Advanced Com...   \n",
       "20  Document_MWQEBJBU  Citation: Lee, J.; Kim, D.; Park, J. A\\n Machi...   \n",
       "22  Document_FPBF5IKX  Reviewing the application of machine learning ...   \n",
       "24  Document_SX39863M   \\n Available online at www.ijournalse.org \\n ...   \n",
       "26  Document_XVX4XMR2  Contents lists available at ScienceDirect\\n Co...   \n",
       "28  Document_7TIFU594  Applied Geography, Vol. 18, No. 1, pp. 83-96, ...   \n",
       "30  Document_LTZN6E4P  Contents lists available at ScienceDirect\\n Ci...   \n",
       "32  Document_IB7PWZVG  History and Theory 0, no. 0 (July 2022), 1–20\\...   \n",
       "33  Document_YJRJLQSA  Cities 129 (2022) 103925\\n Available online 15...   \n",
       "35  Document_DMKRZS8E   \\n  \\n  \\n  \\n Electronic Delivery Cover Shee...   \n",
       "36  Document_ZFPUQZNE  Will You Accept an Imperfect AI? Exploring Des...   \n",
       "37  Document_SYN9YTMS  When (ish) is My Bus? User-centered Visualizat...   \n",
       "38  Document_G4923VSV  What are Data Insights to Professional Visuali...   \n",
       "39  Document_BTK3PPG8   \\n  \\n Visual interactive \\n urban design in ...   \n",
       "40  Document_EV273D9P  Urban Planning (ISSN: 2183–7635)\\n 2020, Volum...   \n",
       "41  Document_PDUA89RL  Visual Analytics of Urban Informality\\n and In...   \n",
       "42  Document_VZGACXNN  Visual Analytics in Urban Computing:\\n An Over...   \n",
       "43  Document_YGFJAA5F  Visual Analytics in Deep Learning: An\\n Interr...   \n",
       "44  Document_KN8U5AXF  Computing in Civil Engineering 2019 \\n 328 \\n ...   \n",
       "45  Document_NDH25D7X  637\\n BUILT  ENVIRONMENT   VOL  46   NO  4\\n V...   \n",
       "\n",
       "      ocr  \n",
       "0   False  \n",
       "1   False  \n",
       "3   False  \n",
       "5   False  \n",
       "6   False  \n",
       "8   False  \n",
       "10  False  \n",
       "12  False  \n",
       "14  False  \n",
       "16  False  \n",
       "18  False  \n",
       "20  False  \n",
       "22  False  \n",
       "24  False  \n",
       "26  False  \n",
       "28  False  \n",
       "30  False  \n",
       "32  False  \n",
       "33  False  \n",
       "35  False  \n",
       "36  False  \n",
       "37  False  \n",
       "38  False  \n",
       "39  False  \n",
       "40  False  \n",
       "41  False  \n",
       "42  False  \n",
       "43  False  \n",
       "44  False  \n",
       "45  False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.drop_duplicates(subset='file_text')\n",
    "out # we are able to scrape the vast majority of the articles without a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rapid topic modeling/cleaning prototyping:\n",
    "out.to_csv(\"extracted_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. Cleaning up the text\n",
    "Using strategies based on [this article](https://monkeylearn.com/blog/text-cleaning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, before we do any other cleaning tasks, this is where we need to match and remove references with the information we got from the Scholarcy API above.\n",
    "\n",
    "#### Resources:\n",
    "- [String comparison in Python](https://note.nkmk.me/en/python-str-compare/)\n",
    "- [Potentially useful example on StackOverflow](https://stackoverflow.com/questions/39551029/if-else-statement-for-finding-the-index-of-a-character-in-a-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def referenceChecker(extracted_df):\n",
    "    ref_excluded = {}\n",
    "    counter = 0\n",
    "    string3=\"\"\n",
    "    matches=0\n",
    "    nomatch=0\n",
    "    for name in extracted_df['file_name']:\n",
    "        if \"dummy\" not in name:\n",
    "            text_file = open(str(name) +\".txt\", \"r\")\n",
    "            data = text_file.read()      # Read whole file to a string\n",
    "            text_file.close()         # Close file\n",
    "            string1 = data.replace('\\n',\" \")\n",
    "            string2 = string1.replace('\\t',\"\")\n",
    "            starti =string2.find(\"References\")\n",
    "            startc = string2.find(\"REFERENCES\")\n",
    "            if starti:\n",
    "                string3 = string2.replace(string2[starti:], \"\")\n",
    "            elif startc:\n",
    "                string3 = string2.replace(string2[startc:], \"\")\n",
    "            ref_excluded[name] = string3\n",
    "    return ref_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ex = referenceChecker(out) #could be refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Tasks\n",
    "- Case Normalization\n",
    "- Remove Unicode Characters\n",
    "    - In the future, we may want to experiment with using [ftfy](https://github.com/rspeer/python-ftfy), which fixes text encoding issues, in this pipeline. We may also be interested in exploring [scrubadub](https://scrubadub.readthedocs.io/en/stable/index.html), which redacts potential PII from text.\n",
    "- Remove Stopwords\n",
    "- Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCleaner(ref_ex_dict):\n",
    "    full_corpus = []\n",
    "    stop = stopwords.words('english')\n",
    "    stop.extend(['et','al'])\n",
    "    for i in ref_ex_dict.keys():\n",
    "        data = ref_ex_dict[i]\n",
    "        da = data.lower()\n",
    "        d = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", da)\n",
    "        all_words = nltk.word_tokenize(d)\n",
    "        words = [w for w in all_words if w not in stop]\n",
    "        words = [w for w in words if w.isalpha()]\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        word_out = []\n",
    "        for word in words:\n",
    "            a = lemmatizer.lemmatize(word)\n",
    "            word_out.append(a)\n",
    "        ref_ex_dict[i] = word_out\n",
    "        full_corpus.append(word_out)\n",
    "    return ref_ex_dict, full_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = textCleaner(ref_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdict = a[0]\n",
    "corpus = a[1]\n",
    "full_corpus = [x for xs in corpus for x in xs] #flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick frequency distribution of the *most common words* in the corpus, and the *most common two and three word collocations* in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ai': 1293, 'urban': 1238, 'city': 735, 'data': 666, 'study': 517, 'model': 410, 'planning': 389, 'area': 333, 'used': 332, 'method': 295, ...})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_fd = nltk.FreqDist(full_corpus)\n",
    "word_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('computer', 'vision'): 110, ('land', 'use'): 108, ('articial', 'intelligence'): 101, ('walking', 'satisfaction'): 92, ('urban', 'planning'): 89, ('local', 'government'): 88, ('urban', 'service'): 86, ('ai', 'technology'): 85, ('hong', 'kong'): 72, ('shapley', 'value'): 71, ...})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_fd = nltk.FreqDist(nltk.bigrams(full_corpus))\n",
    "bigram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('urban', 'land', 'use'): 45, ('land', 'use', 'planning'): 36, ('proportion', 'street', 'furniture'): 34, ('figure', 'example', 'image'): 32, ('urban', 'service', 'ai'): 26, ('australia', 'hong', 'kong'): 25, ('ai', 'benefit', 'urban'): 24, ('benefit', 'urban', 'service'): 20, ('ai', 'benefit', 'disaster'): 20, ('urban', 'articial', 'intelligence'): 20, ...})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_fd = nltk.FreqDist(nltk.trigrams(full_corpus))\n",
    "trigram_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using some of nltk's built in functions to get more information about the collocation scores according to association measures.\n",
    "See more information about the nltk collocation methodology [here](https://www.nltk.org/api/nltk.collocations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('computer', 'vision'), 0.0014380776823417134),\n",
       " (('land', 'use'), 0.0014119308153900459),\n",
       " (('articial', 'intelligence'), 0.0013204167810592095),\n",
       " (('walking', 'satisfaction'), 0.0012027558797767057),\n",
       " (('urban', 'planning'), 0.0011635355793492045),\n",
       " (('local', 'government'), 0.0011504621458733708),\n",
       " (('urban', 'service'), 0.0011243152789217033),\n",
       " (('ai', 'technology'), 0.0011112418454458694),\n",
       " (('hong', 'kong'), 0.0009412872102600306),\n",
       " (('shapley', 'value'), 0.0009282137767841969),\n",
       " (('ai', 'help'), 0.0008889934763566955),\n",
       " (('deep', 'learning'), 0.0008889934763566955),\n",
       " (('machine', 'learning'), 0.0008497731759291942),\n",
       " (('smart', 'city'), 0.0008366997424533605),\n",
       " (('big', 'data'), 0.0007974794420258593),\n",
       " (('inll', 'development'), 0.0007844060085500255),\n",
       " (('urban', 'land'), 0.0007713325750741917),\n",
       " (('unsupervised', 'learning'), 0.0007321122746466904),\n",
       " (('urban', 'design'), 0.0007321122746466904),\n",
       " (('urban', 'growth'), 0.0007190388411708567),\n",
       " (('urban', 'study'), 0.0007190388411708567),\n",
       " (('ai', 'machine'), 0.0007059654076950229),\n",
       " (('built', 'environment'), 0.0007059654076950229),\n",
       " (('ai', 'benefit'), 0.0006798185407433555),\n",
       " (('financial', 'resource'), 0.0006405982403158542),\n",
       " (('street', 'furniture'), 0.0006405982403158542),\n",
       " (('urban', 'development'), 0.0006275248068400204),\n",
       " (('use', 'ai'), 0.0006013779398883529),\n",
       " (('neural', 'network'), 0.0005883045064125191),\n",
       " (('ai', 'agent'), 0.0005752310729366854),\n",
       " (('autonomous', 'car'), 0.0005229373390333503),\n",
       " (('example', 'image'), 0.0005229373390333503),\n",
       " (('land', 'cell'), 0.0005229373390333503),\n",
       " (('ai', 'used'), 0.0005098639055575166),\n",
       " (('city', 'planning'), 0.0005098639055575166),\n",
       " (('urban', 'system'), 0.0005098639055575166),\n",
       " (('area', 'ratio'), 0.0004967904720816828),\n",
       " (('city', 'brain'), 0.0004967904720816828),\n",
       " (('street', 'view'), 0.0004967904720816828),\n",
       " (('case', 'study'), 0.00048371703860584903),\n",
       " (('figure', 'example'), 0.00048371703860584903),\n",
       " (('public', 'perception'), 0.00048371703860584903),\n",
       " (('urban', 'geography'), 0.00048371703860584903),\n",
       " (('use', 'planning'), 0.00048371703860584903),\n",
       " (('study', 'area'), 0.0004706436051300153),\n",
       " (('proportion', 'street'), 0.00045757017165418156),\n",
       " (('agedcare', 'disability'), 0.00043142330470251404),\n",
       " (('logistic', 'regression'), 0.00043142330470251404),\n",
       " (('social', 'medium'), 0.00043142330470251404),\n",
       " (('autonomous', 'city'), 0.0004052764377508465),\n",
       " (('urban', 'space'), 0.0004052764377508465),\n",
       " (('edge', 'detection'), 0.00039220300427501273),\n",
       " (('service', 'ai'), 0.00039220300427501273),\n",
       " (('topic', 'modeling'), 0.00039220300427501273),\n",
       " (('ud', 'clustering'), 0.00039220300427501273),\n",
       " (('walking', 'environment'), 0.00039220300427501273),\n",
       " (('application', 'ai'), 0.000379129570799179),\n",
       " (('input', 'data'), 0.000379129570799179),\n",
       " (('application', 'area'), 0.0003660561373233452),\n",
       " (('clustering', 'kmeans'), 0.0003660561373233452),\n",
       " (('ranked', 'agree'), 0.0003660561373233452),\n",
       " (('ai', 'application'), 0.00035298270384751147),\n",
       " (('ai', 'local'), 0.00035298270384751147),\n",
       " (('data', 'set'), 0.00035298270384751147),\n",
       " (('supervised', 'learning'), 0.00035298270384751147),\n",
       " (('believe', 'ai'), 0.00033990927037167774),\n",
       " (('lagos', 'metropolis'), 0.00033990927037167774),\n",
       " (('machinelearning', 'model'), 0.00033990927037167774),\n",
       " (('trust', 'ai'), 0.00033990927037167774),\n",
       " (('australia', 'hong'), 0.00032683583689584395),\n",
       " (('goalreasoning', 'ai'), 0.00032683583689584395),\n",
       " (('perception', 'ai'), 0.00032683583689584395),\n",
       " (('random', 'forest'), 0.00032683583689584395),\n",
       " (('semantic', 'segmentation'), 0.00032683583689584395),\n",
       " (('urban', 'area'), 0.00032683583689584395),\n",
       " (('ai', 'society'), 0.0003137624034200102),\n",
       " (('benefit', 'urban'), 0.0003137624034200102),\n",
       " (('planning', 'design'), 0.0003137624034200102),\n",
       " (('proportion', 'road'), 0.0003137624034200102),\n",
       " (('decision', 'maker'), 0.00030068896994417643),\n",
       " (('disaster', 'management'), 0.00030068896994417643),\n",
       " (('green', 'space'), 0.00030068896994417643),\n",
       " (('ml', 'algorithm'), 0.00030068896994417643),\n",
       " (('ai', 'trust'), 0.0002876155364683427),\n",
       " (('ai', 'urban'), 0.0002876155364683427),\n",
       " (('effect', 'walking'), 0.0002876155364683427),\n",
       " (('goal', 'reasoning'), 0.0002876155364683427),\n",
       " (('proportion', 'building'), 0.0002876155364683427),\n",
       " (('proportion', 'sidewalk'), 0.0002876155364683427),\n",
       " (('shap', 'value'), 0.0002876155364683427),\n",
       " (('street', 'environment'), 0.0002876155364683427),\n",
       " (('urban', 'analytics'), 0.0002876155364683427),\n",
       " (('urban', 'articial'), 0.0002876155364683427),\n",
       " (('urban', 'future'), 0.0002876155364683427),\n",
       " (('ai', 'risk'), 0.0002745421029925089),\n",
       " (('builtup', 'area'), 0.0002745421029925089),\n",
       " (('city', 'system'), 0.0002745421029925089),\n",
       " (('expert', 'knowledge'), 0.0002745421029925089),\n",
       " (('physical', 'feature'), 0.0002745421029925089),\n",
       " (('science', 'journal'), 0.0002745421029925089),\n",
       " (('unsupervised', 'method'), 0.0002745421029925089),\n",
       " (('urban', 'form'), 0.0002745421029925089),\n",
       " (('using', 'ai'), 0.0002745421029925089),\n",
       " (('value', 'plot'), 0.0002745421029925089),\n",
       " (('benefit', 'disaster'), 0.00026146866951667517),\n",
       " (('data', 'type'), 0.00026146866951667517),\n",
       " (('emerging', 'science'), 0.00026146866951667517),\n",
       " (('factor', 'analysis'), 0.00026146866951667517),\n",
       " (('public', 'sector'), 0.00026146866951667517),\n",
       " (('ur', 'clustering'), 0.00026146866951667517),\n",
       " (('urban', 'environment'), 0.00026146866951667517),\n",
       " (('wide', 'range'), 0.00026146866951667517),\n",
       " (('adopting', 'ai'), 0.0002483952360408414),\n",
       " (('cnn', 'model'), 0.0002483952360408414),\n",
       " (('hidden', 'layer'), 0.0002483952360408414),\n",
       " (('journal', 'vol'), 0.0002483952360408414),\n",
       " (('local', 'community'), 0.0002483952360408414),\n",
       " (('positive', 'effect'), 0.0002483952360408414),\n",
       " (('public', 'service'), 0.0002483952360408414),\n",
       " (('remote', 'sensing'), 0.0002483952360408414),\n",
       " (('thematic', 'group'), 0.0002483952360408414),\n",
       " (('urban', 'data'), 0.0002483952360408414),\n",
       " (('urban', 'management'), 0.0002483952360408414),\n",
       " (('vol', 'page'), 0.0002483952360408414),\n",
       " (('clustering', 'dbscan'), 0.00023532180256500765),\n",
       " (('image', 'showing'), 0.00023532180256500765),\n",
       " (('interaction', 'eects'), 0.00023532180256500765),\n",
       " (('ml', 'model'), 0.00023532180256500765),\n",
       " (('model', 'performance'), 0.00023532180256500765),\n",
       " (('mostly', 'positive'), 0.00023532180256500765),\n",
       " (('shap', 'summary'), 0.00023532180256500765),\n",
       " (('showing', 'proportion'), 0.00023532180256500765),\n",
       " (('summary', 'plot'), 0.00023532180256500765),\n",
       " (('sustainable', 'urban'), 0.00023532180256500765),\n",
       " (('u', 'clustering'), 0.00023532180256500765),\n",
       " (('urban', 'dynamic'), 0.00023532180256500765),\n",
       " (('visual', 'analytics'), 0.00023532180256500765),\n",
       " (('ai', 'adoption'), 0.0002222483690891739),\n",
       " (('ai', 'public'), 0.0002222483690891739),\n",
       " (('data', 'source'), 0.0002222483690891739),\n",
       " (('disaster', 'ai'), 0.0002222483690891739),\n",
       " (('feature', 'extraction'), 0.0002222483690891739),\n",
       " (('heterogeneous', 'goal'), 0.0002222483690891739),\n",
       " (('learning', 'model'), 0.0002222483690891739),\n",
       " (('research', 'strategy'), 0.0002222483690891739),\n",
       " (('risk', 'ai'), 0.0002222483690891739),\n",
       " (('visual', 'feature'), 0.0002222483690891739),\n",
       " (('clustering', 'som'), 0.00020917493561334013),\n",
       " (('floating', 'population'), 0.00020917493561334013),\n",
       " (('future', 'research'), 0.00020917493561334013),\n",
       " (('growth', 'pattern'), 0.00020917493561334013),\n",
       " (('learning', 'algorithm'), 0.00020917493561334013),\n",
       " (('machine', 'used'), 0.00020917493561334013),\n",
       " (('pedestrian', 'satisfaction'), 0.00020917493561334013),\n",
       " (('satellite', 'image'), 0.00020917493561334013),\n",
       " (('see', 'table'), 0.00020917493561334013),\n",
       " (('state', 'space'), 0.00020917493561334013),\n",
       " (('think', 'ai'), 0.00020917493561334013),\n",
       " (('urban', 'transport'), 0.00020917493561334013),\n",
       " (('affected', 'walking'), 0.00019610150213750636),\n",
       " (('decision', 'tree'), 0.00019610150213750636),\n",
       " (('f', 'biljecki'), 0.00019610150213750636),\n",
       " (('gender', 'age'), 0.00019610150213750636),\n",
       " (('j', 'wang'), 0.00019610150213750636),\n",
       " (('naver', 'street'), 0.00019610150213750636),\n",
       " (('new', 'data'), 0.00019610150213750636),\n",
       " (('p', 'p'), 0.00019610150213750636),\n",
       " (('peer', 'review'), 0.00019610150213750636),\n",
       " (('seoul', 'floating'), 0.00019610150213750636),\n",
       " (('urban', 'sustainability'), 0.00019610150213750636),\n",
       " (('vertical', 'element'), 0.00019610150213750636),\n",
       " (('art', 'culture'), 0.0001830280686616726),\n",
       " (('artificial', 'intelligence'), 0.0001830280686616726),\n",
       " (('biljecki', 'city'), 0.0001830280686616726),\n",
       " (('data', 'collection'), 0.0001830280686616726),\n",
       " (('decision', 'making'), 0.0001830280686616726),\n",
       " (('design', 'planning'), 0.0001830280686616726),\n",
       " (('digital', 'divide'), 0.0001830280686616726),\n",
       " (('human', 'planner'), 0.0001830280686616726),\n",
       " (('j', 'urban'), 0.0001830280686616726),\n",
       " (('key', 'challenge'), 0.0001830280686616726),\n",
       " (('los', 'angeles'), 0.0001830280686616726),\n",
       " (('people', 'prefer'), 0.0001830280686616726),\n",
       " (('plann', 'dev'), 0.0001830280686616726),\n",
       " (('population', 'report'), 0.0001830280686616726),\n",
       " (('prefer', 'street'), 0.0001830280686616726),\n",
       " (('ref', 'yes'), 0.0001830280686616726),\n",
       " (('reinforcement', 'learning'), 0.0001830280686616726),\n",
       " (('residential', 'area'), 0.0001830280686616726),\n",
       " (('rise', 'autonomous'), 0.0001830280686616726),\n",
       " (('study', 'used'), 0.0001830280686616726),\n",
       " (('sustainability', 'x'), 0.0001830280686616726),\n",
       " (('urban', 'plann'), 0.0001830280686616726),\n",
       " (('used', 'reduce'), 0.0001830280686616726),\n",
       " (('wang', 'f'), 0.0001830280686616726),\n",
       " (('x', 'peer'), 0.0001830280686616726),\n",
       " (('adopt', 'ai'), 0.00016995463518583887),\n",
       " (('ai', 'city'), 0.00016995463518583887),\n",
       " (('ai', 'project'), 0.00016995463518583887),\n",
       " (('application', 'challenge'), 0.00016995463518583887),\n",
       " (('best', 'solution'), 0.00016995463518583887),\n",
       " (('bootstrap', 'sampling'), 0.00016995463518583887),\n",
       " (('dependence', 'plot'), 0.00016995463518583887),\n",
       " (('deployment', 'ai'), 0.00016995463518583887),\n",
       " (('design', 'quality'), 0.00016995463518583887),\n",
       " (('geographic', 'information'), 0.00016995463518583887),\n",
       " (('human', 'planning'), 0.00016995463518583887),\n",
       " (('impact', 'ai'), 0.00016995463518583887),\n",
       " (('intelligence', 'ai'), 0.00016995463518583887),\n",
       " (('journal', 'urban'), 0.00016995463518583887),\n",
       " (('lack', 'transparency'), 0.00016995463518583887),\n",
       " (('layer', 'city'), 0.00016995463518583887),\n",
       " (('learning', 'computer'), 0.00016995463518583887),\n",
       " (('learning', 'urban'), 0.00016995463518583887),\n",
       " (('method', 'used'), 0.00016995463518583887),\n",
       " (('pedestrian', 'environment'), 0.00016995463518583887),\n",
       " (('planning', 'manuscript'), 0.00016995463518583887),\n",
       " (('positive', 'shapley'), 0.00016995463518583887),\n",
       " (('residential', 'inll'), 0.00016995463518583887),\n",
       " (('service', 'robot'), 0.00016995463518583887),\n",
       " (('shap', 'dependence'), 0.00016995463518583887),\n",
       " (('social', 'economic'), 0.00016995463518583887),\n",
       " (('systematic', 'review'), 0.00016995463518583887),\n",
       " (('uiip', 'lagos'), 0.00016995463518583887),\n",
       " (('urban', 'challenge'), 0.00016995463518583887),\n",
       " (('urban', 'informality'), 0.00016995463518583887),\n",
       " (('used', 'urban'), 0.00016995463518583887),\n",
       " (('w', 'chen'), 0.00016995463518583887),\n",
       " (('adoption', 'challenge'), 0.0001568812017100051),\n",
       " (('agricultural', 'land'), 0.0001568812017100051),\n",
       " (('ai', 'agedcare'), 0.0001568812017100051),\n",
       " (('ai', 'experience'), 0.0001568812017100051),\n",
       " (('ai', 'feel'), 0.0001568812017100051),\n",
       " (('ai', 'rise'), 0.0001568812017100051),\n",
       " (('ann', 'architecture'), 0.0001568812017100051),\n",
       " (('challenge', 'adopting'), 0.0001568812017100051),\n",
       " (('challenge', 'ai'), 0.0001568812017100051),\n",
       " (('chen', 'city'), 0.0001568812017100051),\n",
       " (('decision', 'support'), 0.0001568812017100051),\n",
       " (('delivery', 'urban'), 0.0001568812017100051),\n",
       " (('descriptive', 'analysis'), 0.0001568812017100051),\n",
       " (('element', 'make'), 0.0001568812017100051),\n",
       " (('emergency', 'service'), 0.0001568812017100051),\n",
       " (('extraction', 'pca'), 0.0001568812017100051),\n",
       " (('factor', 'extraction'), 0.0001568812017100051),\n",
       " (('feel', 'use'), 0.0001568812017100051),\n",
       " (('four', 'goal'), 0.0001568812017100051),\n",
       " (('future', 'application'), 0.0001568812017100051),\n",
       " (('help', 'local'), 0.0001568812017100051),\n",
       " (('lack', 'clarity'), 0.0001568812017100051),\n",
       " (('learning', 'method'), 0.0001568812017100051),\n",
       " (('modeling', 'lda'), 0.0001568812017100051),\n",
       " (('oa', 'achieved'), 0.0001568812017100051),\n",
       " (('positively', 'affected'), 0.0001568812017100051),\n",
       " (('predictive', 'performance'), 0.0001568812017100051),\n",
       " (('r', 'c'), 0.0001568812017100051),\n",
       " (('review', 'table'), 0.0001568812017100051),\n",
       " (('road', 'proportion'), 0.0001568812017100051),\n",
       " (('sample', 'size'), 0.0001568812017100051),\n",
       " (('satisfaction', 'score'), 0.0001568812017100051),\n",
       " (('see', 'fig'), 0.0001568812017100051),\n",
       " (('showed', 'positive'), 0.0001568812017100051),\n",
       " (('significant', 'challenge'), 0.0001568812017100051),\n",
       " (('socioeconomic', 'environmental'), 0.0001568812017100051),\n",
       " (('urban', 'infrastructure'), 0.0001568812017100051),\n",
       " (('value', 'proportion'), 0.0001568812017100051),\n",
       " (('value', 'value'), 0.0001568812017100051),\n",
       " (('view', 'image'), 0.0001568812017100051),\n",
       " (('vision', 'algorithm'), 0.0001568812017100051),\n",
       " (('widely', 'used'), 0.0001568812017100051),\n",
       " (('affect', 'pedestrian'), 0.00014380776823417135),\n",
       " (('ai', 'perception'), 0.00014380776823417135),\n",
       " (('ai', 'would'), 0.00014380776823417135),\n",
       " (('anns', 'deep'), 0.00014380776823417135),\n",
       " (('clustering', 'multiple'), 0.00014380776823417135),\n",
       " (('com', 'puters'), 0.00014380776823417135),\n",
       " (('economic', 'development'), 0.00014380776823417135),\n",
       " (('enclosure', 'sum'), 0.00014380776823417135),\n",
       " (('ent', 'urban'), 0.00014380776823417135),\n",
       " (('environm', 'ent'), 0.00014380776823417135),\n",
       " (('environmental', 'infrastructure'), 0.00014380776823417135),\n",
       " (('furniture', 'enclosure'), 0.00014380776823417135),\n",
       " (('heuristic', 'h'), 0.00014380776823417135),\n",
       " (('highest', 'satisfaction'), 0.00014380776823417135),\n",
       " (('independent', 'variable'), 0.00014380776823417135),\n",
       " (('infrastructure', 'planning'), 0.00014380776823417135),\n",
       " (('j', 'kropp'), 0.00014380776823417135),\n",
       " (('land', 'usecover'), 0.00014380776823417135),\n",
       " (('lulc', 'map'), 0.00014380776823417135),\n",
       " (('make', 'decision'), 0.00014380776823417135),\n",
       " (('negative', 'effect'), 0.00014380776823417135),\n",
       " (('number', 'lane'), 0.00014380776823417135),\n",
       " (('number', 'paper'), 0.00014380776823417135),\n",
       " (('pedestrian', 'prefer'), 0.00014380776823417135),\n",
       " (('planning', 'task'), 0.00014380776823417135),\n",
       " (('positive', 'correlation'), 0.00014380776823417135),\n",
       " (('positive', 'indicating'), 0.00014380776823417135),\n",
       " (('probability', 'people'), 0.00014380776823417135),\n",
       " (('puters', 'environm'), 0.00014380776823417135),\n",
       " (('rail', 'transit'), 0.00014380776823417135),\n",
       " (('regression', 'model'), 0.00014380776823417135),\n",
       " (('satisfaction', 'however'), 0.00014380776823417135),\n",
       " (('scenario', 'simulation'), 0.00014380776823417135),\n",
       " (('spatial', 'data'), 0.00014380776823417135),\n",
       " (('streetscape', 'image'), 0.00014380776823417135),\n",
       " (('streetscape', 'people'), 0.00014380776823417135),\n",
       " (('thematic', 'issue'), 0.00014380776823417135),\n",
       " (('urban', 'function'), 0.00014380776823417135),\n",
       " (('urban', 'morphology'), 0.00014380776823417135),\n",
       " (('urban', 'planner'), 0.00014380776823417135),\n",
       " (('urbanization', 'growth'), 0.00014380776823417135),\n",
       " (('used', 'monitor'), 0.00014380776823417135),\n",
       " (('using', 'computer'), 0.00014380776823417135),\n",
       " (('value', 'mostly'), 0.00014380776823417135),\n",
       " (('ai', 'implementation'), 0.00013073433475833759),\n",
       " (('ai', 'knowledge'), 0.00013073433475833759),\n",
       " (('ai', 'research'), 0.00013073433475833759),\n",
       " (('analysis', 'city'), 0.00013073433475833759),\n",
       " (('analysis', 'da'), 0.00013073433475833759),\n",
       " (('analysis', 'factor'), 0.00013073433475833759),\n",
       " (('analytics', 'urban'), 0.00013073433475833759),\n",
       " (('application', 'type'), 0.00013073433475833759),\n",
       " (('attribute', 'descriptive'), 0.00013073433475833759),\n",
       " (('building', 'openness'), 0.00013073433475833759),\n",
       " (('bus', 'stop'), 0.00013073433475833759),\n",
       " (('capability', 'ai'), 0.00013073433475833759),\n",
       " (('change', 'detection'), 0.00013073433475833759),\n",
       " (('change', 'urban'), 0.00013073433475833759),\n",
       " (('city', 'los'), 0.00013073433475833759),\n",
       " (('coefficient', 'respectively'), 0.00013073433475833759),\n",
       " (('complex', 'urban'), 0.00013073433475833759),\n",
       " (('complexity', 'greenery'), 0.00013073433475833759),\n",
       " (('complexity', 'value'), 0.00013073433475833759),\n",
       " (('concern', 'ai'), 0.00013073433475833759),\n",
       " (('cost', 'saving'), 0.00013073433475833759),\n",
       " (('dependent', 'variable'), 0.00013073433475833759),\n",
       " (('design', 'research'), 0.00013073433475833759),\n",
       " (('devel', 'opment'), 0.00013073433475833759),\n",
       " (('distance', 'nearest'), 0.00013073433475833759),\n",
       " (('experience', 'ai'), 0.00013073433475833759),\n",
       " (('figure', 'describes'), 0.00013073433475833759),\n",
       " (('forest', 'xgboost'), 0.00013073433475833759),\n",
       " (('future', 'urban'), 0.00013073433475833759),\n",
       " (('future', 'urbanization'), 0.00013073433475833759),\n",
       " (('g', 'grekousis'), 0.00013073433475833759),\n",
       " (('gmcts', 'ai'), 0.00013073433475833759),\n",
       " (('government', 'financial'), 0.00013073433475833759),\n",
       " (('greenery', 'proportion'), 0.00013073433475833759),\n",
       " (('grekousis', 'com'), 0.00013073433475833759),\n",
       " (('high', 'probability'), 0.00013073433475833759),\n",
       " (('implementing', 'ai'), 0.00013073433475833759),\n",
       " (('investment', 'capability'), 0.00013073433475833759),\n",
       " (('knowl', 'edge'), 0.00013073433475833759),\n",
       " (('land', 'cover'), 0.00013073433475833759),\n",
       " (('landuse', 'planning'), 0.00013073433475833759),\n",
       " (('learning', 'technique'), 0.00013073433475833759),\n",
       " (('limited', 'local'), 0.00013073433475833759),\n",
       " (('masdar', 'city'), 0.00013073433475833759),\n",
       " (('maximum', 'input'), 0.00013073433475833759),\n",
       " (('melbourne', 'brisbane'), 0.00013073433475833759),\n",
       " (('monitor', 'respond'), 0.00013073433475833759),\n",
       " (('planning', 'urban'), 0.00013073433475833759),\n",
       " (('policy', 'goal'), 0.00013073433475833759),\n",
       " (('positive', 'positive'), 0.00013073433475833759),\n",
       " (('public', 'opinion'), 0.00013073433475833759),\n",
       " (('ra', 'ai'), 0.00013073433475833759),\n",
       " (('ratio', 'le'), 0.00013073433475833759),\n",
       " (('reduce', 'public'), 0.00013073433475833759),\n",
       " (('resource', 'investment'), 0.00013073433475833759),\n",
       " (('right', 'wrong'), 0.00013073433475833759),\n",
       " (('satisfying', 'walking'), 0.00013073433475833759),\n",
       " (('step', 'action'), 0.00013073433475833759),\n",
       " (('study', 'urban'), 0.00013073433475833759),\n",
       " (('sustainable', 'development'), 0.00013073433475833759),\n",
       " (('sydney', 'melbourne'), 0.00013073433475833759),\n",
       " (('system', 'j'), 0.00013073433475833759),\n",
       " (('thing', 'see'), 0.00013073433475833759),\n",
       " (('using', 'anns'), 0.00013073433475833759),\n",
       " (('width', 'sidewalk'), 0.00013073433475833759),\n",
       " (('addition', 'shapley'), 0.00011766090128250382),\n",
       " (('affect', 'walking'), 0.00011766090128250382),\n",
       " (('agree', 'ai'), 0.00011766090128250382),\n",
       " (('ai', 'applied'), 0.00011766090128250382),\n",
       " (('ai', 'future'), 0.00011766090128250382),\n",
       " (('ai', 'may'), 0.00011766090128250382),\n",
       " (('ai', 'might'), 0.00011766090128250382),\n",
       " (('analysis', 'result'), 0.00011766090128250382),\n",
       " (('anns', 'urban'), 0.00011766090128250382),\n",
       " (('anns', 'used'), 0.00011766090128250382),\n",
       " (('area', 'class'), 0.00011766090128250382),\n",
       " (('articial', 'neural'), 0.00011766090128250382),\n",
       " (('canny', 'edge'), 0.00011766090128250382),\n",
       " (('challenge', 'government'), 0.00011766090128250382),\n",
       " (('close', 'maximum'), 0.00011766090128250382),\n",
       " (('community', 'member'), 0.00011766090128250382),\n",
       " (('computer', 'science'), 0.00011766090128250382),\n",
       " (('contributing', 'factor'), 0.00011766090128250382),\n",
       " (('correlation', 'showed'), 0.00011766090128250382),\n",
       " (('correlation', 'thereafter'), 0.00011766090128250382),\n",
       " (('corresponding', 'author'), 0.00011766090128250382),\n",
       " (('data', 'highest'), 0.00011766090128250382),\n",
       " (('deep', 'cnn'), 0.00011766090128250382),\n",
       " (('design', 'management'), 0.00011766090128250382),\n",
       " (('enclosure', 'positive'), 0.00011766090128250382),\n",
       " (('enclosure', 'proportion'), 0.00011766090128250382),\n",
       " (('enclosure', 'showed'), 0.00011766090128250382),\n",
       " (('feature', 'value'), 0.00011766090128250382),\n",
       " (('fulllment', 'degree'), 0.00011766090128250382),\n",
       " (('furniture', 'close'), 0.00011766090128250382),\n",
       " (('furniture', 'mostly'), 0.00011766090128250382),\n",
       " (('g', 'g'), 0.00011766090128250382),\n",
       " (('goaloriented', 'heuristic'), 0.00011766090128250382),\n",
       " (('government', 'adopt'), 0.00011766090128250382),\n",
       " (('government', 'monitor'), 0.00011766090128250382),\n",
       " (('guideline', 'reporting'), 0.00011766090128250382),\n",
       " (('however', 'area'), 0.00011766090128250382),\n",
       " (('human', 'activity'), 0.00011766090128250382),\n",
       " (('ibrahim', 'city'), 0.00011766090128250382),\n",
       " (('image', 'naver'), 0.00011766090128250382),\n",
       " (('indicating', 'pedestrian'), 0.00011766090128250382),\n",
       " (('indicating', 'positively'), 0.00011766090128250382),\n",
       " (('informality', 'infrastructure'), 0.00011766090128250382),\n",
       " (('large', 'amount'), 0.00011766090128250382),\n",
       " (('le', 'shapley'), 0.00011766090128250382),\n",
       " (('literature', 'review'), 0.00011766090128250382),\n",
       " (('make', 'streetscape'), 0.00011766090128250382),\n",
       " (('management', 'xxx'), 0.00011766090128250382),\n",
       " (('many', 'thing'), 0.00011766090128250382),\n",
       " (('mr', 'ibrahim'), 0.00011766090128250382),\n",
       " (('negative', 'correlation'), 0.00011766090128250382),\n",
       " (('negative', 'indicating'), 0.00011766090128250382),\n",
       " (('network', 'analysis'), 0.00011766090128250382),\n",
       " (('objectbased', 'detection'), 0.00011766090128250382),\n",
       " (('openness', 'shapley'), 0.00011766090128250382),\n",
       " (('p', 'jankowski'), 0.00011766090128250382),\n",
       " (('plan', 'ning'), 0.00011766090128250382),\n",
       " (('plot', 'proportion'), 0.00011766090128250382),\n",
       " (('population', 'growth'), 0.00011766090128250382),\n",
       " (('prefer', 'proportion'), 0.00011766090128250382),\n",
       " (('principal', 'component'), 0.00011766090128250382),\n",
       " (('proportion', 'proportion'), 0.00011766090128250382),\n",
       " (('r', 'mortaheb'), 0.00011766090128250382),\n",
       " (('regarding', 'ai'), 0.00011766090128250382),\n",
       " (('regression', 'random'), 0.00011766090128250382),\n",
       " (('reviewed', 'paper'), 0.00011766090128250382),\n",
       " (('rf', 'algorithm'), 0.00011766090128250382),\n",
       " (('right', 'side'), 0.00011766090128250382),\n",
       " (('road', 'figure'), 0.00011766090128250382),\n",
       " (('satisfaction', 'enclosure'), 0.00011766090128250382),\n",
       " (('satisfaction', 'shown'), 0.00011766090128250382),\n",
       " (('sector', 'cost'), 0.00011766090128250382),\n",
       " (('see', 'complexity'), 0.00011766090128250382),\n",
       " (('seed', 'ai'), 0.00011766090128250382),\n",
       " (('showed', 'negative'), 0.00011766090128250382),\n",
       " (('shown', 'enclosure'), 0.00011766090128250382),\n",
       " (('shown', 'figure'), 0.00011766090128250382),\n",
       " (('sidewalk', 'complexity'), 0.00011766090128250382),\n",
       " (('significant', 'driver'), 0.00011766090128250382),\n",
       " (('smart', 'card'), 0.00011766090128250382),\n",
       " (('smart', 'growth'), 0.00011766090128250382),\n",
       " (('socioeconomic', 'characteristic'), 0.00011766090128250382),\n",
       " (('solve', 'problem'), 0.00011766090128250382),\n",
       " (('street', 'many'), 0.00011766090128250382),\n",
       " (('sum', 'vertical'), 0.00011766090128250382),\n",
       " (('support', 'system'), 0.00011766090128250382),\n",
       " (('table', 'shap'), 0.00011766090128250382),\n",
       " (('thereafter', 'addition'), 0.00011766090128250382),\n",
       " (('training', 'data'), 0.00011766090128250382),\n",
       " (('training', 'process'), 0.00011766090128250382),\n",
       " (('transparency', 'community'), 0.00011766090128250382),\n",
       " (('two', 'goal'), 0.00011766090128250382),\n",
       " (('use', 'anns'), 0.00011766090128250382),\n",
       " (('using', 'data'), 0.00011766090128250382),\n",
       " (('value', 'enclosure'), 0.00011766090128250382),\n",
       " (('value', 'negative'), 0.00011766090128250382),\n",
       " (('view', 'api'), 0.00011766090128250382),\n",
       " (('xai', 'technique'), 0.00011766090128250382),\n",
       " (('xxx', 'xxxx'), 0.00011766090128250382),\n",
       " (('xxxx', 'xxx'), 0.00011766090128250382),\n",
       " (('age', 'group'), 0.00010458746780667006),\n",
       " (('ai', 'yesno'), 0.00010458746780667006),\n",
       " (('area', 'adoption'), 0.00010458746780667006),\n",
       " (('australian', 'hongkongers'), 0.00010458746780667006),\n",
       " (('available', 'online'), 0.00010458746780667006),\n",
       " (('bar', 'indicates'), 0.00010458746780667006),\n",
       " (('better', 'understand'), 0.00010458746780667006),\n",
       " (('bootstrapped', 'mean'), 0.00010458746780667006),\n",
       " (('building', 'figure'), 0.00010458746780667006),\n",
       " (('challenge', 'local'), 0.00010458746780667006),\n",
       " (('clustering', 'hca'), 0.00010458746780667006),\n",
       " (('community', 'engagement'), 0.00010458746780667006),\n",
       " (('company', 'developing'), 0.00010458746780667006),\n",
       " (('component', 'analysis'), 0.00010458746780667006),\n",
       " (('control', 'system'), 0.00010458746780667006),\n",
       " (('data', 'collected'), 0.00010458746780667006),\n",
       " (('deep', 'model'), 0.00010458746780667006),\n",
       " (('determining', 'disaster'), 0.00010458746780667006),\n",
       " (('development', 'ai'), 0.00010458746780667006),\n",
       " (('development', 'city'), 0.00010458746780667006),\n",
       " (('digital', 'tool'), 0.00010458746780667006),\n",
       " (('direction', 'size'), 0.00010458746780667006),\n",
       " (('economic', 'environmental'), 0.00010458746780667006),\n",
       " (('environment', 'urban'), 0.00010458746780667006),\n",
       " (('feature', 'urban'), 0.00010458746780667006),\n",
       " (('first', 'thought'), 0.00010458746780667006),\n",
       " (('form', 'urban'), 0.00010458746780667006),\n",
       " (('ga', 'future'), 0.00010458746780667006),\n",
       " (('ga', 'model'), 0.00010458746780667006),\n",
       " (('global', 'optimum'), 0.00010458746780667006),\n",
       " (('growth', 'prediction'), 0.00010458746780667006),\n",
       " (('help', 'determining'), 0.00010458746780667006),\n",
       " (('human', 'intelligence'), 0.00010458746780667006),\n",
       " (('human', 'interaction'), 0.00010458746780667006),\n",
       " (('information', 'system'), 0.00010458746780667006),\n",
       " (('jankowski', 'journal'), 0.00010458746780667006),\n",
       " (('kmeans', 'clustering'), 0.00010458746780667006),\n",
       " (('knn', 'algorithm'), 0.00010458746780667006),\n",
       " (('kong', 'resident'), 0.00010458746780667006),\n",
       " (('machine', 'making'), 0.00010458746780667006),\n",
       " (('machinelearning', 'algorithm'), 0.00010458746780667006),\n",
       " (('make', 'possible'), 0.00010458746780667006),\n",
       " (('melbourne', 'participant'), 0.00010458746780667006),\n",
       " (('mlp', 'algorithm'), 0.00010458746780667006),\n",
       " (('mobile', 'phone'), 0.00010458746780667006),\n",
       " (('mortaheb', 'p'), 0.00010458746780667006),\n",
       " (('natural', 'environment'), 0.00010458746780667006),\n",
       " (('open', 'access'), 0.00010458746780667006),\n",
       " (('paper', 'also'), 0.00010458746780667006),\n",
       " (('pedestrian', 'catchment'), 0.00010458746780667006),\n",
       " (('performance', 'ml'), 0.00010458746780667006),\n",
       " (('physical', 'characteristic'), 0.00010458746780667006),\n",
       " (('physical', 'environment'), 0.00010458746780667006),\n",
       " (('plot', 'rank'), 0.00010458746780667006),\n",
       " (('point', 'view'), 0.00010458746780667006),\n",
       " (('potential', 'application'), 0.00010458746780667006),\n",
       " (('real', 'estate'), 0.00010458746780667006),\n",
       " (('recent', 'study'), 0.00010458746780667006),\n",
       " (('related', 'urban'), 0.00010458746780667006),\n",
       " (('resource', 'significant'), 0.00010458746780667006),\n",
       " (('result', 'machinelearning'), 0.00010458746780667006),\n",
       " (('satisfaction', 'walking'), 0.00010458746780667006),\n",
       " (('selforganizing', 'map'), 0.00010458746780667006),\n",
       " (('shap', 'algorithm'), 0.00010458746780667006),\n",
       " (('shed', 'light'), 0.00010458746780667006),\n",
       " (('side', 'contributes'), 0.00010458746780667006),\n",
       " (('sidewalk', 'figure'), 0.00010458746780667006),\n",
       " (('singh', 'mohan'), 0.00010458746780667006),\n",
       " (('social', 'science'), 0.00010458746780667006),\n",
       " (('surrounding', 'environment'), 0.00010458746780667006),\n",
       " (('survey', 'data'), 0.00010458746780667006),\n",
       " (('table', 'show'), 0.00010458746780667006),\n",
       " (('tax', 'yield'), 0.00010458746780667006),\n",
       " (('term', 'direction'), 0.00010458746780667006),\n",
       " (('thought', 'think'), 0.00010458746780667006),\n",
       " (('ud', 'topic'), 0.00010458746780667006),\n",
       " (('un', 'supervised'), 0.00010458746780667006),\n",
       " (('understanding', 'city'), 0.00010458746780667006),\n",
       " (('unemployed', 'people'), 0.00010458746780667006),\n",
       " (('urban', 'ai'), 0.00010458746780667006),\n",
       " (('urban', 'analysis'), 0.00010458746780667006),\n",
       " (('urban', 'landuse'), 0.00010458746780667006),\n",
       " (('urban', 'policy'), 0.00010458746780667006),\n",
       " (('urban', 'vibrancy'), 0.00010458746780667006),\n",
       " (('used', 'computer'), 0.00010458746780667006),\n",
       " (('value', 'greater'), 0.00010458746780667006),\n",
       " (('view', 'service'), 0.00010458746780667006),\n",
       " (('within', 'pedestrian'), 0.00010458746780667006),\n",
       " (('yigitcanlar', 'etal'), 0.00010458746780667006),\n",
       " (('access', 'article'), 9.15140343308363e-05),\n",
       " (('ai', 'ai'), 9.15140343308363e-05),\n",
       " (('ai', 'general'), 9.15140343308363e-05),\n",
       " (('ai', 'system'), 9.15140343308363e-05),\n",
       " (('amman', 'jordan'), 9.15140343308363e-05),\n",
       " (('among', 'others'), 9.15140343308363e-05),\n",
       " (('amount', 'visual'), 9.15140343308363e-05),\n",
       " (('analysis', 'method'), 9.15140343308363e-05),\n",
       " (('application', 'computer'), 9.15140343308363e-05),\n",
       " (('applied', 'agedcare'), 9.15140343308363e-05),\n",
       " (('articially', 'intelligent'), 9.15140343308363e-05),\n",
       " (('asce', 'j'), 9.15140343308363e-05),\n",
       " (('based', 'data'), 9.15140343308363e-05),\n",
       " (('believe', 'financial'), 9.15140343308363e-05),\n",
       " (('braille', 'block'), 9.15140343308363e-05),\n",
       " (('brisbane', 'participant'), 9.15140343308363e-05),\n",
       " (('call', 'record'), 9.15140343308363e-05),\n",
       " (('care', 'disability'), 9.15140343308363e-05),\n",
       " (('category', 'application'), 9.15140343308363e-05),\n",
       " (('cellular', 'automaton'), 9.15140343308363e-05),\n",
       " (('challenge', 'uiip'), 9.15140343308363e-05),\n",
       " (('city', 'ai'), 9.15140343308363e-05),\n",
       " (('city', 'city'), 9.15140343308363e-05),\n",
       " (('city', 'model'), 9.15140343308363e-05),\n",
       " (('city', 'urban'), 9.15140343308363e-05),\n",
       " (('com', 'puter'), 9.15140343308363e-05),\n",
       " (('commercialising', 'ai'), 9.15140343308363e-05),\n",
       " (('connection', 'weight'), 9.15140343308363e-05),\n",
       " (('could', 'used'), 9.15140343308363e-05),\n",
       " (('creative', 'common'), 9.15140343308363e-05),\n",
       " (('crowdsourced', 'data'), 9.15140343308363e-05),\n",
       " (('data', 'analytics'), 9.15140343308363e-05),\n",
       " (('data', 'data'), 9.15140343308363e-05),\n",
       " (('data', 'science'), 9.15140343308363e-05),\n",
       " (('data', 'used'), 9.15140343308363e-05),\n",
       " (('decisionmaking', 'process'), 9.15140343308363e-05),\n",
       " (('dev', 'j'), 9.15140343308363e-05),\n",
       " (('develop', 'ment'), 9.15140343308363e-05),\n",
       " (('developing', 'commercialising'), 9.15140343308363e-05),\n",
       " (('dierent', 'type'), 9.15140343308363e-05),\n",
       " (('digital', 'twin'), 9.15140343308363e-05),\n",
       " (('dummy', 'variable'), 9.15140343308363e-05),\n",
       " (('environ', 'ment'), 9.15140343308363e-05),\n",
       " (('environment', 'street'), 9.15140343308363e-05),\n",
       " (('environmental', 'factor'), 9.15140343308363e-05),\n",
       " (('expert', 'system'), 9.15140343308363e-05),\n",
       " (('fully', 'autonomous'), 9.15140343308363e-05),\n",
       " (('future', 'smart'), 9.15140343308363e-05),\n",
       " (('future', 'use'), 9.15140343308363e-05),\n",
       " (('geoai', 'could'), 9.15140343308363e-05),\n",
       " (('german', 'city'), 9.15140343308363e-05),\n",
       " (('greenery', 'figure'), 9.15140343308363e-05),\n",
       " (('housing', 'homelessness'), 9.15140343308363e-05),\n",
       " (('image', 'complexity'), 9.15140343308363e-05),\n",
       " (('image', 'used'), 9.15140343308363e-05),\n",
       " (('improve', 'urban'), 9.15140343308363e-05),\n",
       " (('improving', 'quality'), 9.15140343308363e-05),\n",
       " (('information', 'science'), 9.15140343308363e-05),\n",
       " (('input', 'variable'), 9.15140343308363e-05),\n",
       " (('intelligent', 'entity'), 9.15140343308363e-05),\n",
       " (('issue', 'page'), 9.15140343308363e-05),\n",
       " (('know', 'ai'), 9.15140343308363e-05),\n",
       " (('knowledge', 'ai'), 9.15140343308363e-05),\n",
       " (('land', 'change'), 9.15140343308363e-05),\n",
       " (('landuse', 'change'), 9.15140343308363e-05),\n",
       " (('management', 'ai'), 9.15140343308363e-05),\n",
       " (('many', 'study'), 9.15140343308363e-05),\n",
       " (('map', 'service'), 9.15140343308363e-05),\n",
       " (('mcda', 'method'), 9.15140343308363e-05),\n",
       " (('mean', 'value'), 9.15140343308363e-05),\n",
       " (('measurement', 'vector'), 9.15140343308363e-05),\n",
       " (('method', 'urban'), 9.15140343308363e-05),\n",
       " (('model', 'urban'), 9.15140343308363e-05),\n",
       " (('nonlinear', 'relationship'), 9.15140343308363e-05),\n",
       " (('one', 'hand'), 9.15140343308363e-05),\n",
       " (('one', 'main'), 9.15140343308363e-05),\n",
       " (('openness', 'greenery'), 9.15140343308363e-05),\n",
       " (('parent', 'tree'), 9.15140343308363e-05),\n",
       " (('past', 'decade'), 9.15140343308363e-05),\n",
       " (('people', 'feel'), 9.15140343308363e-05),\n",
       " (('people', 'perception'), 9.15140343308363e-05),\n",
       " (('perception', 'difference'), 9.15140343308363e-05),\n",
       " (('personal', 'characteristic'), 9.15140343308363e-05),\n",
       " (('planning', 'domain'), 9.15140343308363e-05),\n",
       " (('planning', 'framework'), 9.15140343308363e-05),\n",
       " (('planning', 'process'), 9.15140343308363e-05),\n",
       " (('planning', 'strategy'), 9.15140343308363e-05),\n",
       " (('political', 'agenda'), 9.15140343308363e-05),\n",
       " (('precision', 'recall'), 9.15140343308363e-05),\n",
       " (('prediction', 'model'), 9.15140343308363e-05),\n",
       " (('prediction', 'urban'), 9.15140343308363e-05),\n",
       " (('present', 'future'), 9.15140343308363e-05),\n",
       " (('prior', 'knowledge'), 9.15140343308363e-05),\n",
       " (('priority', 'image'), 9.15140343308363e-05),\n",
       " (('problem', 'using'), 9.15140343308363e-05),\n",
       " (('quality', 'life'), 9.15140343308363e-05),\n",
       " (('quality', 'street'), 9.15140343308363e-05),\n",
       " (('realworld', 'urban'), 9.15140343308363e-05),\n",
       " (('relationship', 'walking'), 9.15140343308363e-05),\n",
       " (('reporting', 'anns'), 9.15140343308363e-05),\n",
       " (('research', 'direction'), 9.15140343308363e-05),\n",
       " (('research', 'gap'), 9.15140343308363e-05),\n",
       " (('review', 'metaanalysis'), 9.15140343308363e-05),\n",
       " (('rf', 'knn'), 9.15140343308363e-05),\n",
       " (('satisfaction', 'shap'), 9.15140343308363e-05),\n",
       " (('service', 'delivery'), 9.15140343308363e-05),\n",
       " (('sidewalk', 'number'), 9.15140343308363e-05),\n",
       " (('society', 'attribute'), 9.15140343308363e-05),\n",
       " (('south', 'korea'), 9.15140343308363e-05),\n",
       " (('street', 'network'), 9.15140343308363e-05),\n",
       " (('streetlevel', 'image'), 9.15140343308363e-05),\n",
       " (('study', 'finding'), 9.15140343308363e-05),\n",
       " (('subjectiveobjective', 'combined'), 9.15140343308363e-05),\n",
       " (('subway', 'station'), 9.15140343308363e-05),\n",
       " (('sun', 'axhausen'), 9.15140343308363e-05),\n",
       " (('survey', 'point'), 9.15140343308363e-05),\n",
       " (('technique', 'used'), 9.15140343308363e-05),\n",
       " (('term', 'ai'), 9.15140343308363e-05),\n",
       " (('traffic', 'flow'), 9.15140343308363e-05),\n",
       " (('type', 'data'), 9.15140343308363e-05),\n",
       " (('ul', 'technique'), 9.15140343308363e-05),\n",
       " (('understanding', 'public'), 9.15140343308363e-05),\n",
       " (('united', 'state'), 9.15140343308363e-05),\n",
       " (('urban', 'change'), 9.15140343308363e-05),\n",
       " (('urban', 'issue'), 9.15140343308363e-05),\n",
       " (('urban', 'model'), 9.15140343308363e-05),\n",
       " (('urban', 'problem'), 9.15140343308363e-05),\n",
       " (('urban', 'sprawl'), 9.15140343308363e-05),\n",
       " (('used', 'basic'), 9.15140343308363e-05),\n",
       " (('value', 'street'), 9.15140343308363e-05),\n",
       " (('vision', 'task'), 9.15140343308363e-05),\n",
       " (('vision', 'technique'), 9.15140343308363e-05),\n",
       " (('visual', 'perception'), 9.15140343308363e-05),\n",
       " (('volume', 'issue'), 9.15140343308363e-05),\n",
       " (('age', 'ai'), 7.844060085500255e-05),\n",
       " (('age', 'education'), 7.844060085500255e-05),\n",
       " (('aged', 'care'), 7.844060085500255e-05),\n",
       " (('ai', 'ability'), 7.844060085500255e-05),\n",
       " (('ai', 'algorithm'), 7.844060085500255e-05),\n",
       " (('ai', 'could'), 7.844060085500255e-05),\n",
       " (('ai', 'decision'), 7.844060085500255e-05),\n",
       " (('ai', 'deployment'), 7.844060085500255e-05),\n",
       " (('ai', 'education'), 7.844060085500255e-05),\n",
       " (('ai', 'model'), 7.844060085500255e-05),\n",
       " (('ai', 'workplace'), 7.844060085500255e-05),\n",
       " (('aibased', 'service'), 7.844060085500255e-05),\n",
       " (('algorithm', 'computer'), 7.844060085500255e-05),\n",
       " (('allowed', 'u'), 7.844060085500255e-05),\n",
       " (('also', 'known'), 7.844060085500255e-05),\n",
       " (('anns', 'performance'), 7.844060085500255e-05),\n",
       " (('appendix', 'b'), 7.844060085500255e-05),\n",
       " (('application', 'city'), 7.844060085500255e-05),\n",
       " (('application', 'urban'), 7.844060085500255e-05),\n",
       " (('approach', 'urban'), 7.844060085500255e-05),\n",
       " (('associated', 'urban'), 7.844060085500255e-05),\n",
       " (('attitude', 'towards'), 7.844060085500255e-05),\n",
       " (('attribute', 'data'), 7.844060085500255e-05),\n",
       " (('auc', 'score'), 7.844060085500255e-05),\n",
       " (('autonomous', 'place'), 7.844060085500255e-05),\n",
       " (('available', 'sciencedirect'), 7.844060085500255e-05),\n",
       " (('b', 'r'), 7.844060085500255e-05),\n",
       " (('basic', 'data'), 7.844060085500255e-05),\n",
       " (('behind', 'public'), 7.844060085500255e-05),\n",
       " (('benchmark', 'datasets'), 7.844060085500255e-05),\n",
       " (('best', 'model'), 7.844060085500255e-05),\n",
       " (('binary', 'classification'), 7.844060085500255e-05),\n",
       " (('bootstrapped', 'average'), 7.844060085500255e-05),\n",
       " (('broad', 'range'), 7.844060085500255e-05),\n",
       " (('c', 'l'), 7.844060085500255e-05),\n",
       " (('car', 'robot'), 7.844060085500255e-05),\n",
       " (('carbon', 'emission'), 7.844060085500255e-05),\n",
       " (('challenge', 'associated'), 7.844060085500255e-05),\n",
       " (('challenging', 'area'), 7.844060085500255e-05),\n",
       " (('clarity', 'digital'), 7.844060085500255e-05),\n",
       " (('classication', 'prediction'), 7.844060085500255e-05),\n",
       " (('classification', 'logistic'), 7.844060085500255e-05),\n",
       " (('commonly', 'used'), 7.844060085500255e-05),\n",
       " (('commonsocial', 'good'), 7.844060085500255e-05),\n",
       " (('community', 'participation'), 7.844060085500255e-05),\n",
       " (('community', 'support'), 7.844060085500255e-05),\n",
       " (('complex', 'problem'), 7.844060085500255e-05),\n",
       " (('conceptual', 'framework'), 7.844060085500255e-05),\n",
       " (('concerned', 'ai'), 7.844060085500255e-05),\n",
       " (('content', 'list'), 7.844060085500255e-05),\n",
       " (('contrast', 'participant'), 7.844060085500255e-05),\n",
       " (('convolutional', 'neural'), 7.844060085500255e-05),\n",
       " (('country', 'context'), 7.844060085500255e-05),\n",
       " (('critical', 'gi'), 7.844060085500255e-05),\n",
       " (('customer', 'service'), 7.844060085500255e-05),\n",
       " (('data', 'complexity'), 7.844060085500255e-05),\n",
       " (('data', 'curation'), 7.844060085500255e-05),\n",
       " (('data', 'structure'), 7.844060085500255e-05),\n",
       " (('data', 'study'), 7.844060085500255e-05),\n",
       " (('decision', 'analysis'), 7.844060085500255e-05),\n",
       " (('deploy', 'ai'), 7.844060085500255e-05),\n",
       " (('describes', 'visual'), 7.844060085500255e-05),\n",
       " (('dierent', 'layer'), 7.844060085500255e-05),\n",
       " (('digital', 'visual'), 7.844060085500255e-05),\n",
       " (('disadvantaged', 'community'), 7.844060085500255e-05),\n",
       " (('disaster', 'awareness'), 7.844060085500255e-05),\n",
       " (('driver', 'ai'), 7.844060085500255e-05),\n",
       " (('driver', 'behind'), 7.844060085500255e-05),\n",
       " (('due', 'lack'), 7.844060085500255e-05),\n",
       " (('dynamic', 'urban'), 7.844060085500255e-05),\n",
       " (('e', 'n'), 7.844060085500255e-05),\n",
       " (('early', 'warning'), 7.844060085500255e-05),\n",
       " (('economic', 'growth'), 7.844060085500255e-05),\n",
       " (('ecosystem', 'service'), 7.844060085500255e-05),\n",
       " (('edge', 'extracted'), 7.844060085500255e-05),\n",
       " (('email', 'address'), 7.844060085500255e-05),\n",
       " (('engagement', 'aibased'), 7.844060085500255e-05),\n",
       " (('entire', 'city'), 7.844060085500255e-05),\n",
       " (('environment', 'characteristic'), 7.844060085500255e-05),\n",
       " (('environmental', 'study'), 7.844060085500255e-05),\n",
       " (('facility', 'service'), 7.844060085500255e-05),\n",
       " (('factor', 'improving'), 7.844060085500255e-05),\n",
       " (('factor', 'street'), 7.844060085500255e-05),\n",
       " (('feng', 'liu'), 7.844060085500255e-05),\n",
       " (('figure', 'figure'), 7.844060085500255e-05),\n",
       " (('free', 'time'), 7.844060085500255e-05),\n",
       " (('g', 'mcts'), 7.844060085500255e-05),\n",
       " (('generate', 'new'), 7.844060085500255e-05),\n",
       " (('generative', 'model'), 7.844060085500255e-05),\n",
       " (('geospatial', 'articial'), 7.844060085500255e-05),\n",
       " (('gmcts', 'method'), 7.844060085500255e-05),\n",
       " (('goal', 'goal'), 7.844060085500255e-05),\n",
       " (('good', 'community'), 7.844060085500255e-05),\n",
       " (('government', 'ai'), 7.844060085500255e-05),\n",
       " (('government', 'context'), 7.844060085500255e-05),\n",
       " (('grey', 'area'), 7.844060085500255e-05),\n",
       " (('growth', 'urban'), 7.844060085500255e-05),\n",
       " (('help', 'increasing'), 7.844060085500255e-05),\n",
       " (('hierarchical', 'clustering'), 7.844060085500255e-05),\n",
       " (('huang', 'li'), 7.844060085500255e-05),\n",
       " (('human', 'goal'), 7.844060085500255e-05),\n",
       " (('human', 'life'), 7.844060085500255e-05),\n",
       " (('humanoid', 'robot'), 7.844060085500255e-05),\n",
       " (('image', 'figure'), 7.844060085500255e-05),\n",
       " (('importance', 'variable'), 7.844060085500255e-05),\n",
       " (('input', 'layer'), 7.844060085500255e-05),\n",
       " (('integrated', 'urban'), 7.844060085500255e-05),\n",
       " (('intelligent', 'human'), 7.844060085500255e-05),\n",
       " (('interacted', 'ai'), 7.844060085500255e-05),\n",
       " (('interest', 'author'), 7.844060085500255e-05),\n",
       " (('invade', 'privacy'), 7.844060085500255e-05),\n",
       " (('journal', 'homepage'), 7.844060085500255e-05),\n",
       " (('kernel', 'probability'), 7.844060085500255e-05),\n",
       " (('knowledge', 'gap'), 7.844060085500255e-05),\n",
       " (('l', 'e'), 7.844060085500255e-05),\n",
       " (('layer', 'output'), 7.844060085500255e-05),\n",
       " (('learning', 'deep'), 7.844060085500255e-05),\n",
       " (('limited', 'financial'), 7.844060085500255e-05),\n",
       " (('list', 'available'), 7.844060085500255e-05),\n",
       " (('local', 'authority'), 7.844060085500255e-05),\n",
       " (('low', 'probability'), 7.844060085500255e-05),\n",
       " (('made', 'possible'), 7.844060085500255e-05),\n",
       " (('many', 'people'), 7.844060085500255e-05),\n",
       " (('measured', 'complexity'), 7.844060085500255e-05),\n",
       " (('mediumhigh', 'income'), 7.844060085500255e-05),\n",
       " (('method', 'study'), 7.844060085500255e-05),\n",
       " (('metropolitan', 'area'), 7.844060085500255e-05),\n",
       " (('model', 'shap'), 7.844060085500255e-05),\n",
       " (('model', 'used'), 7.844060085500255e-05),\n",
       " (('monitor', 'urban'), 7.844060085500255e-05),\n",
       " (('n', 'f'), 7.844060085500255e-05),\n",
       " (('n', 'n'), 7.844060085500255e-05),\n",
       " (('na', 'na'), 7.844060085500255e-05),\n",
       " (('new', 'form'), 7.844060085500255e-05),\n",
       " (('north', 'america'), 7.844060085500255e-05),\n",
       " (('number', 'state'), 7.844060085500255e-05),\n",
       " (('oh', 'kim'), 7.844060085500255e-05),\n",
       " (('optimization', 'model'), 7.844060085500255e-05),\n",
       " (('output', 'layer'), 7.844060085500255e-05),\n",
       " (('overall', 'satisfaction'), 7.844060085500255e-05),\n",
       " (('past', 'present'), 7.844060085500255e-05),\n",
       " (('people', 'view'), 7.844060085500255e-05),\n",
       " (('performance', 'machinelearning'), 7.844060085500255e-05),\n",
       " (('performance', 'model'), 7.844060085500255e-05),\n",
       " (('planner', 'policymakers'), 7.844060085500255e-05),\n",
       " (('planning', 'case'), 7.844060085500255e-05),\n",
       " (('planning', 'decision'), 7.844060085500255e-05),\n",
       " (('planning', 'discipline'), 7.844060085500255e-05),\n",
       " (('planning', 'practice'), 7.844060085500255e-05),\n",
       " (('planning', 'volume'), 7.844060085500255e-05),\n",
       " (('plot', 'show'), 7.844060085500255e-05),\n",
       " (('positive', 'negative'), 7.844060085500255e-05),\n",
       " (('postgraduate', 'degree'), 7.844060085500255e-05),\n",
       " (('previous', 'study'), 7.844060085500255e-05),\n",
       " (('pro', 'ce'), 7.844060085500255e-05),\n",
       " (('probability', 'density'), 7.844060085500255e-05),\n",
       " (('public', 'participation'), 7.844060085500255e-05),\n",
       " (('public', 'space'), 7.844060085500255e-05),\n",
       " (('purpose', 'passage'), 7.844060085500255e-05),\n",
       " (('puter', 'vision'), 7.844060085500255e-05),\n",
       " (('queensland', 'university'), 7.844060085500255e-05),\n",
       " (('regional', 'study'), 7.844060085500255e-05),\n",
       " (('research', 'area'), 7.844060085500255e-05),\n",
       " (('research', 'design'), 7.844060085500255e-05),\n",
       " (('result', 'shap'), 7.844060085500255e-05),\n",
       " (('result', 'show'), 7.844060085500255e-05),\n",
       " (('result', 'study'), 7.844060085500255e-05),\n",
       " (('road', 'type'), 7.844060085500255e-05),\n",
       " (('roc', 'curve'), 7.844060085500255e-05),\n",
       " (('rst', 'step'), 7.844060085500255e-05),\n",
       " (('satellite', 'imagery'), 7.844060085500255e-05),\n",
       " (('section', 'discus'), 7.844060085500255e-05),\n",
       " (('see', 'section'), 7.844060085500255e-05),\n",
       " (('semiindustrial', 'area'), 7.844060085500255e-05),\n",
       " (('shallow', 'anns'), 7.844060085500255e-05),\n",
       " (('shap', 'analysis'), 7.844060085500255e-05),\n",
       " (('show', 'variable'), 7.844060085500255e-05),\n",
       " (('sleuth', 'model'), 7.844060085500255e-05),\n",
       " (('spatial', 'arrangement'), 7.844060085500255e-05),\n",
       " (('study', 'conducted'), 7.844060085500255e-05),\n",
       " (('support', 'engagement'), 7.844060085500255e-05),\n",
       " (('svm', 'mlp'), 7.844060085500255e-05),\n",
       " (('system', 'security'), 7.844060085500255e-05),\n",
       " (('take', 'place'), 7.844060085500255e-05),\n",
       " (('thematic', 'breakdown'), 7.844060085500255e-05),\n",
       " (('total', 'number'), 7.844060085500255e-05),\n",
       " (('towards', 'ai'), 7.844060085500255e-05),\n",
       " (('transit', 'accessibility'), 7.844060085500255e-05),\n",
       " (('transport', 'mode'), 7.844060085500255e-05),\n",
       " (('trust', 'citizen'), 7.844060085500255e-05),\n",
       " (('unsu', 'pervised'), 7.844060085500255e-05),\n",
       " (('urban', 'fabric'), 7.844060085500255e-05),\n",
       " (('urban', 'regional'), 7.844060085500255e-05),\n",
       " (('urban', 'research'), 7.844060085500255e-05),\n",
       " (('urbanization', 'regional'), 7.844060085500255e-05),\n",
       " (('urbanized', 'area'), 7.844060085500255e-05),\n",
       " (('used', 'commonsocial'), 7.844060085500255e-05),\n",
       " (('used', 'invade'), 7.844060085500255e-05),\n",
       " (('value', 'sustainability'), 7.844060085500255e-05),\n",
       " (('view', 'imagery'), 7.844060085500255e-05),\n",
       " (('vision', 'application'), 7.844060085500255e-05),\n",
       " (('visual', 'abundance'), 7.844060085500255e-05),\n",
       " (('visual', 'analysis'), 7.844060085500255e-05),\n",
       " (('visual', 'information'), 7.844060085500255e-05),\n",
       " (('visual', 'tool'), 7.844060085500255e-05),\n",
       " (('wang', 'yang'), 7.844060085500255e-05),\n",
       " (('water', 'management'), 7.844060085500255e-05),\n",
       " (('web', 'science'), 7.844060085500255e-05),\n",
       " (('ye', 'chen'), 7.844060085500255e-05),\n",
       " (('across', 'city'), 6.536716737916879e-05),\n",
       " (('action', 'step'), 6.536716737916879e-05),\n",
       " (('activation', 'function'), 6.536716737916879e-05),\n",
       " (('adoption', 'ai'), 6.536716737916879e-05),\n",
       " (('agency', 'using'), 6.536716737916879e-05),\n",
       " (('agent', 'could'), 6.536716737916879e-05),\n",
       " (('agent', 'interaction'), 6.536716737916879e-05),\n",
       " (('ai', 'also'), 6.536716737916879e-05),\n",
       " (('ai', 'approach'), 6.536716737916879e-05),\n",
       " (('ai', 'development'), 6.536716737916879e-05),\n",
       " (('ai', 'method'), 6.536716737916879e-05),\n",
       " (('ai', 'utilization'), 6.536716737916879e-05),\n",
       " (('also', 'used'), 6.536716737916879e-05),\n",
       " (('among', 'many'), 6.536716737916879e-05),\n",
       " (('amount', 'greenery'), 6.536716737916879e-05),\n",
       " (('amount', 'private'), 6.536716737916879e-05),\n",
       " (('analysis', 'uiip'), 6.536716737916879e-05),\n",
       " (('anns', 'performed'), 6.536716737916879e-05),\n",
       " (('appendix', 'part'), 6.536716737916879e-05),\n",
       " (('architecture', 'hyperparameters'), 6.536716737916879e-05),\n",
       " (('area', 'city'), 6.536716737916879e-05),\n",
       " (('area', 'ensure'), 6.536716737916879e-05),\n",
       " (('around', 'world'), 6.536716737916879e-05),\n",
       " (('aspect', 'urban'), 6.536716737916879e-05),\n",
       " (('author', 'declare'), 6.536716737916879e-05),\n",
       " (('autonomous', 'vehicle'), 6.536716737916879e-05),\n",
       " (('bare', 'land'), 6.536716737916879e-05),\n",
       " (('behavior', 'pattern'), 6.536716737916879e-05),\n",
       " (('better', 'understanding'), 6.536716737916879e-05),\n",
       " (('block', 'fence'), 6.536716737916879e-05),\n",
       " (('blue', 'bar'), 6.536716737916879e-05),\n",
       " (('building', 'footprint'), 6.536716737916879e-05),\n",
       " (('c', 'c'), 6.536716737916879e-05),\n",
       " (('car', 'accident'), 6.536716737916879e-05),\n",
       " (('category', 'urban'), 6.536716737916879e-05),\n",
       " (('causal', 'relationship'), 6.536716737916879e-05),\n",
       " (('chal', 'lenges'), 6.536716737916879e-05),\n",
       " (('challenge', 'remain'), 6.536716737916879e-05),\n",
       " (('change', 'city'), 6.536716737916879e-05),\n",
       " (('characteristic', 'affect'), 6.536716737916879e-05),\n",
       " (('characteristic', 'neighborhood'), 6.536716737916879e-05),\n",
       " (('city', 'planner'), 6.536716737916879e-05),\n",
       " (('clarity', 'ifhow'), 6.536716737916879e-05),\n",
       " (('class', 'ii'), 6.536716737916879e-05),\n",
       " (('climate', 'change'), 6.536716737916879e-05),\n",
       " (('climate', 'crisis'), 6.536716737916879e-05),\n",
       " (('clustering', 'others'), 6.536716737916879e-05),\n",
       " (('communicative', 'construction'), 6.536716737916879e-05),\n",
       " (('community', 'addressed'), 6.536716737916879e-05),\n",
       " (('community', 'ai'), 6.536716737916879e-05),\n",
       " (('comparing', 'performance'), 6.536716737916879e-05),\n",
       " (('complex', 'data'), 6.536716737916879e-05),\n",
       " (('complex', 'system'), 6.536716737916879e-05),\n",
       " (('complexity', 'complexity'), 6.536716737916879e-05),\n",
       " (('complexity', 'openness'), 6.536716737916879e-05),\n",
       " (('concept', 'ai'), 6.536716737916879e-05),\n",
       " (('conflict', 'interest'), 6.536716737916879e-05),\n",
       " (('conservation', 'heritage'), 6.536716737916879e-05),\n",
       " (('construction', 'location'), 6.536716737916879e-05),\n",
       " (('control', 'monitoring'), 6.536716737916879e-05),\n",
       " (('conventional', 'method'), 6.536716737916879e-05),\n",
       " (('critical', 'urban'), 6.536716737916879e-05),\n",
       " (('cronbachs', 'alpha'), 6.536716737916879e-05),\n",
       " (('da', 'neu'), 6.536716737916879e-05),\n",
       " (('da', 'neutral'), 6.536716737916879e-05),\n",
       " (('da', 'ra'), 6.536716737916879e-05),\n",
       " (('daily', 'life'), 6.536716737916879e-05),\n",
       " (('data', 'analysis'), 6.536716737916879e-05),\n",
       " (('data', 'based'), 6.536716737916879e-05),\n",
       " (('data', 'derived'), 6.536716737916879e-05),\n",
       " (('data', 'point'), 6.536716737916879e-05),\n",
       " (('data', 'programmed'), 6.536716737916879e-05),\n",
       " (('data', 'well'), 6.536716737916879e-05),\n",
       " (('density', 'estimate'), 6.536716737916879e-05),\n",
       " (('destroy', 'humanity'), 6.536716737916879e-05),\n",
       " (('detection', 'figure'), 6.536716737916879e-05),\n",
       " (('development', 'control'), 6.536716737916879e-05),\n",
       " (('development', 'urban'), 6.536716737916879e-05),\n",
       " (('dierent', 'scenario'), 6.536716737916879e-05),\n",
       " (('digital', 'medium'), 6.536716737916879e-05),\n",
       " (('dimensionality', 'reduction'), 6.536716737916879e-05),\n",
       " (('dis', 'aster'), 6.536716737916879e-05),\n",
       " (('disagree', 'agree'), 6.536716737916879e-05),\n",
       " (('disaster', 'providing'), 6.536716737916879e-05),\n",
       " (('disasteremergency', 'prediction'), 6.536716737916879e-05),\n",
       " (('disasterrelated', 'information'), 6.536716737916879e-05),\n",
       " (('disruption', 'disadvantaged'), 6.536716737916879e-05),\n",
       " (('domain', 'urban'), 6.536716737916879e-05),\n",
       " (('due', 'complexity'), 6.536716737916879e-05),\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder(word_fd, bigram_fd)\n",
    "finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional File Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for f in glob.glob(\"Document_*\"):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vt_tm] *",
   "language": "python",
   "name": "conda-env-vt_tm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

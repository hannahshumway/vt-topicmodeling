{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Basic Text Analysis - Topic Modeling Pt. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1. Zotero API + PDF Text Miner\n",
    "We need this so we don't have to bring down all of the pdfs in our library to our local machines, and we can always run our data prep on the most up-to-date corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pdf2image import convert_from_path\n",
    "import ftfy\n",
    "import nltk.corpus\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import models, corpora\n",
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "import pprint\n",
    "import datetime\n",
    "import glob\n",
    "import urllib.request\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoteroCrawler(key, groupid):\n",
    "    multiplier = 0\n",
    "    zoterogroup = []\n",
    "    # get number of items in group\n",
    "    headers = {\"Zotero-API-Version\":\"3\",'Connection':'close', \"Zotero-API-Key\":key}\n",
    "    checkurl = \"https://api.zotero.org/groups/\" +groupid\n",
    "    rcheck = requests.get(checkurl, headers=headers)\n",
    "    items = rcheck.json()['meta']['numItems']\n",
    "    print(items)\n",
    "    pages = math.ceil((items/100))\n",
    "    while pages > 0:\n",
    "        url = \"https://api.zotero.org/groups/\" +groupid + \"/items\" + \"?limit=100&start=\" + str(multiplier)\n",
    "        print(url)\n",
    "        r = requests.get(url, headers=headers)\n",
    "        rj = r.json() #jsonified version of our Zotero group\n",
    "        print(len(rj))\n",
    "        for i in rj:\n",
    "            zoterogroup.append(i)\n",
    "        multiplier = multiplier + 100\n",
    "        pages = pages - 1\n",
    "    return zoterogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"N6yPwqH9VQFt8ZKBKCAFf8KV\"\n",
    "group_id = \"2808857\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=0\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=100\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=200\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=300\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=400\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=500\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=600\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=700\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=800\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=900\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=1000\n",
      "100\n",
      "https://api.zotero.org/groups/2808857/items?limit=100&start=1100\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "rj= zoteroCrawler(api_key, group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)    \n",
    "    file = open(filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# now what? get the attachments\n",
    "# inputs are jsonified version of your zotero group, base url to zotero group items, and api key\n",
    "# going to have to loop through and run this for every page I think\n",
    "def attachmentGrabber(rj, url, key):\n",
    "    counter = 0\n",
    "    to_extract = []\n",
    "    citation_list = []\n",
    "    for i in rj:\n",
    "        if counter < 100:\n",
    "            try:\n",
    "                item_key = rj[counter][\"key\"]\n",
    "                headers = {\"Zotero-API-Version\":\"3\",'Connection':'close', \"Zotero-API-Key\":key}\n",
    "                attach = requests.get(url + item_key + \"/file\", headers=headers)\n",
    "                if \"200\" in str(attach):\n",
    "                    download_file(attach.url, f'Document_{item_key}')\n",
    "                    to_extract.append(f'Document_{item_key}.pdf')\n",
    "                    print(\"GOOD\" + \" 1 \" + str(item_key))\n",
    "                else:\n",
    "                    attach = requests.get(rj[counter]['links']['attachment']['href'] + \"/file\", headers=headers)\n",
    "                    print(attach)\n",
    "                    if \"200\" in str(attach):\n",
    "                        download_file(attach.url, f'Document_{item_key}')\n",
    "                        to_extract.append(f'Document_{item_key}.pdf')\n",
    "                        print(\"GOOD\" + \" \" + str(item_key))\n",
    "                    else:\n",
    "                        print(\"that didn't work\" + \" \" + attach.url)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            counter +=1\n",
    "    return to_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOD 1 47GCMTBN\n",
      "<Response [200]>\n",
      "GOOD 3X676VED\n",
      "GOOD 1 QCQS4ST2\n",
      "<Response [200]>\n",
      "GOOD JBHVWUZE\n",
      "<Response [200]>\n",
      "GOOD JI4B2NX5\n",
      "GOOD 1 P3ZBU43W\n",
      "<Response [200]>\n",
      "GOOD JFQB362K\n",
      "GOOD 1 DUDUGGU3\n",
      "<Response [200]>\n",
      "GOOD TMZ5ADAT\n",
      "GOOD 1 TF4SN283\n",
      "<Response [200]>\n",
      "GOOD RU3DU96U\n",
      "GOOD 1 M22IF67B\n",
      "<Response [200]>\n",
      "GOOD XRPE4C5V\n",
      "GOOD 1 DSCUFYAG\n",
      "<Response [200]>\n",
      "GOOD A72X8Q5P\n",
      "GOOD 1 DHKVRINE\n",
      "<Response [200]>\n",
      "GOOD UW8IXCF9\n",
      "GOOD 1 6ES6XHAP\n",
      "<Response [200]>\n",
      "GOOD KW9E2UTE\n",
      "GOOD 1 MWQEBJBU\n",
      "<Response [200]>\n",
      "GOOD 79SRZNQ3\n",
      "GOOD 1 FPBF5IKX\n",
      "<Response [200]>\n",
      "GOOD J7HBXYBQ\n",
      "GOOD 1 2LRB28HQ\n",
      "GOOD 1 SX39863M\n",
      "<Response [200]>\n",
      "GOOD 9JV4R9EW\n",
      "GOOD 1 Q73YL96D\n",
      "GOOD 1 XVX4XMR2\n",
      "<Response [200]>\n",
      "GOOD PKB9CB7I\n",
      "<Response [200]>\n",
      "GOOD 7TIFU594\n",
      "GOOD 1 TAAJRZEP\n",
      "GOOD 1 RH5JP7XX\n",
      "GOOD 1 LTZN6E4P\n",
      "<Response [200]>\n",
      "GOOD D6YVIFBC\n",
      "GOOD 1 3E578E54\n",
      "GOOD 1 IB7PWZVG\n",
      "GOOD 1 TMFT472T\n",
      "GOOD 1 YJRJLQSA\n",
      "<Response [200]>\n",
      "GOOD UTLT344I\n",
      "<Response [200]>\n",
      "GOOD DMKRZS8E\n",
      "<Response [200]>\n",
      "GOOD ZFPUQZNE\n",
      "<Response [200]>\n",
      "HTTP Error 403: Forbidden\n",
      "<Response [200]>\n",
      "GOOD G4923VSV\n",
      "<Response [200]>\n",
      "HTTP Error 403: Forbidden\n",
      "<Response [200]>\n",
      "GOOD EV273D9P\n",
      "<Response [200]>\n",
      "GOOD PDUA89RL\n",
      "<Response [200]>\n",
      "GOOD VZGACXNN\n",
      "<Response [200]>\n",
      "GOOD YGFJAA5F\n",
      "<Response [200]>\n",
      "GOOD KN8U5AXF\n",
      "<Response [200]>\n",
      "GOOD NDH25D7X\n",
      "<Response [200]>\n",
      "GOOD BM6L3JUC\n",
      "<Response [200]>\n",
      "GOOD TJR42XC5\n",
      "<Response [200]>\n",
      "GOOD RSB2STPR\n",
      "<Response [200]>\n",
      "GOOD 3JVVCGH6\n",
      "<Response [200]>\n",
      "GOOD 334IKY7D\n",
      "<Response [200]>\n",
      "GOOD NDTF8ZQG\n",
      "<Response [200]>\n",
      "GOOD UR68UWWC\n",
      "<Response [200]>\n",
      "GOOD P7ZQXA49\n",
      "<Response [200]>\n",
      "GOOD HE9X7NKT\n",
      "<Response [200]>\n",
      "GOOD 4S7CU23C\n",
      "<Response [200]>\n",
      "GOOD QKHD29TS\n",
      "<Response [200]>\n",
      "GOOD NYRUWCRI\n",
      "<Response [200]>\n",
      "GOOD 5H6TVKRX\n",
      "<Response [200]>\n",
      "GOOD WSFZDI5V\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "<Response [200]>\n",
      "GOOD J5WD5TBV\n",
      "<Response [200]>\n",
      "GOOD ZH6G29C7\n",
      "<Response [200]>\n",
      "GOOD PGPVWJGT\n",
      "<Response [200]>\n",
      "GOOD 8MUZLDEB\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "<Response [200]>\n",
      "GOOD REYPV3ZC\n",
      "<Response [200]>\n",
      "GOOD J2HMCSYG\n",
      "<Response [200]>\n",
      "GOOD WE83RECQ\n",
      "<Response [200]>\n",
      "GOOD P6HD9YXC\n",
      "<Response [200]>\n",
      "GOOD CP48TTDC\n",
      "<Response [200]>\n",
      "GOOD CI6ZIKFF\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "<Response [200]>\n",
      "GOOD ZLF6SLHS\n",
      "<Response [200]>\n",
      "GOOD AB4GLPL8\n",
      "<Response [200]>\n",
      "GOOD AP5DVV5Z\n",
      "<Response [200]>\n",
      "GOOD I64NHKAU\n",
      "<Response [200]>\n",
      "GOOD R5MQWTF6\n",
      "<Response [200]>\n",
      "GOOD AM87JDAZ\n",
      "<Response [200]>\n",
      "GOOD 9TTYWUNW\n",
      "<Response [200]>\n",
      "GOOD H5FD5NJN\n",
      "<Response [200]>\n",
      "GOOD YJ2Z9CDU\n",
      "<Response [200]>\n",
      "GOOD K92VUF7U\n",
      "<Response [200]>\n",
      "GOOD NBEFP27R\n",
      "<Response [200]>\n",
      "GOOD XJZTU57V\n",
      "<Response [200]>\n",
      "GOOD C8WB7LEN\n",
      "<Response [200]>\n",
      "GOOD 2JGSDMU8\n",
      "<Response [200]>\n",
      "GOOD 6LZN3M3H\n",
      "<Response [200]>\n",
      "GOOD ECWZZCYD\n",
      "<Response [200]>\n",
      "GOOD DI5M2UVW\n",
      "<Response [200]>\n",
      "GOOD NA63NB35\n",
      "<Response [200]>\n",
      "GOOD QIHZDINR\n",
      "<Response [200]>\n",
      "GOOD 266KRB6Z\n",
      "<Response [200]>\n",
      "GOOD QWHY5CPT\n",
      "<Response [200]>\n",
      "GOOD RK8DMZHV\n",
      "<Response [200]>\n",
      "GOOD 76RTMKVS\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.zotero.org/groups/2808857/items/\"\n",
    "to_extract  = attachmentGrabber(rj, url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('to_extract_backup.txt', 'w') as f:\n",
    " #   f.write(json.dumps(to_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('to_extract_backup.txt', 'r', encoding='utf-8') as f:\n",
    " #   data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_extract = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attachments have been procured. Let's do something with them. Thanks to [PDF Text Miner](https://github.com/prldc/pdf_text_miner) for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_pdfs(list):  # You can easily extract a list from a .csv with pandas.\n",
    "    d = {'file_name': ['dummy'], 'file_text': ['dummy'], 'ocr': [False]}\n",
    "    df = pd.DataFrame(d, columns=['file_name', 'file_text', 'ocr'])\n",
    "    count = 1\n",
    "    for pdf in list:\n",
    "        try:\n",
    "            ext = os.path.splitext(pdf)[1][1:].strip()  # Gets file extension.\n",
    "            if ext == 'pdf':  # Guarantees that the file is a .pdf, otherwise the program will crash when extracting text.\n",
    "                ocr = False\n",
    "                name = pdf.split('.pdf')[0]\n",
    "                doc = fitz.open(f\"{name}.pdf\")\n",
    "                text_file = open(f\"{name}.txt\", 'w')\n",
    "                number_of_pages = doc.page_count\n",
    "                for page_n in range(number_of_pages):  # Extracts text from each page.\n",
    "                    page = doc.load_page(page_n)\n",
    "                    page_content = page.get_text(\"text\")\n",
    "                    text_file.write(page_content)\n",
    "                if os.stat(\n",
    "                        f\"{name}.txt\").st_size < 2000:  # Assumes file lacks OCR based on .txt file size, starts Tesseract.\n",
    "                    ocr = True\n",
    "                    os.remove(f\"{name}.txt\")  # Removes the previously scraped .txt.\n",
    "                    tess_file = f\"{name}.pdf\"\n",
    "                    pages = convert_from_path(tess_file, 500)\n",
    "                    image_counter = 1\n",
    "                    for page in pages:  # Converts the PDF to image.\n",
    "                        filename = f\"{name}page_{str(image_counter)}.jpg\"\n",
    "                        page.save(filename, 'JPEG')\n",
    "                        image_counter = image_counter + 1\n",
    "                    filelimit = image_counter - 1\n",
    "                    outfile = f\"{name}.txt\"\n",
    "                    f = open(outfile, \"a\")\n",
    "                    for i in range(1, filelimit + 1):  # Applies OCR to each image, saves text file.\n",
    "                        filename = f\"{name}page_{str(i)}.jpg\"\n",
    "                        text = str((pytesseract.image_to_string(Image.open(filename), lang=\"por\")))\n",
    "                        text = text.replace('-\\n', '')\n",
    "                        f.write(text)\n",
    "                    f.close()\n",
    "                text = open(f\"{name}.txt\", 'r')\n",
    "                txt = \" \".join(text.readlines())\n",
    "                df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)    \n",
    "                end = datetime.datetime.now()\n",
    "                print(\n",
    "                    f\"Finished {name} at {end}. OCR = {ocr}. {count} files read. {round(count * 100 / len(list), 2)}% done.\")\n",
    "        except Exception as e:\n",
    "            print(f'Did not finish {pdf}... check out that one.')\n",
    "            print(e)\n",
    "        count = count + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_47GCMTBN at 2023-03-12 21:17:38.149271. OCR = False. 1 files read. 1.05% done.\n",
      "Finished Document_3X676VED at 2023-03-12 21:17:38.225014. OCR = False. 2 files read. 2.11% done.\n",
      "Finished Document_QCQS4ST2 at 2023-03-12 21:17:38.348600. OCR = False. 3 files read. 3.16% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_JBHVWUZE at 2023-03-12 21:17:38.431438. OCR = False. 4 files read. 4.21% done.\n",
      "Finished Document_JI4B2NX5 at 2023-03-12 21:17:38.481473. OCR = False. 5 files read. 5.26% done.\n",
      "Finished Document_P3ZBU43W at 2023-03-12 21:17:38.553210. OCR = False. 6 files read. 6.32% done.\n",
      "Finished Document_JFQB362K at 2023-03-12 21:17:38.616059. OCR = False. 7 files read. 7.37% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_DUDUGGU3 at 2023-03-12 21:17:38.701947. OCR = False. 8 files read. 8.42% done.\n",
      "Finished Document_TMZ5ADAT at 2023-03-12 21:17:38.780565. OCR = False. 9 files read. 9.47% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_TF4SN283 at 2023-03-12 21:17:39.103099. OCR = False. 10 files read. 10.53% done.\n",
      "Finished Document_RU3DU96U at 2023-03-12 21:17:39.237380. OCR = False. 11 files read. 11.58% done.\n",
      "Finished Document_M22IF67B at 2023-03-12 21:17:39.297298. OCR = False. 12 files read. 12.63% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_XRPE4C5V at 2023-03-12 21:17:39.359673. OCR = False. 13 files read. 13.68% done.\n",
      "Finished Document_DSCUFYAG at 2023-03-12 21:17:39.446093. OCR = False. 14 files read. 14.74% done.\n",
      "Finished Document_A72X8Q5P at 2023-03-12 21:17:39.549448. OCR = False. 15 files read. 15.79% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_DHKVRINE at 2023-03-12 21:17:39.636784. OCR = False. 16 files read. 16.84% done.\n",
      "Finished Document_UW8IXCF9 at 2023-03-12 21:17:39.732200. OCR = False. 17 files read. 17.89% done.\n",
      "Finished Document_6ES6XHAP at 2023-03-12 21:17:39.814228. OCR = False. 18 files read. 18.95% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_KW9E2UTE at 2023-03-12 21:17:39.899996. OCR = False. 19 files read. 20.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_MWQEBJBU at 2023-03-12 21:17:40.220044. OCR = False. 20 files read. 21.05% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_79SRZNQ3 at 2023-03-12 21:17:40.516874. OCR = False. 21 files read. 22.11% done.\n",
      "Finished Document_FPBF5IKX at 2023-03-12 21:17:40.660017. OCR = False. 22 files read. 23.16% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_J7HBXYBQ at 2023-03-12 21:17:40.800869. OCR = False. 23 files read. 24.21% done.\n",
      "Did not finish Document_2LRB28HQ.pdf... check out that one.\n",
      "cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_SX39863M at 2023-03-12 21:17:41.007799. OCR = False. 25 files read. 26.32% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_9JV4R9EW at 2023-03-12 21:17:41.232924. OCR = False. 26 files read. 27.37% done.\n",
      "Did not finish Document_Q73YL96D.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_XVX4XMR2 at 2023-03-12 21:17:41.374884. OCR = False. 28 files read. 29.47% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_PKB9CB7I at 2023-03-12 21:17:41.447570. OCR = False. 29 files read. 30.53% done.\n",
      "Finished Document_7TIFU594 at 2023-03-12 21:17:41.506311. OCR = False. 30 files read. 31.58% done.\n",
      "Finished Document_TAAJRZEP at 2023-03-12 21:17:41.561036. OCR = False. 31 files read. 32.63% done.\n",
      "Did not finish Document_RH5JP7XX.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_LTZN6E4P at 2023-03-12 21:17:41.643907. OCR = False. 33 files read. 34.74% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_D6YVIFBC at 2023-03-12 21:17:41.728373. OCR = False. 34 files read. 35.79% done.\n",
      "Did not finish Document_3E578E54.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_IB7PWZVG at 2023-03-12 21:17:41.792076. OCR = False. 36 files read. 37.89% done.\n",
      "Did not finish Document_TMFT472T.pdf... check out that one.\n",
      "cannot open broken document\n",
      "Finished Document_YJRJLQSA at 2023-03-12 21:17:41.927337. OCR = False. 38 files read. 40.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_UTLT344I at 2023-03-12 21:17:42.066421. OCR = False. 39 files read. 41.05% done.\n",
      "Finished Document_DMKRZS8E at 2023-03-12 21:17:42.158436. OCR = False. 40 files read. 42.11% done.\n",
      "Finished Document_ZFPUQZNE at 2023-03-12 21:17:42.256831. OCR = False. 41 files read. 43.16% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_G4923VSV at 2023-03-12 21:17:42.317216. OCR = False. 42 files read. 44.21% done.\n",
      "Finished Document_EV273D9P at 2023-03-12 21:17:42.370145. OCR = False. 43 files read. 45.26% done.\n",
      "Finished Document_PDUA89RL at 2023-03-12 21:17:42.414755. OCR = False. 44 files read. 46.32% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_VZGACXNN at 2023-03-12 21:17:42.544722. OCR = False. 45 files read. 47.37% done.\n",
      "Finished Document_YGFJAA5F at 2023-03-12 21:17:42.684419. OCR = False. 46 files read. 48.42% done.\n",
      "Finished Document_KN8U5AXF at 2023-03-12 21:17:42.744806. OCR = False. 47 files read. 49.47% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_NDH25D7X at 2023-03-12 21:17:42.800990. OCR = False. 48 files read. 50.53% done.\n",
      "Finished Document_BM6L3JUC at 2023-03-12 21:17:42.864686. OCR = False. 49 files read. 51.58% done.\n",
      "Finished Document_TJR42XC5 at 2023-03-12 21:17:42.918728. OCR = False. 50 files read. 52.63% done.\n",
      "Finished Document_RSB2STPR at 2023-03-12 21:17:42.981317. OCR = False. 51 files read. 53.68% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_3JVVCGH6 at 2023-03-12 21:17:43.058086. OCR = False. 52 files read. 54.74% done.\n",
      "Finished Document_334IKY7D at 2023-03-12 21:17:43.113379. OCR = False. 53 files read. 55.79% done.\n",
      "Finished Document_NDTF8ZQG at 2023-03-12 21:17:43.179179. OCR = False. 54 files read. 56.84% done.\n",
      "Finished Document_UR68UWWC at 2023-03-12 21:17:43.241170. OCR = False. 55 files read. 57.89% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_P7ZQXA49 at 2023-03-12 21:17:43.337091. OCR = False. 56 files read. 58.95% done.\n",
      "Finished Document_HE9X7NKT at 2023-03-12 21:17:43.416657. OCR = False. 57 files read. 60.0% done.\n",
      "Finished Document_4S7CU23C at 2023-03-12 21:17:43.473366. OCR = False. 58 files read. 61.05% done.\n",
      "Finished Document_QKHD29TS at 2023-03-12 21:17:43.530887. OCR = False. 59 files read. 62.11% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_NYRUWCRI at 2023-03-12 21:17:43.595361. OCR = False. 60 files read. 63.16% done.\n",
      "Finished Document_5H6TVKRX at 2023-03-12 21:17:43.776182. OCR = False. 61 files read. 64.21% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_WSFZDI5V at 2023-03-12 21:17:43.905069. OCR = False. 62 files read. 65.26% done.\n",
      "Finished Document_J5WD5TBV at 2023-03-12 21:17:43.959896. OCR = False. 63 files read. 66.32% done.\n",
      "Finished Document_ZH6G29C7 at 2023-03-12 21:17:44.023463. OCR = False. 64 files read. 67.37% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_PGPVWJGT at 2023-03-12 21:17:44.121116. OCR = False. 65 files read. 68.42% done.\n",
      "Finished Document_8MUZLDEB at 2023-03-12 21:17:44.179747. OCR = False. 66 files read. 69.47% done.\n",
      "Finished Document_REYPV3ZC at 2023-03-12 21:17:44.230858. OCR = False. 67 files read. 70.53% done.\n",
      "Finished Document_J2HMCSYG at 2023-03-12 21:17:44.307111. OCR = False. 68 files read. 71.58% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_WE83RECQ at 2023-03-12 21:17:44.362950. OCR = False. 69 files read. 72.63% done.\n",
      "Finished Document_P6HD9YXC at 2023-03-12 21:17:44.423685. OCR = False. 70 files read. 73.68% done.\n",
      "Finished Document_CP48TTDC at 2023-03-12 21:17:44.470523. OCR = False. 71 files read. 74.74% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_CI6ZIKFF at 2023-03-12 21:17:44.613780. OCR = False. 72 files read. 75.79% done.\n",
      "Finished Document_ZLF6SLHS at 2023-03-12 21:17:44.674856. OCR = False. 73 files read. 76.84% done.\n",
      "Finished Document_AB4GLPL8 at 2023-03-12 21:17:44.733078. OCR = False. 74 files read. 77.89% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_AP5DVV5Z at 2023-03-12 21:17:45.152205. OCR = False. 75 files read. 78.95% done.\n",
      "Finished Document_I64NHKAU at 2023-03-12 21:17:45.308597. OCR = False. 76 files read. 80.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_R5MQWTF6 at 2023-03-12 21:17:45.403587. OCR = False. 77 files read. 81.05% done.\n",
      "Finished Document_AM87JDAZ at 2023-03-12 21:17:45.526290. OCR = False. 78 files read. 82.11% done.\n",
      "Finished Document_9TTYWUNW at 2023-03-12 21:17:45.575020. OCR = False. 79 files read. 83.16% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_H5FD5NJN at 2023-03-12 21:17:45.650747. OCR = False. 80 files read. 84.21% done.\n",
      "Finished Document_YJ2Z9CDU at 2023-03-12 21:17:45.738824. OCR = False. 81 files read. 85.26% done.\n",
      "Finished Document_K92VUF7U at 2023-03-12 21:17:45.812661. OCR = False. 82 files read. 86.32% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_NBEFP27R at 2023-03-12 21:17:45.862703. OCR = False. 83 files read. 87.37% done.\n",
      "Finished Document_XJZTU57V at 2023-03-12 21:17:45.926522. OCR = False. 84 files read. 88.42% done.\n",
      "Finished Document_C8WB7LEN at 2023-03-12 21:17:46.000662. OCR = False. 85 files read. 89.47% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_2JGSDMU8 at 2023-03-12 21:17:46.106056. OCR = False. 86 files read. 90.53% done.\n",
      "Finished Document_6LZN3M3H at 2023-03-12 21:17:46.204442. OCR = False. 87 files read. 91.58% done.\n",
      "Finished Document_ECWZZCYD at 2023-03-12 21:17:46.270155. OCR = False. 88 files read. 92.63% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_DI5M2UVW at 2023-03-12 21:17:46.335924. OCR = False. 89 files read. 93.68% done.\n",
      "Finished Document_NA63NB35 at 2023-03-12 21:17:46.442449. OCR = False. 90 files read. 94.74% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Document_QIHZDINR at 2023-03-12 21:17:46.568144. OCR = False. 91 files read. 95.79% done.\n",
      "Finished Document_266KRB6Z at 2023-03-12 21:17:46.631380. OCR = False. 92 files read. 96.84% done.\n",
      "Finished Document_QWHY5CPT at 2023-03-12 21:17:46.692921. OCR = False. 93 files read. 97.89% done.\n",
      "Finished Document_RK8DMZHV at 2023-03-12 21:17:46.846676. OCR = False. 94 files read. 98.95% done.\n",
      "Finished Document_76RTMKVS at 2023-03-12 21:17:46.891274. OCR = False. 95 files read. 100.0% done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n",
      "/var/folders/t6/g5mv7rgx2jn_4y8tdl9_2pcm0000gq/T/ipykernel_40340/3197693240.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'file_name': f\"{name}\", 'file_text': txt, 'ocr': ocr}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "out = extract_pdfs(to_extract) # look at the frame.append method and change to concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_text</th>\n",
       "      <th>ocr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Document_47GCMTBN</td>\n",
       "      <td>Managing future urbanization\\n growth patterns...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Document_QCQS4ST2</td>\n",
       "      <td>Smart city re-imagined: City planning and GeoA...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Document_JI4B2NX5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Document_P3ZBU43W</td>\n",
       "      <td>Using Natural Language\\n Processing to Read Pl...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Document_QIHZDINR</td>\n",
       "      <td>Accelerating the world's research.\\n The End o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Document_266KRB6Z</td>\n",
       "      <td>Futures 36 (2004) 1077–1094\\n www.elsevier.com...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Document_QWHY5CPT</td>\n",
       "      <td>The Development of Optimization Methods in Gen...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Document_RK8DMZHV</td>\n",
       "      <td>REVIEW\\n Open Access\\n The core academic and s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Document_76RTMKVS</td>\n",
       "      <td>��� ������������ ������ �� ���������� ������ �...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name                                          file_text  \\\n",
       "0               dummy                                              dummy   \n",
       "1   Document_47GCMTBN  Managing future urbanization\\n growth patterns...   \n",
       "3   Document_QCQS4ST2  Smart city re-imagined: City planning and GeoA...   \n",
       "5   Document_JI4B2NX5                                                ...   \n",
       "6   Document_P3ZBU43W  Using Natural Language\\n Processing to Read Pl...   \n",
       "..                ...                                                ...   \n",
       "86  Document_QIHZDINR  Accelerating the world's research.\\n The End o...   \n",
       "87  Document_266KRB6Z  Futures 36 (2004) 1077–1094\\n www.elsevier.com...   \n",
       "88  Document_QWHY5CPT  The Development of Optimization Methods in Gen...   \n",
       "89  Document_RK8DMZHV  REVIEW\\n Open Access\\n The core academic and s...   \n",
       "90  Document_76RTMKVS  ��� ������������ ������ �� ���������� ������ �...   \n",
       "\n",
       "      ocr  \n",
       "0   False  \n",
       "1   False  \n",
       "3   False  \n",
       "5   False  \n",
       "6   False  \n",
       "..    ...  \n",
       "86  False  \n",
       "87  False  \n",
       "88  False  \n",
       "89  False  \n",
       "90  False  \n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.drop_duplicates(subset='file_text')\n",
    "out # we are able to scrape the vast majority of the articles without a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rapid topic modeling/cleaning prototyping:\n",
    "#out.to_csv(r\"extracted_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. Cleaning up the text\n",
    "Using strategies based on [this article](https://monkeylearn.com/blog/text-cleaning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, before we do any other cleaning tasks, this is where we need to match and remove references with the information we got from the Scholarcy API above.\n",
    "\n",
    "#### Resources:\n",
    "- [String comparison in Python](https://note.nkmk.me/en/python-str-compare/)\n",
    "- [Potentially useful example on StackOverflow](https://stackoverflow.com/questions/39551029/if-else-statement-for-finding-the-index-of-a-character-in-a-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def referenceChecker(extracted_df):\n",
    "    ref_excluded = {}\n",
    "    counter = 0\n",
    "    string3=\"\"\n",
    "    matches=0\n",
    "    nomatch=0\n",
    "    for name in extracted_df['file_name']:\n",
    "        if \"dummy\" not in name:\n",
    "            text_file = open(str(name) +\".txt\", \"r\")\n",
    "            data = text_file.read()      # Read whole file to a string\n",
    "            text_file.close()         # Close file\n",
    "            string1 = data.replace('\\n',\" \")\n",
    "            string2 = string1.replace('\\t',\"\")\n",
    "            coverp_s = string2.find(\"Electronic Delivery Cover Sheet\")\n",
    "            coverp_e = string2.find(\"Part 201.14\")\n",
    "            if coverp_s:\n",
    "                string3  = string2.replace(string2[coverp_s:coverp_e], \"\")\n",
    "            else:\n",
    "                string3 = string2\n",
    "            starti = string3.find(\"References\")\n",
    "            startc = string3.find(\"REFERENCES\")\n",
    "            if starti:\n",
    "                string4 = string3.replace(string3[starti:], \"\")\n",
    "            elif startc:\n",
    "                string4 = string3.replace(string3[startc:], \"\")\n",
    "            else:\n",
    "                string4=string3\n",
    "            ref_excluded[name] = string4\n",
    "    return ref_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ex = referenceChecker(out) #could be refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Tasks\n",
    "- Case Normalization\n",
    "- Remove Unicode Characters\n",
    "    - In the future, we may want to experiment with using [ftfy](https://github.com/rspeer/python-ftfy), which fixes text encoding issues, in this pipeline. We may also be interested in exploring [scrubadub](https://scrubadub.readthedocs.io/en/stable/index.html), which redacts potential PII from text.\n",
    "- Remove Stopwords\n",
    "- Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCleaner(ref_ex_dict):\n",
    "    full_corpus = []\n",
    "    stop = stopwords.words('english')\n",
    "    stop.extend(['et','al',\"chicago\",\"university\",\"press\",\"copyrighted\",\"unauthorized\",\"could\", 'u','x','fig','eg'])\n",
    "    for i in ref_ex_dict.keys():\n",
    "        data = ref_ex_dict[i]\n",
    "        da = data.lower()\n",
    "        d = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", da)\n",
    "        all_words = nltk.word_tokenize(d)\n",
    "        words = [w for w in all_words if w not in stop]\n",
    "        words = [w for w in words if w.isalpha()]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        word_out = []\n",
    "        for word in words:\n",
    "            a = lemmatizer.lemmatize(word)\n",
    "            word_out.append(a)\n",
    "        ref_ex_dict[i] = word_out\n",
    "        full_corpus.append(word_out)\n",
    "    return ref_ex_dict, full_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = textCleaner(ref_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdict = a[0]\n",
    "corpus = a[1] # corpus in the same way that gensim defines it\n",
    "full_corpus = [x for xs in corpus for x in xs] #flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick frequency distribution of the *most common words* in the corpus, and the *most common two and three word collocations* in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'urban': 3007, 'data': 2331, 'city': 1969, 'ai': 1744, 'planning': 1345, 'model': 1167, 'system': 945, 'technology': 799, 'study': 796, 'process': 765, ...})"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_fd = nltk.FreqDist(full_corpus)\n",
    "word_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('urban', 'planning'): 377, ('big', 'data'): 272, ('smart', 'city'): 232, ('urban', 'design'): 170, ('machine', 'learning'): 166, ('social', 'medium'): 162, ('land', 'use'): 161, ('articial', 'intelligence'): 149, ('computer', 'vision'): 123, ('deep', 'learning'): 119, ...})"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_fd = nltk.FreqDist(nltk.bigrams(full_corpus))\n",
    "bigram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('smart', 'sustainable', 'city'): 61, ('datadriven', 'smart', 'sustainable'): 61, ('urban', 'land', 'use'): 46, ('treatment', 'eff', 'ect'): 45, ('urban', 'technological', 'innovation'): 42, ('smart', 'sustainable', 'urbanism'): 41, ('land', 'use', 'planning'): 37, ('reading', 'material', 'published'): 36, ('material', 'published', 'posting'): 36, ('published', 'posting', 'copying'): 36, ...})"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_fd = nltk.FreqDist(nltk.trigrams(full_corpus))\n",
    "trigram_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using some of nltk's built in functions to get more information about the collocation scores according to association measures.\n",
    "See more information about the nltk collocation methodology [here](https://www.nltk.org/api/nltk.collocations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('urban', 'planning'), 0.0018434847240151782),\n",
       " (('big', 'data'), 0.001330047334037476),\n",
       " (('smart', 'city'), 0.0011344521378554944),\n",
       " (('urban', 'design'), 0.0008312795837734225),\n",
       " (('machine', 'learning'), 0.0008117200641552244),\n",
       " (('social', 'medium'), 0.0007921605445370261),\n",
       " (('land', 'use'), 0.0007872706646324766),\n",
       " (('articial', 'intelligence'), 0.0007285921057778821),\n",
       " (('computer', 'vision'), 0.0006014552282595939),\n",
       " (('deep', 'learning'), 0.0005818957086413958),\n",
       " (('smart', 'sustainable'), 0.0005574463091186481),\n",
       " (('ai', 'technology'), 0.000547666549309549),\n",
       " (('urban', 'development'), 0.0005427766694049994),\n",
       " (('local', 'government'), 0.0005134373899777022),\n",
       " (('neural', 'network'), 0.0004840981105504049),\n",
       " (('artificial', 'intelligence'), 0.0004645385909322067),\n",
       " (('eff', 'ect'), 0.0004547588311231076),\n",
       " (('urban', 'data'), 0.00044986895121855805),\n",
       " (('walking', 'satisfaction'), 0.00044986895121855805),\n",
       " (('urban', 'service'), 0.000440089191409459),\n",
       " (('sustainable', 'city'), 0.00041074991198216174),\n",
       " (('urban', 'planner'), 0.0004058600320776122),\n",
       " (('automated', 'city'), 0.00039608027226851306),\n",
       " (('datadriven', 'smart'), 0.00039608027226851306),\n",
       " (('case', 'study'), 0.000386300512459414),\n",
       " (('hong', 'kong'), 0.0003765207526503149),\n",
       " (('semantic', 'segmentation'), 0.0003765207526503149),\n",
       " (('built', 'environment'), 0.0003716308727457654),\n",
       " (('data', 'science'), 0.0003716308727457654),\n",
       " (('data', 'set'), 0.0003716308727457654),\n",
       " (('urban', 'growth'), 0.00035696123303211676),\n",
       " (('public', 'service'), 0.0003520713531275672),\n",
       " (('shapley', 'value'), 0.00034718147322301764),\n",
       " (('ai', 'help'), 0.0003422915933184681),\n",
       " (('planning', 'process'), 0.0003422915933184681),\n",
       " (('urban', 'system'), 0.0003422915933184681),\n",
       " (('urban', 'environment'), 0.000332511833509369),\n",
       " (('unsupervised', 'learning'), 0.00032762195360481946),\n",
       " (('urban', 'science'), 0.00032762195360481946),\n",
       " (('urban', 'study'), 0.0003080624339866213),\n",
       " (('sustainable', 'urbanism'), 0.0003031725540820717),\n",
       " (('urban', 'land'), 0.0002982826741775222),\n",
       " (('city', 'planning'), 0.00029339279427297266),\n",
       " (('inll', 'development'), 0.00029339279427297266),\n",
       " (('point', 'cloud'), 0.00029339279427297266),\n",
       " (('urban', 'sustainability'), 0.00029339279427297266),\n",
       " (('technological', 'innovation'), 0.0002885029143684231),\n",
       " (('urban', 'area'), 0.0002836130344638736),\n",
       " (('computer', 'science'), 0.00027872315455932403),\n",
       " (('ai', 'machine'), 0.0002689433947502249),\n",
       " (('urban', 'space'), 0.0002640535148456754),\n",
       " (('last', 'accessed'), 0.00025916363494112585),\n",
       " (('satellite', 'image'), 0.00025916363494112585),\n",
       " (('ai', 'benefit'), 0.0002542737550365763),\n",
       " (('data', 'analytics'), 0.00024449399522747723),\n",
       " (('financial', 'resource'), 0.00024449399522747723),\n",
       " (('decision', 'making'), 0.00023960411532292767),\n",
       " (('street', 'furniture'), 0.00023960411532292767),\n",
       " (('use', 'ai'), 0.00023960411532292767),\n",
       " (('network', 'governance'), 0.0002347142354183781),\n",
       " (('planning', 'design'), 0.0002347142354183781),\n",
       " (('random', 'forest'), 0.0002347142354183781),\n",
       " (('sustainable', 'urban'), 0.0002347142354183781),\n",
       " (('urban', 'informatics'), 0.0002347142354183781),\n",
       " (('streetview', 'photo'), 0.00022493447560927902),\n",
       " (('trafc', 'ow'), 0.00022493447560927902),\n",
       " (('treatment', 'eff'), 0.00022493447560927902),\n",
       " (('complex', 'system'), 0.0002200445957047295),\n",
       " (('public', 'sector'), 0.0002200445957047295),\n",
       " (('ai', 'agent'), 0.00021515471580017996),\n",
       " (('data', 'collection'), 0.00021515471580017996),\n",
       " (('data', 'source'), 0.00021515471580017996),\n",
       " (('urban', 'technological'), 0.00021515471580017996),\n",
       " (('autonomous', 'car'), 0.0002102648358956304),\n",
       " (('data', 'processing'), 0.0002102648358956304),\n",
       " (('social', 'science'), 0.0002102648358956304),\n",
       " (('wide', 'range'), 0.0002102648358956304),\n",
       " (('ai', 'application'), 0.00020537495599108087),\n",
       " (('design', 'process'), 0.00020537495599108087),\n",
       " (('street', 'view'), 0.00020537495599108087),\n",
       " (('use', 'planning'), 0.00020537495599108087),\n",
       " (('ai', 'used'), 0.0002004850760865313),\n",
       " (('example', 'image'), 0.00019559519618198178),\n",
       " (('land', 'cell'), 0.00019559519618198178),\n",
       " (('sustainable', 'development'), 0.00019559519618198178),\n",
       " (('city', 'brain'), 0.00019070531627743222),\n",
       " (('figure', 'example'), 0.00019070531627743222),\n",
       " (('application', 'ai'), 0.0001858154363728827),\n",
       " (('application', 'area'), 0.0001858154363728827),\n",
       " (('area', 'ratio'), 0.0001858154363728827),\n",
       " (('information', 'system'), 0.0001858154363728827),\n",
       " (('public', 'perception'), 0.0001858154363728827),\n",
       " (('material', 'published'), 0.00018092555646833313),\n",
       " (('urban', 'geography'), 0.00018092555646833313),\n",
       " (('author', 'publisher'), 0.0001760356765637836),\n",
       " (('copying', 'distributing'), 0.0001760356765637836),\n",
       " (('copyright', 'law'), 0.0001760356765637836),\n",
       " (('de', 'roo'), 0.0001760356765637836),\n",
       " (('distributing', 'work'), 0.0001760356765637836),\n",
       " (('except', 'permitted'), 0.0001760356765637836),\n",
       " (('future', 'city'), 0.0001760356765637836),\n",
       " (('illegal', 'injures'), 0.0001760356765637836),\n",
       " (('injures', 'author'), 0.0001760356765637836),\n",
       " (('law', 'illegal'), 0.0001760356765637836),\n",
       " (('permitted', 'u'), 0.0001760356765637836),\n",
       " (('posting', 'copying'), 0.0001760356765637836),\n",
       " (('published', 'posting'), 0.0001760356765637836),\n",
       " (('reading', 'material'), 0.0001760356765637836),\n",
       " (('study', 'area'), 0.0001760356765637836),\n",
       " (('u', 'copyright'), 0.0001760356765637836),\n",
       " (('work', 'except'), 0.0001760356765637836),\n",
       " (('data', 'mining'), 0.00017114579665923404),\n",
       " (('input', 'data'), 0.00017114579665923404),\n",
       " (('lidar', 'data'), 0.00017114579665923404),\n",
       " (('proportion', 'street'), 0.00017114579665923404),\n",
       " (('smart', 'urbanism'), 0.00017114579665923404),\n",
       " (('supervised', 'learning'), 0.00017114579665923404),\n",
       " (('urban', 'management'), 0.00017114579665923404),\n",
       " (('causal', 'inference'), 0.0001662559167546845),\n",
       " (('intelligence', 'ai'), 0.0001662559167546845),\n",
       " (('learning', 'algorithm'), 0.0001662559167546845),\n",
       " (('logistic', 'regression'), 0.0001662559167546845),\n",
       " (('public', 'transit'), 0.0001662559167546845),\n",
       " (('support', 'vector'), 0.0001662559167546845),\n",
       " (('transit', 'network'), 0.0001662559167546845),\n",
       " (('agedcare', 'disability'), 0.00016136603685013495),\n",
       " (('space', 'place'), 0.00016136603685013495),\n",
       " (('data', 'used'), 0.00015647615694558542),\n",
       " (('geographic', 'information'), 0.00015647615694558542),\n",
       " (('ml', 'algorithm'), 0.00015647615694558542),\n",
       " (('new', 'york'), 0.00015647615694558542),\n",
       " (('real', 'time'), 0.00015647615694558542),\n",
       " (('sustainability', 'science'), 0.00015647615694558542),\n",
       " (('user', 'preference'), 0.00015647615694558542),\n",
       " (('autonomous', 'city'), 0.00015158627704103586),\n",
       " (('decision', 'maker'), 0.00015158627704103586),\n",
       " (('future', 'research'), 0.00015158627704103586),\n",
       " (('health', 'resort'), 0.00015158627704103586),\n",
       " (('hybrid', 'space'), 0.00015158627704103586),\n",
       " (('information', 'technology'), 0.00015158627704103586),\n",
       " (('new', 'technology'), 0.00015158627704103586),\n",
       " (('planning', 'urban'), 0.00015158627704103586),\n",
       " (('topic', 'modeling'), 0.00015158627704103586),\n",
       " (('urban', 'analytics'), 0.00015158627704103586),\n",
       " (('urban', 'life'), 0.00015158627704103586),\n",
       " (('ai', 'urban'), 0.00014669639713648633),\n",
       " (('computational', 'urban'), 0.00014669639713648633),\n",
       " (('edge', 'detection'), 0.00014669639713648633),\n",
       " (('service', 'ai'), 0.00014669639713648633),\n",
       " (('time', 'cost'), 0.00014669639713648633),\n",
       " (('ud', 'clustering'), 0.00014669639713648633),\n",
       " (('walking', 'environment'), 0.00014669639713648633),\n",
       " (('data', 'collected'), 0.0001418065172319368),\n",
       " (('planning', 'role'), 0.0001418065172319368),\n",
       " (('urban', 'articial'), 0.0001418065172319368),\n",
       " (('urban', 'form'), 0.0001418065172319368),\n",
       " (('bibri', 'computational'), 0.00013691663732738724),\n",
       " (('climate', 'change'), 0.00013691663732738724),\n",
       " (('clustering', 'kmeans'), 0.00013691663732738724),\n",
       " (('community', 'wellbeing'), 0.00013691663732738724),\n",
       " (('data', 'management'), 0.00013691663732738724),\n",
       " (('data', 'urban'), 0.00013691663732738724),\n",
       " (('decision', 'support'), 0.00013691663732738724),\n",
       " (('expert', 'knowledge'), 0.00013691663732738724),\n",
       " (('hidden', 'layer'), 0.00013691663732738724),\n",
       " (('knowledge', 'base'), 0.00013691663732738724),\n",
       " (('literature', 'review'), 0.00013691663732738724),\n",
       " (('quality', 'life'), 0.00013691663732738724),\n",
       " (('ranked', 'agree'), 0.00013691663732738724),\n",
       " (('regional', 'planning'), 0.00013691663732738724),\n",
       " (('solve', 'problem'), 0.00013691663732738724),\n",
       " (('source', 'author'), 0.00013691663732738724),\n",
       " (('trust', 'ai'), 0.00013691663732738724),\n",
       " (('urban', 'zoning'), 0.00013691663732738724),\n",
       " (('ai', 'local'), 0.0001320267574228377),\n",
       " (('future', 'automated'), 0.0001320267574228377),\n",
       " (('living', 'lab'), 0.0001320267574228377),\n",
       " (('process', 'urban'), 0.0001320267574228377),\n",
       " (('public', 'space'), 0.0001320267574228377),\n",
       " (('science', 'page'), 0.0001320267574228377),\n",
       " (('travel', 'plan'), 0.0001320267574228377),\n",
       " (('believe', 'ai'), 0.00012713687751828815),\n",
       " (('city', 'social'), 0.00012713687751828815),\n",
       " (('cloud', 'computing'), 0.00012713687751828815),\n",
       " (('data', 'data'), 0.00012713687751828815),\n",
       " (('disaster', 'management'), 0.00012713687751828815),\n",
       " (('future', 'urban'), 0.00012713687751828815),\n",
       " (('green', 'space'), 0.00012713687751828815),\n",
       " (('international', 'journal'), 0.00012713687751828815),\n",
       " (('lagos', 'metropolis'), 0.00012713687751828815),\n",
       " (('machinelearning', 'model'), 0.00012713687751828815),\n",
       " (('make', 'decision'), 0.00012713687751828815),\n",
       " (('project', 'planning'), 0.00012713687751828815),\n",
       " (('remote', 'sensing'), 0.00012713687751828815),\n",
       " (('support', 'system'), 0.00012713687751828815),\n",
       " (('urban', 'infrastructure'), 0.00012713687751828815),\n",
       " (('ai', 'society'), 0.00012224699761373862),\n",
       " (('australia', 'hong'), 0.00012224699761373862),\n",
       " (('benefit', 'urban'), 0.00012224699761373862),\n",
       " (('city', 'system'), 0.00012224699761373862),\n",
       " (('city', 'urban'), 0.00012224699761373862),\n",
       " (('diff', 'erent'), 0.00012224699761373862),\n",
       " (('goalreasoning', 'ai'), 0.00012224699761373862),\n",
       " (('land', 'cover'), 0.00012224699761373862),\n",
       " (('method', 'used'), 0.00012224699761373862),\n",
       " (('metropolitan', 'area'), 0.00012224699761373862),\n",
       " (('new', 'way'), 0.00012224699761373862),\n",
       " (('peer', 'review'), 0.00012224699761373862),\n",
       " (('perception', 'ai'), 0.00012224699761373862),\n",
       " (('social', 'economic'), 0.00012224699761373862),\n",
       " (('widely', 'used'), 0.00012224699761373862),\n",
       " (('zone', 'type'), 0.00012224699761373862),\n",
       " (('automated', 'vehicle'), 0.00011735711770918906),\n",
       " (('claudia', 'yamu'), 0.00011735711770918906),\n",
       " (('data', 'analysis'), 0.00011735711770918906),\n",
       " (('decisionmaking', 'process'), 0.00011735711770918906),\n",
       " (('gert', 'de'), 0.00011735711770918906),\n",
       " (('proportion', 'road'), 0.00011735711770918906),\n",
       " (('sustainability', 'peer'), 0.00011735711770918906),\n",
       " (('technology', 'automation'), 0.00011735711770918906),\n",
       " (('urban', 'ai'), 0.00011735711770918906),\n",
       " (('urban', 'future'), 0.00011735711770918906),\n",
       " (('adaptive', 'system'), 0.00011246723780463951),\n",
       " (('ai', 'city'), 0.00011246723780463951),\n",
       " (('data', 'type'), 0.00011246723780463951),\n",
       " (('linearly', 'inseparable'), 0.00011246723780463951),\n",
       " (('new', 'urban'), 0.00011246723780463951),\n",
       " (('ow', 'prediction'), 0.00011246723780463951),\n",
       " (('planning', 'problem'), 0.00011246723780463951),\n",
       " (('shown', 'figure'), 0.00011246723780463951),\n",
       " (('social', 'technical'), 0.00011246723780463951),\n",
       " (('transportation', 'network'), 0.00011246723780463951),\n",
       " (('ai', 'system'), 0.00010757735790008998),\n",
       " (('ai', 'trust'), 0.00010757735790008998),\n",
       " (('builtup', 'area'), 0.00010757735790008998),\n",
       " (('complex', 'adaptive'), 0.00010757735790008998),\n",
       " (('different', 'type'), 0.00010757735790008998),\n",
       " (('economic', 'development'), 0.00010757735790008998),\n",
       " (('economic', 'social'), 0.00010757735790008998),\n",
       " (('effect', 'walking'), 0.00010757735790008998),\n",
       " (('ethical', 'perspective'), 0.00010757735790008998),\n",
       " (('goal', 'reasoning'), 0.00010757735790008998),\n",
       " (('human', 'intelligence'), 0.00010757735790008998),\n",
       " (('impact', 'machine'), 0.00010757735790008998),\n",
       " (('innovation', 'process'), 0.00010757735790008998),\n",
       " (('large', 'number'), 0.00010757735790008998),\n",
       " (('material', 'virtual'), 0.00010757735790008998),\n",
       " (('ml', 'method'), 0.00010757735790008998),\n",
       " (('ml', 'model'), 0.00010757735790008998),\n",
       " (('model', 'based'), 0.00010757735790008998),\n",
       " (('multiagent', 'system'), 0.00010757735790008998),\n",
       " (('proportion', 'building'), 0.00010757735790008998),\n",
       " (('proportion', 'sidewalk'), 0.00010757735790008998),\n",
       " (('science', 'journal'), 0.00010757735790008998),\n",
       " (('shap', 'value'), 0.00010757735790008998),\n",
       " (('street', 'environment'), 0.00010757735790008998),\n",
       " (('technical', 'ethical'), 0.00010757735790008998),\n",
       " (('trafc', 'data'), 0.00010757735790008998),\n",
       " (('urban', 'dynamic'), 0.00010757735790008998),\n",
       " (('ai', 'risk'), 0.00010268747799554043),\n",
       " (('automation', 'robotisation'), 0.00010268747799554043),\n",
       " (('city', 'policy'), 0.00010268747799554043),\n",
       " (('cost', 'time'), 0.00010268747799554043),\n",
       " (('design', 'planning'), 0.00010268747799554043),\n",
       " (('factor', 'analysis'), 0.00010268747799554043),\n",
       " (('inseparable', 'data'), 0.00010268747799554043),\n",
       " (('inspired', 'algorithm'), 0.00010268747799554043),\n",
       " (('internet', 'thing'), 0.00010268747799554043),\n",
       " (('journal', 'urban'), 0.00010268747799554043),\n",
       " (('learning', 'economics'), 0.00010268747799554043),\n",
       " (('learning', 'model'), 0.00010268747799554043),\n",
       " (('model', 'used'), 0.00010268747799554043),\n",
       " (('new', 'data'), 0.00010268747799554043),\n",
       " (('physical', 'feature'), 0.00010268747799554043),\n",
       " (('positive', 'effect'), 0.00010268747799554043),\n",
       " (('process', 'planner'), 0.00010268747799554043),\n",
       " (('result', 'show'), 0.00010268747799554043),\n",
       " (('scientific', 'discipline'), 0.00010268747799554043),\n",
       " (('see', 'table'), 0.00010268747799554043),\n",
       " (('short', 'term'), 0.00010268747799554043),\n",
       " (('susan', 'athey'), 0.00010268747799554043),\n",
       " (('symbolic', 'value'), 0.00010268747799554043),\n",
       " (('unsupervised', 'method'), 0.00010268747799554043),\n",
       " (('urban', 'model'), 0.00010268747799554043),\n",
       " (('urban', 'modeling'), 0.00010268747799554043),\n",
       " (('urban', 'problem'), 0.00010268747799554043),\n",
       " (('using', 'ai'), 0.00010268747799554043),\n",
       " (('using', 'data'), 0.00010268747799554043),\n",
       " (('value', 'plot'), 0.00010268747799554043),\n",
       " (('virtual', 'world'), 0.00010268747799554043),\n",
       " (('b', 'c'), 9.779759809099089e-05),\n",
       " (('benefit', 'disaster'), 9.779759809099089e-05),\n",
       " (('city', 'city'), 9.779759809099089e-05),\n",
       " (('data', 'scientist'), 9.779759809099089e-05),\n",
       " (('decision', 'tree'), 9.779759809099089e-05),\n",
       " (('digital', 'technology'), 9.779759809099089e-05),\n",
       " (('emerging', 'science'), 9.779759809099089e-05),\n",
       " (('learning', 'method'), 9.779759809099089e-05),\n",
       " (('learning', 'technique'), 9.779759809099089e-05),\n",
       " (('local', 'community'), 9.779759809099089e-05),\n",
       " (('material', 'world'), 9.779759809099089e-05),\n",
       " (('medium', 'account'), 9.779759809099089e-05),\n",
       " (('model', 'performance'), 9.779759809099089e-05),\n",
       " (('modern', 'city'), 9.779759809099089e-05),\n",
       " (('opportunity', 'threat'), 9.779759809099089e-05),\n",
       " (('planning', 'development'), 9.779759809099089e-05),\n",
       " (('process', 'automation'), 9.779759809099089e-05),\n",
       " (('public', 'administration'), 9.779759809099089e-05),\n",
       " (('risk', 'ai'), 9.779759809099089e-05),\n",
       " (('science', 'technology'), 9.779759809099089e-05),\n",
       " (('spatial', 'planning'), 9.779759809099089e-05),\n",
       " (('study', 'urban'), 9.779759809099089e-05),\n",
       " (('svm', 'network'), 9.779759809099089e-05),\n",
       " (('take', 'place'), 9.779759809099089e-05),\n",
       " (('test', 'set'), 9.779759809099089e-05),\n",
       " (('training', 'data'), 9.779759809099089e-05),\n",
       " (('traveling', 'salesman'), 9.779759809099089e-05),\n",
       " (('ur', 'clustering'), 9.779759809099089e-05),\n",
       " (('urban', 'policy'), 9.779759809099089e-05),\n",
       " (('visual', 'analytics'), 9.779759809099089e-05),\n",
       " (('visual', 'feature'), 9.779759809099089e-05),\n",
       " (('adopting', 'ai'), 9.290771818644134e-05),\n",
       " (('aspect', 'urban'), 9.290771818644134e-05),\n",
       " (('cnn', 'model'), 9.290771818644134e-05),\n",
       " (('commonly', 'used'), 9.290771818644134e-05),\n",
       " (('complex', 'urban'), 9.290771818644134e-05),\n",
       " (('complexity', 'science'), 9.290771818644134e-05),\n",
       " (('development', 'urban'), 9.290771818644134e-05),\n",
       " (('digital', 'transformation'), 9.290771818644134e-05),\n",
       " (('field', 'urban'), 9.290771818644134e-05),\n",
       " (('health', 'spa'), 9.290771818644134e-05),\n",
       " (('journal', 'vol'), 9.290771818644134e-05),\n",
       " (('nature', 'inspired'), 9.290771818644134e-05),\n",
       " (('planning', 'model'), 9.290771818644134e-05),\n",
       " (('planning', 'network'), 9.290771818644134e-05),\n",
       " (('planning', 'reform'), 9.290771818644134e-05),\n",
       " (('recent', 'year'), 9.290771818644134e-05),\n",
       " (('reinforcement', 'learning'), 9.290771818644134e-05),\n",
       " (('separation', 'margin'), 9.290771818644134e-05),\n",
       " (('service', 'robot'), 9.290771818644134e-05),\n",
       " (('spatial', 'data'), 9.290771818644134e-05),\n",
       " (('sustain', 'able'), 9.290771818644134e-05),\n",
       " (('thematic', 'group'), 9.290771818644134e-05),\n",
       " (('transport', 'system'), 9.290771818644134e-05),\n",
       " (('urban', 'domain'), 9.290771818644134e-05),\n",
       " (('vol', 'page'), 9.290771818644134e-05),\n",
       " (('walking', 'distance'), 9.290771818644134e-05),\n",
       " (('bee', 'system'), 8.80178382818918e-05),\n",
       " (('city', 'ai'), 8.80178382818918e-05),\n",
       " (('clustering', 'dbscan'), 8.80178382818918e-05),\n",
       " (('conditioning', 'space'), 8.80178382818918e-05),\n",
       " (('data', 'driven'), 8.80178382818918e-05),\n",
       " (('data', 'information'), 8.80178382818918e-05),\n",
       " (('feature', 'extraction'), 8.80178382818918e-05),\n",
       " (('food', 'source'), 8.80178382818918e-05),\n",
       " (('image', 'showing'), 8.80178382818918e-05),\n",
       " (('interaction', 'eects'), 8.80178382818918e-05),\n",
       " (('large', 'amount'), 8.80178382818918e-05),\n",
       " (('machine', 'used'), 8.80178382818918e-05),\n",
       " (('mostly', 'positive'), 8.80178382818918e-05),\n",
       " (('open', 'access'), 8.80178382818918e-05),\n",
       " (('planning', 'algorithm'), 8.80178382818918e-05),\n",
       " (('planning', 'management'), 8.80178382818918e-05),\n",
       " (('publisher', 'impact'), 8.80178382818918e-05),\n",
       " (('publisher', 'susan'), 8.80178382818918e-05),\n",
       " (('shap', 'summary'), 8.80178382818918e-05),\n",
       " (('showing', 'proportion'), 8.80178382818918e-05),\n",
       " (('smart', 'data'), 8.80178382818918e-05),\n",
       " (('social', 'bot'), 8.80178382818918e-05),\n",
       " (('summary', 'plot'), 8.80178382818918e-05),\n",
       " (('table', 'show'), 8.80178382818918e-05),\n",
       " (('think', 'ai'), 8.80178382818918e-05),\n",
       " (('travel', 'time'), 8.80178382818918e-05),\n",
       " (('u', 'clustering'), 8.80178382818918e-05),\n",
       " (('urban', 'challenge'), 8.80178382818918e-05),\n",
       " (('urban', 'transport'), 8.80178382818918e-05),\n",
       " (('used', 'urban'), 8.80178382818918e-05),\n",
       " (('ai', 'adoption'), 8.312795837734225e-05),\n",
       " (('ai', 'public'), 8.312795837734225e-05),\n",
       " (('amount', 'data'), 8.312795837734225e-05),\n",
       " (('ant', 'system'), 8.312795837734225e-05),\n",
       " (('architecture', 'urban'), 8.312795837734225e-05),\n",
       " (('bus', 'stop'), 8.312795837734225e-05),\n",
       " (('complex', 'problem'), 8.312795837734225e-05),\n",
       " (('computer', 'system'), 8.312795837734225e-05),\n",
       " (('con', 'dence'), 8.312795837734225e-05),\n",
       " (('design', 'management'), 8.312795837734225e-05),\n",
       " (('develop', 'ment'), 8.312795837734225e-05),\n",
       " (('disaster', 'ai'), 8.312795837734225e-05),\n",
       " (('heterogeneous', 'goal'), 8.312795837734225e-05),\n",
       " (('large', 'scale'), 8.312795837734225e-05),\n",
       " (('make', 'use'), 8.312795837734225e-05),\n",
       " (('new', 'approach'), 8.312795837734225e-05),\n",
       " (('new', 'form'), 8.312795837734225e-05),\n",
       " (('one', 'hand'), 8.312795837734225e-05),\n",
       " (('optimization', 'problem'), 8.312795837734225e-05),\n",
       " (('public', 'transportation'), 8.312795837734225e-05),\n",
       " (('research', 'strategy'), 8.312795837734225e-05),\n",
       " (('role', 'development'), 8.312795837734225e-05),\n",
       " (('sci', 'ence'), 8.312795837734225e-05),\n",
       " (('sound', 'level'), 8.312795837734225e-05),\n",
       " (('system', 'gi'), 8.312795837734225e-05),\n",
       " (('system', 'urban'), 8.312795837734225e-05),\n",
       " (('type', 'data'), 8.312795837734225e-05),\n",
       " (('urban', 'regional'), 8.312795837734225e-05),\n",
       " (('urban', 'research'), 8.312795837734225e-05),\n",
       " (('algo', 'rithms'), 7.823807847279271e-05),\n",
       " (('also', 'used'), 7.823807847279271e-05),\n",
       " (('architectural', 'design'), 7.823807847279271e-05),\n",
       " (('best', 'solution'), 7.823807847279271e-05),\n",
       " (('business', 'model'), 7.823807847279271e-05),\n",
       " (('causal', 'eff'), 7.823807847279271e-05),\n",
       " (('cellular', 'automaton'), 7.823807847279271e-05),\n",
       " (('city', 'smart'), 7.823807847279271e-05),\n",
       " (('clustering', 'som'), 7.823807847279271e-05),\n",
       " (('cognitive', 'model'), 7.823807847279271e-05),\n",
       " (('common', 'knowledge'), 7.823807847279271e-05),\n",
       " (('community', 'engagement'), 7.823807847279271e-05),\n",
       " (('compact', 'city'), 7.823807847279271e-05),\n",
       " (('computational', 'method'), 7.823807847279271e-05),\n",
       " (('convolutional', 'neural'), 7.823807847279271e-05),\n",
       " (('devel', 'opment'), 7.823807847279271e-05),\n",
       " (('digital', 'divide'), 7.823807847279271e-05),\n",
       " (('dont', 'contribute'), 7.823807847279271e-05),\n",
       " (('ea', 'silva'), 7.823807847279271e-05),\n",
       " (('ecological', 'urbanism'), 7.823807847279271e-05),\n",
       " (('floating', 'population'), 7.823807847279271e-05),\n",
       " (('growth', 'pattern'), 7.823807847279271e-05),\n",
       " (('human', 'activity'), 7.823807847279271e-05),\n",
       " (('key', 'challenge'), 7.823807847279271e-05),\n",
       " (('knowledge', 'urban'), 7.823807847279271e-05),\n",
       " (('los', 'angeles'), 7.823807847279271e-05),\n",
       " (('objective', 'function'), 7.823807847279271e-05),\n",
       " (('panel', 'data'), 7.823807847279271e-05),\n",
       " (('pedestrian', 'satisfaction'), 7.823807847279271e-05),\n",
       " (('people', 'prefer'), 7.823807847279271e-05),\n",
       " (('plan', 'ning'), 7.823807847279271e-05),\n",
       " (('planning', 'task'), 7.823807847279271e-05),\n",
       " (('positive', 'negative'), 7.823807847279271e-05),\n",
       " (('public', 'participation'), 7.823807847279271e-05),\n",
       " (('public', 'private'), 7.823807847279271e-05),\n",
       " (('real', 'estate'), 7.823807847279271e-05),\n",
       " (('sample', 'size'), 7.823807847279271e-05),\n",
       " (('state', 'space'), 7.823807847279271e-05),\n",
       " (('study', 'used'), 7.823807847279271e-05),\n",
       " (('system', 'city'), 7.823807847279271e-05),\n",
       " (('take', 'account'), 7.823807847279271e-05),\n",
       " (('total', 'number'), 7.823807847279271e-05),\n",
       " (('united', 'state'), 7.823807847279271e-05),\n",
       " (('urban', 'context'), 7.823807847279271e-05),\n",
       " (('urban', 'robot'), 7.823807847279271e-05),\n",
       " (('virtual', 'space'), 7.823807847279271e-05),\n",
       " (('affected', 'walking'), 7.334819856824316e-05),\n",
       " (('ai', 'planning'), 7.334819856824316e-05),\n",
       " (('ai', 'project'), 7.334819856824316e-05),\n",
       " (('ai', 'research'), 7.334819856824316e-05),\n",
       " (('artificial', 'bee'), 7.334819856824316e-05),\n",
       " (('better', 'understand'), 7.334819856824316e-05),\n",
       " (('city', 'model'), 7.334819856824316e-05),\n",
       " (('civil', 'servant'), 7.334819856824316e-05),\n",
       " (('creative', 'common'), 7.334819856824316e-05),\n",
       " (('dynamic', 'urban'), 7.334819856824316e-05),\n",
       " (('f', 'biljecki'), 7.334819856824316e-05),\n",
       " (('gender', 'age'), 7.334819856824316e-05),\n",
       " (('impact', 'ai'), 7.334819856824316e-05),\n",
       " (('impact', 'nature'), 7.334819856824316e-05),\n",
       " (('infrastructure', 'planning'), 7.334819856824316e-05),\n",
       " (('j', 'wang'), 7.334819856824316e-05),\n",
       " (('learning', 'urban'), 7.334819856824316e-05),\n",
       " (('lidar', 'point'), 7.334819856824316e-05),\n",
       " (('model', 'urban'), 7.334819856824316e-05),\n",
       " (('naver', 'street'), 7.334819856824316e-05),\n",
       " (('p', 'p'), 7.334819856824316e-05),\n",
       " (('past', 'decade'), 7.334819856824316e-05),\n",
       " (('planning', 'decision'), 7.334819856824316e-05),\n",
       " (('planning', 'practice'), 7.334819856824316e-05),\n",
       " (('pro', 'ce'), 7.334819856824316e-05),\n",
       " (('problem', 'using'), 7.334819856824316e-05),\n",
       " (('proposed', 'approach'), 7.334819856824316e-05),\n",
       " (('public', 'policy'), 7.334819856824316e-05),\n",
       " (('roo', 'claudia'), 7.334819856824316e-05),\n",
       " (('rst', 'step'), 7.334819856824316e-05),\n",
       " (('running', 'time'), 7.334819856824316e-05),\n",
       " (('seoul', 'floating'), 7.334819856824316e-05),\n",
       " (('silva', 'future'), 7.334819856824316e-05),\n",
       " (('sub', 'cluster'), 7.334819856824316e-05),\n",
       " (('sus', 'tainable'), 7.334819856824316e-05),\n",
       " (('systematic', 'review'), 7.334819856824316e-05),\n",
       " (('transportation', 'unit'), 7.334819856824316e-05),\n",
       " (('urban', 'issue'), 7.334819856824316e-05),\n",
       " (('urban', 'morphology'), 7.334819856824316e-05),\n",
       " (('use', 'data'), 7.334819856824316e-05),\n",
       " (('use', 'technology'), 7.334819856824316e-05),\n",
       " (('used', 'reduce'), 7.334819856824316e-05),\n",
       " (('vertical', 'element'), 7.334819856824316e-05),\n",
       " (('world', 'matter'), 7.334819856824316e-05),\n",
       " (('aerial', 'image'), 6.845831866369362e-05),\n",
       " (('algorithm', 'biomimetic'), 6.845831866369362e-05),\n",
       " (('answer', 'question'), 6.845831866369362e-05),\n",
       " (('application', 'urban'), 6.845831866369362e-05),\n",
       " (('approach', 'urban'), 6.845831866369362e-05),\n",
       " (('art', 'culture'), 6.845831866369362e-05),\n",
       " (('articial', 'neural'), 6.845831866369362e-05),\n",
       " (('articially', 'intelligent'), 6.845831866369362e-05),\n",
       " (('automated', 'social'), 6.845831866369362e-05),\n",
       " (('biljecki', 'city'), 6.845831866369362e-05),\n",
       " (('city', 'agency'), 6.845831866369362e-05),\n",
       " (('city', 'complex'), 6.845831866369362e-05),\n",
       " (('communication', 'technology'), 6.845831866369362e-05),\n",
       " (('design', 'problem'), 6.845831866369362e-05),\n",
       " (('development', 'ai'), 6.845831866369362e-05),\n",
       " (('dif', 'ferent'), 6.845831866369362e-05),\n",
       " (('field', 'datadriven'), 6.845831866369362e-05),\n",
       " (('human', 'being'), 6.845831866369362e-05),\n",
       " (('human', 'planner'), 6.845831866369362e-05),\n",
       " (('important', 'role'), 6.845831866369362e-05),\n",
       " (('information', 'science'), 6.845831866369362e-05),\n",
       " (('interest', 'author'), 6.845831866369362e-05),\n",
       " (('j', 'urban'), 6.845831866369362e-05),\n",
       " (('negative', 'effect'), 6.845831866369362e-05),\n",
       " (('network', 'model'), 6.845831866369362e-05),\n",
       " (('new', 'business'), 6.845831866369362e-05),\n",
       " (('noise', 'level'), 6.845831866369362e-05),\n",
       " (('participatory', 'planning'), 6.845831866369362e-05),\n",
       " (('physical', 'environment'), 6.845831866369362e-05),\n",
       " (('plann', 'dev'), 6.845831866369362e-05),\n",
       " (('planning', 'system'), 6.845831866369362e-05),\n",
       " (('population', 'report'), 6.845831866369362e-05),\n",
       " (('predictive', 'model'), 6.845831866369362e-05),\n",
       " (('prefer', 'street'), 6.845831866369362e-05),\n",
       " (('prob', 'lem'), 6.845831866369362e-05),\n",
       " (('ref', 'yes'), 6.845831866369362e-05),\n",
       " (('residential', 'area'), 6.845831866369362e-05),\n",
       " (('rise', 'autonomous'), 6.845831866369362e-05),\n",
       " (('robotic', 'process'), 6.845831866369362e-05),\n",
       " (('san', 'francisco'), 6.845831866369362e-05),\n",
       " (('service', 'delivery'), 6.845831866369362e-05),\n",
       " (('smart', 'urban'), 6.845831866369362e-05),\n",
       " (('tech', 'nology'), 6.845831866369362e-05),\n",
       " (('technology', 'urban'), 6.845831866369362e-05),\n",
       " (('treatment', 'assignment'), 6.845831866369362e-05),\n",
       " (('urban', 'big'), 6.845831866369362e-05),\n",
       " (('urban', 'datamining'), 6.845831866369362e-05),\n",
       " (('urban', 'plann'), 6.845831866369362e-05),\n",
       " (('value', 'value'), 6.845831866369362e-05),\n",
       " (('wang', 'f'), 6.845831866369362e-05),\n",
       " (('way', 'conditioning'), 6.845831866369362e-05),\n",
       " (('within', 'virtual'), 6.845831866369362e-05),\n",
       " (('adopt', 'ai'), 6.356843875914407e-05),\n",
       " (('agricultural', 'land'), 6.356843875914407e-05),\n",
       " (('ai', 'knowledge'), 6.356843875914407e-05),\n",
       " (('ai', 'might'), 6.356843875914407e-05),\n",
       " (('algorithm', 'used'), 6.356843875914407e-05),\n",
       " (('application', 'challenge'), 6.356843875914407e-05),\n",
       " (('architectural', 'urban'), 6.356843875914407e-05),\n",
       " (('average', 'treatment'), 6.356843875914407e-05),\n",
       " (('bibri', 'krogstie'), 6.356843875914407e-05),\n",
       " (('bootstrap', 'sampling'), 6.356843875914407e-05),\n",
       " (('challenge', 'ai'), 6.356843875914407e-05),\n",
       " (('city', 'future'), 6.356843875914407e-05),\n",
       " (('city', 'technology'), 6.356843875914407e-05),\n",
       " (('computer', 'scientist'), 6.356843875914407e-05),\n",
       " (('context', 'urban'), 6.356843875914407e-05),\n",
       " (('control', 'system'), 6.356843875914407e-05),\n",
       " (('data', 'different'), 6.356843875914407e-05),\n",
       " (('dence', 'interval'), 6.356843875914407e-05),\n",
       " (('dependence', 'plot'), 6.356843875914407e-05),\n",
       " (('deployment', 'ai'), 6.356843875914407e-05),\n",
       " (('descriptive', 'analysis'), 6.356843875914407e-05),\n",
       " (('design', 'quality'), 6.356843875914407e-05),\n",
       " (('design', 'research'), 6.356843875914407e-05),\n",
       " (('development', 'city'), 6.356843875914407e-05),\n",
       " (('digital', 'twin'), 6.356843875914407e-05),\n",
       " (('edge', 'computing'), 6.356843875914407e-05),\n",
       " (('element', 'make'), 6.356843875914407e-05),\n",
       " (('fake', 'news'), 6.356843875914407e-05),\n",
       " (('human', 'planning'), 6.356843875914407e-05),\n",
       " (('hybrid', 'planning'), 6.356843875914407e-05),\n",
       " (('hybrid', 'role'), 6.356843875914407e-05),\n",
       " (('improve', 'urban'), 6.356843875914407e-05),\n",
       " (('information', 'communication'), 6.356843875914407e-05),\n",
       " (('instrumental', 'value'), 6.356843875914407e-05),\n",
       " (('instrumental', 'variable'), 6.356843875914407e-05),\n",
       " (('lack', 'transparency'), 6.356843875914407e-05),\n",
       " (('largescale', 'urban'), 6.356843875914407e-05),\n",
       " (('layer', 'city'), 6.356843875914407e-05),\n",
       " (('learning', 'computer'), 6.356843875914407e-05),\n",
       " (('linearly', 'separable'), 6.356843875914407e-05),\n",
       " (('make', 'possible'), 6.356843875914407e-05),\n",
       " (('may', 'also'), 6.356843875914407e-05),\n",
       " (('medium', 'platform'), 6.356843875914407e-05),\n",
       " (('mentioned', 'earlier'), 6.356843875914407e-05),\n",
       " (('mobile', 'phone'), 6.356843875914407e-05),\n",
       " (('model', 'model'), 6.356843875914407e-05),\n",
       " (('modeling', 'simulation'), 6.356843875914407e-05),\n",
       " (('narrow', 'intelligence'), 6.356843875914407e-05),\n",
       " (('new', 'opportunity'), 6.356843875914407e-05),\n",
       " (('next', 'section'), 6.356843875914407e-05),\n",
       " (('next', 'step'), 6.356843875914407e-05),\n",
       " (('pedestrian', 'environment'), 6.356843875914407e-05),\n",
       " (('planning', 'domain'), 6.356843875914407e-05),\n",
       " (('planning', 'manuscript'), 6.356843875914407e-05),\n",
       " (('point', 'view'), 6.356843875914407e-05),\n",
       " (('population', 'growth'), 6.356843875914407e-05),\n",
       " (('positive', 'shapley'), 6.356843875914407e-05),\n",
       " (('processing', 'data'), 6.356843875914407e-05),\n",
       " (('related', 'work'), 6.356843875914407e-05),\n",
       " (('research', 'question'), 6.356843875914407e-05),\n",
       " (('residential', 'inll'), 6.356843875914407e-05),\n",
       " (('see', 'also'), 6.356843875914407e-05),\n",
       " (('service', 'application'), 6.356843875914407e-05),\n",
       " (('shap', 'dependence'), 6.356843875914407e-05),\n",
       " (('significant', 'challenge'), 6.356843875914407e-05),\n",
       " (('social', 'environmental'), 6.356843875914407e-05),\n",
       " (('socioeconomic', 'environmental'), 6.356843875914407e-05),\n",
       " (('solution', 'cost'), 6.356843875914407e-05),\n",
       " (('sys', 'tems'), 6.356843875914407e-05),\n",
       " (('total', 'travel'), 6.356843875914407e-05),\n",
       " (('trafc', 'flow'), 6.356843875914407e-05),\n",
       " (('uiip', 'lagos'), 6.356843875914407e-05),\n",
       " (('understanding', 'city'), 6.356843875914407e-05),\n",
       " (('urban', 'function'), 6.356843875914407e-05),\n",
       " (('urban', 'informality'), 6.356843875914407e-05),\n",
       " (('urban', 'phenomenon'), 6.356843875914407e-05),\n",
       " (('urban', 'project'), 6.356843875914407e-05),\n",
       " (('use', 'urban'), 6.356843875914407e-05),\n",
       " (('using', 'computer'), 6.356843875914407e-05),\n",
       " (('various', 'urban'), 6.356843875914407e-05),\n",
       " (('view', 'image'), 6.356843875914407e-05),\n",
       " (('w', 'chen'), 6.356843875914407e-05),\n",
       " (('zoning', 'map'), 6.356843875914407e-05),\n",
       " (('academic', 'scientific'), 5.867855885459453e-05),\n",
       " (('accessed', 'future'), 5.867855885459453e-05),\n",
       " (('accessed', 'last'), 5.867855885459453e-05),\n",
       " (('adoption', 'challenge'), 5.867855885459453e-05),\n",
       " (('agency', 'computation'), 5.867855885459453e-05),\n",
       " (('ai', 'agedcare'), 5.867855885459453e-05),\n",
       " (('ai', 'experience'), 5.867855885459453e-05),\n",
       " (('ai', 'feel'), 5.867855885459453e-05),\n",
       " (('ai', 'rise'), 5.867855885459453e-05),\n",
       " (('ai', 'would'), 5.867855885459453e-05),\n",
       " (('allowed', 'u'), 5.867855885459453e-05),\n",
       " (('allows', 'u'), 5.867855885459453e-05),\n",
       " (('analysis', 'data'), 5.867855885459453e-05),\n",
       " (('ann', 'architecture'), 5.867855885459453e-05),\n",
       " (('applica', 'tions'), 5.867855885459453e-05),\n",
       " (('applied', 'artificial'), 5.867855885459453e-05),\n",
       " (('area', 'research'), 5.867855885459453e-05),\n",
       " (('around', 'world'), 5.867855885459453e-05),\n",
       " (('autonomous', 'vehicle'), 5.867855885459453e-05),\n",
       " (('c', 'c'), 5.867855885459453e-05),\n",
       " (('challenge', 'adopting'), 5.867855885459453e-05),\n",
       " (('change', 'urban'), 5.867855885459453e-05),\n",
       " (('chen', 'city'), 5.867855885459453e-05),\n",
       " (('city', 'government'), 5.867855885459453e-05),\n",
       " (('com', 'puters'), 5.867855885459453e-05),\n",
       " (('computation', 'big'), 5.867855885459453e-05),\n",
       " (('computer', 'model'), 5.867855885459453e-05),\n",
       " (('construction', 'site'), 5.867855885459453e-05),\n",
       " (('context', 'smart'), 5.867855885459453e-05),\n",
       " (('corresponding', 'author'), 5.867855885459453e-05),\n",
       " (('cost', 'saving'), 5.867855885459453e-05),\n",
       " (('data', 'acquisition'), 5.867855885459453e-05),\n",
       " (('data', 'revolution'), 5.867855885459453e-05),\n",
       " (('data', 'space'), 5.867855885459453e-05),\n",
       " (('data', 'technology'), 5.867855885459453e-05),\n",
       " (('decision', 'made'), 5.867855885459453e-05),\n",
       " (('delivery', 'urban'), 5.867855885459453e-05),\n",
       " (('design', 'development'), 5.867855885459453e-05),\n",
       " (('development', 'goal'), 5.867855885459453e-05),\n",
       " (('emergency', 'service'), 5.867855885459453e-05),\n",
       " (('environment', 'urban'), 5.867855885459453e-05),\n",
       " (('even', 'though'), 5.867855885459453e-05),\n",
       " (('extraction', 'pca'), 5.867855885459453e-05),\n",
       " (('factor', 'extraction'), 5.867855885459453e-05),\n",
       " (('feel', 'use'), 5.867855885459453e-05),\n",
       " (('figure', 'describes'), 5.867855885459453e-05),\n",
       " (('form', 'urban'), 5.867855885459453e-05),\n",
       " (('four', 'goal'), 5.867855885459453e-05),\n",
       " (('future', 'application'), 5.867855885459453e-05),\n",
       " (('good', 'result'), 5.867855885459453e-05),\n",
       " (('governance', 'metagovernance'), 5.867855885459453e-05),\n",
       " (('help', 'local'), 5.867855885459453e-05),\n",
       " (('heuristic', 'agency'), 5.867855885459453e-05),\n",
       " (('human', 'life'), 5.867855885459453e-05),\n",
       " (('lack', 'clarity'), 5.867855885459453e-05),\n",
       " (('management', 'planning'), 5.867855885459453e-05),\n",
       " (('model', 'selection'), 5.867855885459453e-05),\n",
       " (('modeling', 'lda'), 5.867855885459453e-05),\n",
       " (('natural', 'resource'), 5.867855885459453e-05),\n",
       " (('network', 'framing'), 5.867855885459453e-05),\n",
       " (('oa', 'achieved'), 5.867855885459453e-05),\n",
       " (('one', 'main'), 5.867855885459453e-05),\n",
       " (('open', 'space'), 5.867855885459453e-05),\n",
       " (('optimal', 'solution'), 5.867855885459453e-05),\n",
       " (('parameter', 'estimate'), 5.867855885459453e-05),\n",
       " (('perfor', 'mance'), 5.867855885459453e-05),\n",
       " (('period', 'time'), 5.867855885459453e-05),\n",
       " (('planning', 'issue'), 5.867855885459453e-05),\n",
       " (('policy', 'goal'), 5.867855885459453e-05),\n",
       " (('policy', 'planning'), 5.867855885459453e-05),\n",
       " (('positively', 'affected'), 5.867855885459453e-05),\n",
       " (('precision', 'recall'), 5.867855885459453e-05),\n",
       " (('predictive', 'performance'), 5.867855885459453e-05),\n",
       " (('problem', 'urban'), 5.867855885459453e-05),\n",
       " (('proposed', 'method'), 5.867855885459453e-05),\n",
       " (('proposed', 'model'), 5.867855885459453e-05),\n",
       " (('public', 'governance'), 5.867855885459453e-05),\n",
       " (('public', 'opinion'), 5.867855885459453e-05),\n",
       " (('r', 'c'), 5.867855885459453e-05),\n",
       " (('recent', 'study'), 5.867855885459453e-05),\n",
       " (('regression', 'model'), 5.867855885459453e-05),\n",
       " (('related', 'urban'), 5.867855885459453e-05),\n",
       " (('research', 'field'), 5.867855885459453e-05),\n",
       " (('review', 'table'), 5.867855885459453e-05),\n",
       " (('road', 'proportion'), 5.867855885459453e-05),\n",
       " (('role', 'variant'), 5.867855885459453e-05),\n",
       " (('satisfaction', 'score'), 5.867855885459453e-05),\n",
       " (('science', 'urban'), 5.867855885459453e-05),\n",
       " (('showed', 'positive'), 5.867855885459453e-05),\n",
       " (('spa', 'area'), 5.867855885459453e-05),\n",
       " (('space', 'material'), 5.867855885459453e-05),\n",
       " (('surrounding', 'environment'), 5.867855885459453e-05),\n",
       " (('sus', 'tainability'), 5.867855885459453e-05),\n",
       " (('technolo', 'gy'), 5.867855885459453e-05),\n",
       " (('term', 'ai'), 5.867855885459453e-05),\n",
       " (('term', 'trafc'), 5.867855885459453e-05),\n",
       " (('thematic', 'issue'), 5.867855885459453e-05),\n",
       " (('time', 'space'), 5.867855885459453e-05),\n",
       " (('two', 'type'), 5.867855885459453e-05),\n",
       " (('understanding', 'urban'), 5.867855885459453e-05),\n",
       " (('urban', 'actor'), 5.867855885459453e-05),\n",
       " (('urban', 'affair'), 5.867855885459453e-05),\n",
       " (('urban', 'analysis'), 5.867855885459453e-05),\n",
       " (('urban', 'sprawl'), 5.867855885459453e-05),\n",
       " (('used', 'monitor'), 5.867855885459453e-05),\n",
       " (('value', 'proportion'), 5.867855885459453e-05),\n",
       " (('vector', 'machine'), 5.867855885459453e-05),\n",
       " (('vision', 'algorithm'), 5.867855885459453e-05),\n",
       " (('volume', 'issue'), 5.867855885459453e-05),\n",
       " (('within', 'city'), 5.867855885459453e-05),\n",
       " (('able', 'urbanism'), 5.378867895004499e-05),\n",
       " (('across', 'city'), 5.378867895004499e-05),\n",
       " (('affair', 'review'), 5.378867895004499e-05),\n",
       " (('affect', 'pedestrian'), 5.378867895004499e-05),\n",
       " (('ai', 'development'), 5.378867895004499e-05),\n",
       " (('ai', 'future'), 5.378867895004499e-05),\n",
       " (('ai', 'implementation'), 5.378867895004499e-05),\n",
       " (('ai', 'perception'), 5.378867895004499e-05),\n",
       " (('among', 'others'), 5.378867895004499e-05),\n",
       " (('analysis', 'city'), 5.378867895004499e-05),\n",
       " (('analytical', 'question'), 5.378867895004499e-05),\n",
       " (('analytics', 'urban'), 5.378867895004499e-05),\n",
       " (('anns', 'deep'), 5.378867895004499e-05),\n",
       " (('application', 'type'), 5.378867895004499e-05),\n",
       " (('articial', 'narrow'), 5.378867895004499e-05),\n",
       " (('athey', 'imbens'), 5.378867895004499e-05),\n",
       " (('attribute', 'data'), 5.378867895004499e-05),\n",
       " (('automation', 'public'), 5.378867895004499e-05),\n",
       " (('b', 'wang'), 5.378867895004499e-05),\n",
       " (('behavioural', 'condition'), 5.378867895004499e-05),\n",
       " (('biomimetic', 'appro'), 5.378867895004499e-05),\n",
       " (('change', 'city'), 5.378867895004499e-05),\n",
       " (('change', 'detection'), 5.378867895004499e-05),\n",
       " (('city', 'development'), 5.378867895004499e-05),\n",
       " (('city', 'see'), 5.378867895004499e-05),\n",
       " (('civil', 'engineering'), 5.378867895004499e-05),\n",
       " (('cluster', 'community'), 5.378867895004499e-05),\n",
       " (('clustering', 'multiple'), 5.378867895004499e-05),\n",
       " (('collected', 'data'), 5.378867895004499e-05),\n",
       " (('commercial', 'industrial'), 5.378867895004499e-05),\n",
       " (('conceptual', 'framework'), 5.378867895004499e-05),\n",
       " (('concern', 'ai'), 5.378867895004499e-05),\n",
       " (('conflict', 'interest'), 5.378867895004499e-05),\n",
       " (('daily', 'life'), 5.378867895004499e-05),\n",
       " (('data', 'ai'), 5.378867895004499e-05),\n",
       " (('data', 'approach'), 5.378867895004499e-05),\n",
       " (('data', 'based'), 5.378867895004499e-05),\n",
       " (('data', 'system'), 5.378867895004499e-05),\n",
       " (('data', 'using'), 5.378867895004499e-05),\n",
       " (('data', 'well'), 5.378867895004499e-05),\n",
       " (('development', 'public'), 5.378867895004499e-05),\n",
       " (('different', 'form'), 5.378867895004499e-05),\n",
       " (('digital', 'data'), 5.378867895004499e-05),\n",
       " (('dna', 'region'), 5.378867895004499e-05),\n",
       " (('drone', 'image'), 5.378867895004499e-05),\n",
       " (('economic', 'growth'), 5.378867895004499e-05),\n",
       " (('effi', 'ciency'), 5.378867895004499e-05),\n",
       " (('enclosure', 'sum'), 5.378867895004499e-05),\n",
       " (('ent', 'urban'), 5.378867895004499e-05),\n",
       " (('environ', 'ment'), 5.378867895004499e-05),\n",
       " (('environm', 'ent'), 5.378867895004499e-05),\n",
       " (('environmental', 'infrastructure'), 5.378867895004499e-05),\n",
       " (('everyday', 'life'), 5.378867895004499e-05),\n",
       " (('framework', 'urban'), 5.378867895004499e-05),\n",
       " (('furniture', 'enclosure'), 5.378867895004499e-05),\n",
       " (('fuzzy', 'ant'), 5.378867895004499e-05),\n",
       " (('gaussian', 'function'), 5.378867895004499e-05),\n",
       " (('heuristic', 'h'), 5.378867895004499e-05),\n",
       " (('highest', 'satisfaction'), 5.378867895004499e-05),\n",
       " (('image', 'used'), 5.378867895004499e-05),\n",
       " (('implementing', 'ai'), 5.378867895004499e-05),\n",
       " (('independent', 'variable'), 5.378867895004499e-05),\n",
       " (('interdisciplinary', 'transdisciplinary'), 5.378867895004499e-05),\n",
       " (('j', 'kropp'), 5.378867895004499e-05),\n",
       " (('kernel', 'function'), 5.378867895004499e-05),\n",
       " (('knowl', 'edge'), 5.378867895004499e-05),\n",
       " (('knowledge', 'discovery'), 5.378867895004499e-05),\n",
       " (('land', 'usecover'), 5.378867895004499e-05),\n",
       " (('landuse', 'planning'), 5.378867895004499e-05),\n",
       " (('large', 'data'), 5.378867895004499e-05),\n",
       " (('layer', 'output'), 5.378867895004499e-05),\n",
       " (('lulc', 'map'), 5.378867895004499e-05),\n",
       " (('method', 'urban'), 5.378867895004499e-05),\n",
       " (('nal', 'impact'), 5.378867895004499e-05),\n",
       " (('network', 'management'), 5.378867895004499e-05),\n",
       " (('nonlinear', 'svm'), 5.378867895004499e-05),\n",
       " (('number', 'lane'), 5.378867895004499e-05),\n",
       " (('number', 'paper'), 5.378867895004499e-05),\n",
       " (('often', 'used'), 5.378867895004499e-05),\n",
       " (('one', 'another'), 5.378867895004499e-05),\n",
       " (('online', 'community'), 5.378867895004499e-05),\n",
       " (('open', 'source'), 5.378867895004499e-05),\n",
       " (('optimal', 'hyperplane'), 5.378867895004499e-05),\n",
       " (('paper', 'also'), 5.378867895004499e-05),\n",
       " (('paradigm', 'shift'), 5.378867895004499e-05),\n",
       " (('passenger', 'bus'), 5.378867895004499e-05),\n",
       " (('pedestrian', 'prefer'), 5.378867895004499e-05),\n",
       " (('pems', 'dataset'), 5.378867895004499e-05),\n",
       " (('planning', 'condition'), 5.378867895004499e-05),\n",
       " (('planning', 'policy'), 5.378867895004499e-05),\n",
       " (('planning', 'situation'), 5.378867895004499e-05),\n",
       " (('political', 'goal'), 5.378867895004499e-05),\n",
       " (('positive', 'correlation'), 5.378867895004499e-05),\n",
       " (('positive', 'indicating'), 5.378867895004499e-05),\n",
       " (('potential', 'application'), 5.378867895004499e-05),\n",
       " (('predict', 'trafc'), 5.378867895004499e-05),\n",
       " (('private', 'sector'), 5.378867895004499e-05),\n",
       " (('probability', 'people'), 5.378867895004499e-05),\n",
       " (('public', 'health'), 5.378867895004499e-05),\n",
       " (('puters', 'environm'), 5.378867895004499e-05),\n",
       " (('question', 'whether'), 5.378867895004499e-05),\n",
       " (('rail', 'transit'), 5.378867895004499e-05),\n",
       " (('regional', 'dna'), 5.378867895004499e-05),\n",
       " (('research', 'area'), 5.378867895004499e-05),\n",
       " (('research', 'focus'), 5.378867895004499e-05),\n",
       " (('research', 'interest'), 5.378867895004499e-05),\n",
       " (('right', 'wrong'), 5.378867895004499e-05),\n",
       " (('robotisation', 'public'), 5.378867895004499e-05),\n",
       " (('salesman', 'problem'), 5.378867895004499e-05),\n",
       " (('satisfaction', 'however'), 5.378867895004499e-05),\n",
       " (('scenario', 'simulation'), 5.378867895004499e-05),\n",
       " (('search', 'process'), 5.378867895004499e-05),\n",
       " (('shed', 'light'), 5.378867895004499e-05),\n",
       " (('shown', 'table'), 5.378867895004499e-05),\n",
       " (('socioeconomic', 'characteristic'), 5.378867895004499e-05),\n",
       " (('space', 'attribute'), 5.378867895004499e-05),\n",
       " (('speci', 'cation'), 5.378867895004499e-05),\n",
       " (('state', 'art'), 5.378867895004499e-05),\n",
       " (('streetscape', 'image'), 5.378867895004499e-05),\n",
       " (('streetscape', 'people'), 5.378867895004499e-05),\n",
       " (('survey', 'data'), 5.378867895004499e-05),\n",
       " (('technique', 'used'), 5.378867895004499e-05),\n",
       " (('technology', 'used'), 5.378867895004499e-05),\n",
       " (('training', 'process'), 5.378867895004499e-05),\n",
       " (('united', 'nation'), 5.378867895004499e-05),\n",
       " (('urban', 'eld'), 5.378867895004499e-05),\n",
       " (('urban', 'fabric'), 5.378867895004499e-05),\n",
       " (('urban', 'pattern'), 5.378867895004499e-05),\n",
       " (('urbanization', 'growth'), 5.378867895004499e-05),\n",
       " (('use', 'case'), 5.378867895004499e-05),\n",
       " (('value', 'mostly'), 5.378867895004499e-05),\n",
       " (('within', 'urban'), 5.378867895004499e-05),\n",
       " (('across', 'globe'), 4.8898799045495445e-05),\n",
       " (('adoption', 'ai'), 4.8898799045495445e-05),\n",
       " (('ai', 'algorithm'), 4.8898799045495445e-05),\n",
       " (('ai', 'also'), 4.8898799045495445e-05),\n",
       " (('analysis', 'da'), 4.8898799045495445e-05),\n",
       " (('analysis', 'factor'), 4.8898799045495445e-05),\n",
       " (('applied', 'urban'), 4.8898799045495445e-05),\n",
       " (('approach', 'based'), 4.8898799045495445e-05),\n",
       " (('attribute', 'descriptive'), 4.8898799045495445e-05),\n",
       " (('average', 'running'), 4.8898799045495445e-05),\n",
       " (('best', 'model'), 4.8898799045495445e-05),\n",
       " (('better', 'understanding'), 4.8898799045495445e-05),\n",
       " (('building', 'block'), 4.8898799045495445e-05),\n",
       " (('building', 'openness'), 4.8898799045495445e-05),\n",
       " (('ca', 'model'), 4.8898799045495445e-05),\n",
       " (('capability', 'ai'), 4.8898799045495445e-05),\n",
       " (('challenge', 'facing'), 4.8898799045495445e-05),\n",
       " (('city', 'also'), 4.8898799045495445e-05),\n",
       " (('city', 'concept'), 4.8898799045495445e-05),\n",
       " (('city', 'los'), 4.8898799045495445e-05),\n",
       " (('city', 'might'), 4.8898799045495445e-05),\n",
       " (('classi', 'cation'), 4.8898799045495445e-05),\n",
       " (('coefficient', 'respectively'), 4.8898799045495445e-05),\n",
       " (('collaborative', 'innovation'), 4.8898799045495445e-05),\n",
       " (('com', 'puter'), 4.8898799045495445e-05),\n",
       " (('community', 'member'), 4.8898799045495445e-05),\n",
       " (('compact', 'urbanism'), 4.8898799045495445e-05),\n",
       " (('complexity', 'greenery'), 4.8898799045495445e-05),\n",
       " (('complexity', 'value'), 4.8898799045495445e-05),\n",
       " (('contemporary', 'city'), 4.8898799045495445e-05),\n",
       " (('contributing', 'factor'), 4.8898799045495445e-05),\n",
       " (('data', 'need'), 4.8898799045495445e-05),\n",
       " (('data', 'storage'), 4.8898799045495445e-05),\n",
       " (('datadriven', 'approach'), 4.8898799045495445e-05),\n",
       " (('deep', 'cnn'), 4.8898799045495445e-05),\n",
       " (('dependent', 'variable'), 4.8898799045495445e-05),\n",
       " (('design', 'solution'), 4.8898799045495445e-05),\n",
       " (('design', 'urban'), 4.8898799045495445e-05),\n",
       " (('different', 'discipline'), 4.8898799045495445e-05),\n",
       " (('different', 'level'), 4.8898799045495445e-05),\n",
       " (('digital', 'tool'), 4.8898799045495445e-05),\n",
       " (('dimension', 'urban'), 4.8898799045495445e-05),\n",
       " (('distance', 'nearest'), 4.8898799045495445e-05),\n",
       " (('economic', 'environmental'), 4.8898799045495445e-05),\n",
       " (('eindhoven', 'technology'), 4.8898799045495445e-05),\n",
       " (('environmental', 'factor'), 4.8898799045495445e-05),\n",
       " (('equivalent', 'sound'), 4.8898799045495445e-05),\n",
       " (('euclidean', 'distance'), 4.8898799045495445e-05),\n",
       " (('experience', 'ai'), 4.8898799045495445e-05),\n",
       " (('figure', 'figure'), 4.8898799045495445e-05),\n",
       " (('forest', 'xgboost'), 4.8898799045495445e-05),\n",
       " (('future', 'urbanization'), 4.8898799045495445e-05),\n",
       " (('g', 'grekousis'), 4.8898799045495445e-05),\n",
       " (('generate', 'new'), 4.8898799045495445e-05),\n",
       " (('geospatial', 'data'), 4.8898799045495445e-05),\n",
       " (('gmcts', 'ai'), 4.8898799045495445e-05),\n",
       " (('goal', 'urban'), 4.8898799045495445e-05),\n",
       " (('governance', 'network'), 4.8898799045495445e-05),\n",
       " (('government', 'financial'), 4.8898799045495445e-05),\n",
       " (('greenery', 'proportion'), 4.8898799045495445e-05),\n",
       " (('grekousis', 'com'), 4.8898799045495445e-05),\n",
       " (('ground', 'truth'), 4.8898799045495445e-05),\n",
       " (('high', 'probability'), 4.8898799045495445e-05),\n",
       " (('human', 'interaction'), 4.8898799045495445e-05),\n",
       " (('human', 'user'), 4.8898799045495445e-05),\n",
       " (('identi', 'cation'), 4.8898799045495445e-05),\n",
       " (('increase', 'total'), 4.8898799045495445e-05),\n",
       " (('instrumental', 'condition'), 4.8898799045495445e-05),\n",
       " (('integrated', 'system'), 4.8898799045495445e-05),\n",
       " (('inter', 'action'), 4.8898799045495445e-05),\n",
       " (('inter', 'alia'), 4.8898799045495445e-05),\n",
       " (('introduction', 'automated'), 4.8898799045495445e-05),\n",
       " (('investment', 'capability'), 4.8898799045495445e-05),\n",
       " (('journal', 'community'), 4.8898799045495445e-05),\n",
       " (('large', 'volume'), 4.8898799045495445e-05),\n",
       " (('learning', 'ai'), 4.8898799045495445e-05),\n",
       " (('learning', 'data'), 4.8898799045495445e-05),\n",
       " (('level', 'ai'), 4.8898799045495445e-05),\n",
       " (('limited', 'local'), 4.8898799045495445e-05),\n",
       " (('machine', 'metropolis'), 4.8898799045495445e-05),\n",
       " (('many', 'city'), 4.8898799045495445e-05),\n",
       " (('many', 'urban'), 4.8898799045495445e-05),\n",
       " (('masdar', 'city'), 4.8898799045495445e-05),\n",
       " (('maximum', 'input'), 4.8898799045495445e-05),\n",
       " (('meijer', 'thaens'), 4.8898799045495445e-05),\n",
       " (('melbourne', 'brisbane'), 4.8898799045495445e-05),\n",
       " (('method', 'applied'), 4.8898799045495445e-05),\n",
       " (('metropolis', 'introduction'), 4.8898799045495445e-05),\n",
       " (('ml', 'literature'), 4.8898799045495445e-05),\n",
       " (('model', 'design'), 4.8898799045495445e-05),\n",
       " (('monitor', 'respond'), 4.8898799045495445e-05),\n",
       " (('multilayer', 'perceptron'), 4.8898799045495445e-05),\n",
       " (('natural', 'environment'), 4.8898799045495445e-05),\n",
       " (('net', 'work'), 4.8898799045495445e-05),\n",
       " (('network', 'analysis'), 4.8898799045495445e-05),\n",
       " (('network', 'participation'), 4.8898799045495445e-05),\n",
       " (('one', 'important'), 4.8898799045495445e-05),\n",
       " (('open', 'data'), 4.8898799045495445e-05),\n",
       " (('paper', 'present'), 4.8898799045495445e-05),\n",
       " (('photo', 'g'), 4.8898799045495445e-05),\n",
       " (('physical', 'world'), 4.8898799045495445e-05),\n",
       " (('planning', 'authority'), 4.8898799045495445e-05),\n",
       " (('planning', 'education'), 4.8898799045495445e-05),\n",
       " (('positive', 'positive'), 4.8898799045495445e-05),\n",
       " (('prediction', 'model'), 4.8898799045495445e-05),\n",
       " (('prediction', 'urban'), 4.8898799045495445e-05),\n",
       " (('present', 'future'), 4.8898799045495445e-05),\n",
       " (('principal', 'component'), 4.8898799045495445e-05),\n",
       " (('problem', 'solved'), 4.8898799045495445e-05),\n",
       " (('public', 'transport'), 4.8898799045495445e-05),\n",
       " (('publiczne', 'public'), 4.8898799045495445e-05),\n",
       " (('ra', 'ai'), 4.8898799045495445e-05),\n",
       " (('ratio', 'le'), 4.8898799045495445e-05),\n",
       " (('reduce', 'public'), 4.8898799045495445e-05),\n",
       " (('research', 'design'), 4.8898799045495445e-05),\n",
       " (('research', 'direction'), 4.8898799045495445e-05),\n",
       " (('resource', 'investment'), 4.8898799045495445e-05),\n",
       " (('satellite', 'data'), 4.8898799045495445e-05),\n",
       " (('satellite', 'imagery'), 4.8898799045495445e-05),\n",
       " (('satisfying', 'walking'), 4.8898799045495445e-05),\n",
       " (('science', 'data'), 4.8898799045495445e-05),\n",
       " (('see', 'section'), 4.8898799045495445e-05),\n",
       " (('selforganizing', 'map'), 4.8898799045495445e-05),\n",
       " (('sensor', 'data'), 4.8898799045495445e-05),\n",
       " (('service', 'development'), 4.8898799045495445e-05),\n",
       " (('service', 'provision'), 4.8898799045495445e-05),\n",
       " (('social', 'network'), 4.8898799045495445e-05),\n",
       " ...]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder(word_fd, bigram_fd)\n",
    "finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting some topic modeling work in earnest\n",
    "#### `gensim` first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:07:59,235 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-03-12 23:07:59,438 : INFO : built Dictionary<17102 unique tokens: ['abandonment', 'ability', 'abortion', 'absence', 'absorb']...> from 74 documents (total 204504 corpus positions)\n",
      "2023-03-12 23:07:59,439 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<17102 unique tokens: ['abandonment', 'ability', 'abortion', 'absence', 'absorb']...> from 74 documents (total 204504 corpus positions)\", 'datetime': '2023-03-12T23:07:59.438992', 'gensim': '4.3.0', 'python': '3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2023-03-12 23:07:59,461 : INFO : discarding 9872 tokens: [('abortion', 1), ('abudayyeh', 1), ('abukhader', 1), ('aburumman', 1), ('accommodates', 1), ('adaptative', 1), ('afterward', 1), ('ahmadabad', 1), ('alhadidi', 1), ('alnsour', 1)]...\n",
      "2023-03-12 23:07:59,462 : INFO : keeping 7230 tokens which were in no less than 2 and no more than 37 (=50.0%) documents\n",
      "2023-03-12 23:07:59,509 : INFO : resulting dictionary: Dictionary<7230 unique tokens: ['abandonment', 'ability', 'absence', 'absorb', 'abstract']...>\n"
     ]
    }
   ],
   "source": [
    "#some gensim-specific preprocessing\n",
    "dictionary = corpora.Dictionary(corpus) #unflattened corpus\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.50)\n",
    "corpus = [dictionary.doc2bow(text) for text in corpus] # vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 7230\n",
      "Number of documents: 74\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 7\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "#save these params with no below 2 no above .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:09:01,906 : INFO : using autotuned alpha, starting with [0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715]\n",
      "2023-03-12 23:09:01,914 : INFO : using serial LDA version on this node\n",
      "2023-03-12 23:09:01,922 : INFO : running online (multi-pass) LDA training, 7 topics, 20 passes over the supplied corpus of 74 documents, updating model once every 74 documents, evaluating perplexity every 74 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2023-03-12 23:09:03,075 : INFO : -9.675 per-word bound, 817.2 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:03,076 : INFO : PROGRESS: pass 0, at document #74/74\n",
      "2023-03-12 23:09:03,961 : INFO : optimized alpha [0.14779961, 0.155903, 0.16828609, 0.1411346, 0.13582204, 0.17002149, 0.13924336]\n",
      "2023-03-12 23:09:03,970 : INFO : topic #4 (0.136): 0.019*\"ai\" + 0.007*\"computer\" + 0.006*\"design\" + 0.005*\"science\" + 0.005*\"human\" + 0.004*\"sustainable\" + 0.004*\"service\" + 0.004*\"smart\" + 0.004*\"innovation\" + 0.004*\"local\"\n",
      "2023-03-12 23:09:03,972 : INFO : topic #6 (0.139): 0.031*\"ai\" + 0.005*\"local\" + 0.004*\"nature\" + 0.004*\"community\" + 0.004*\"service\" + 0.004*\"design\" + 0.004*\"human\" + 0.004*\"challenge\" + 0.004*\"algorithm\" + 0.003*\"trafc\"\n",
      "2023-03-12 23:09:03,976 : INFO : topic #1 (0.156): 0.005*\"goal\" + 0.005*\"ai\" + 0.005*\"value\" + 0.005*\"figure\" + 0.005*\"space\" + 0.005*\"land\" + 0.004*\"design\" + 0.004*\"smart\" + 0.003*\"algorithm\" + 0.003*\"spatial\"\n",
      "2023-03-12 23:09:03,980 : INFO : topic #2 (0.168): 0.007*\"image\" + 0.006*\"science\" + 0.006*\"algorithm\" + 0.005*\"smart\" + 0.005*\"value\" + 0.005*\"walking\" + 0.004*\"street\" + 0.003*\"service\" + 0.003*\"solution\" + 0.003*\"computer\"\n",
      "2023-03-12 23:09:03,985 : INFO : topic #5 (0.170): 0.006*\"planner\" + 0.005*\"role\" + 0.004*\"design\" + 0.004*\"smart\" + 0.004*\"value\" + 0.004*\"knowledge\" + 0.004*\"ai\" + 0.004*\"innovation\" + 0.004*\"service\" + 0.004*\"goal\"\n",
      "2023-03-12 23:09:03,987 : INFO : topic diff=2.200355, rho=1.000000\n",
      "2023-03-12 23:09:04,742 : INFO : -8.035 per-word bound, 262.2 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:04,742 : INFO : PROGRESS: pass 1, at document #74/74\n",
      "2023-03-12 23:09:05,145 : INFO : optimized alpha [0.11177364, 0.10573362, 0.12754735, 0.10445285, 0.097476125, 0.12497268, 0.09093778]\n",
      "2023-03-12 23:09:05,152 : INFO : topic #6 (0.091): 0.044*\"ai\" + 0.007*\"local\" + 0.007*\"service\" + 0.006*\"challenge\" + 0.005*\"nature\" + 0.005*\"government\" + 0.005*\"participant\" + 0.005*\"design\" + 0.005*\"community\" + 0.005*\"algorithm\"\n",
      "2023-03-12 23:09:05,155 : INFO : topic #4 (0.097): 0.016*\"ai\" + 0.009*\"computer\" + 0.008*\"design\" + 0.008*\"science\" + 0.008*\"sustainable\" + 0.006*\"smart\" + 0.006*\"sustainability\" + 0.005*\"human\" + 0.004*\"intelligence\" + 0.004*\"technological\"\n",
      "2023-03-12 23:09:05,159 : INFO : topic #0 (0.112): 0.027*\"ai\" + 0.007*\"human\" + 0.006*\"intelligence\" + 0.005*\"space\" + 0.005*\"service\" + 0.005*\"articial\" + 0.004*\"community\" + 0.004*\"car\" + 0.004*\"autonomous\" + 0.004*\"design\"\n",
      "2023-03-12 23:09:05,174 : INFO : topic #5 (0.125): 0.008*\"planner\" + 0.006*\"role\" + 0.005*\"knowledge\" + 0.005*\"service\" + 0.005*\"innovation\" + 0.005*\"value\" + 0.004*\"robot\" + 0.004*\"smart\" + 0.004*\"different\" + 0.004*\"management\"\n",
      "2023-03-12 23:09:05,202 : INFO : topic #2 (0.128): 0.008*\"image\" + 0.006*\"value\" + 0.006*\"science\" + 0.006*\"algorithm\" + 0.006*\"smart\" + 0.005*\"street\" + 0.005*\"walking\" + 0.004*\"satisfaction\" + 0.004*\"figure\" + 0.004*\"point\"\n",
      "2023-03-12 23:09:05,207 : INFO : topic diff=0.613691, rho=0.577350\n",
      "2023-03-12 23:09:05,754 : INFO : -7.881 per-word bound, 235.7 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:05,755 : INFO : PROGRESS: pass 2, at document #74/74\n",
      "2023-03-12 23:09:06,025 : INFO : optimized alpha [0.09212586, 0.08766085, 0.10703264, 0.08789627, 0.07909444, 0.1051063, 0.07151918]\n",
      "2023-03-12 23:09:06,033 : INFO : topic #6 (0.072): 0.052*\"ai\" + 0.009*\"service\" + 0.009*\"local\" + 0.007*\"government\" + 0.006*\"challenge\" + 0.006*\"participant\" + 0.006*\"nature\" + 0.005*\"design\" + 0.005*\"algorithm\" + 0.005*\"resource\"\n",
      "2023-03-12 23:09:06,034 : INFO : topic #4 (0.079): 0.013*\"science\" + 0.012*\"ai\" + 0.011*\"sustainable\" + 0.010*\"smart\" + 0.009*\"design\" + 0.009*\"computer\" + 0.008*\"sustainability\" + 0.006*\"urbanism\" + 0.005*\"human\" + 0.005*\"intelligence\"\n",
      "2023-03-12 23:09:06,036 : INFO : topic #0 (0.092): 0.026*\"ai\" + 0.007*\"human\" + 0.007*\"intelligence\" + 0.006*\"space\" + 0.005*\"articial\" + 0.005*\"community\" + 0.004*\"medium\" + 0.004*\"car\" + 0.004*\"autonomous\" + 0.004*\"virtual\"\n",
      "2023-03-12 23:09:06,037 : INFO : topic #5 (0.105): 0.008*\"planner\" + 0.007*\"role\" + 0.006*\"service\" + 0.006*\"innovation\" + 0.006*\"robot\" + 0.005*\"knowledge\" + 0.005*\"value\" + 0.005*\"different\" + 0.005*\"management\" + 0.005*\"governance\"\n",
      "2023-03-12 23:09:06,041 : INFO : topic #2 (0.107): 0.009*\"image\" + 0.007*\"value\" + 0.006*\"street\" + 0.006*\"algorithm\" + 0.006*\"walking\" + 0.005*\"science\" + 0.005*\"smart\" + 0.004*\"figure\" + 0.004*\"satisfaction\" + 0.004*\"point\"\n",
      "2023-03-12 23:09:06,043 : INFO : topic diff=0.504094, rho=0.500000\n",
      "2023-03-12 23:09:06,693 : INFO : -7.798 per-word bound, 222.6 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:06,695 : INFO : PROGRESS: pass 3, at document #74/74\n",
      "2023-03-12 23:09:06,928 : INFO : optimized alpha [0.08078795, 0.07640835, 0.094816186, 0.07802928, 0.07066166, 0.09326944, 0.06254531]\n",
      "2023-03-12 23:09:06,933 : INFO : topic #6 (0.063): 0.057*\"ai\" + 0.011*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.007*\"participant\" + 0.007*\"challenge\" + 0.006*\"nature\" + 0.005*\"design\" + 0.005*\"people\" + 0.005*\"table\"\n",
      "2023-03-12 23:09:06,935 : INFO : topic #4 (0.071): 0.015*\"science\" + 0.012*\"sustainable\" + 0.012*\"smart\" + 0.010*\"ai\" + 0.009*\"sustainability\" + 0.009*\"design\" + 0.008*\"computer\" + 0.008*\"urbanism\" + 0.006*\"datadriven\" + 0.005*\"big\"\n",
      "2023-03-12 23:09:06,938 : INFO : topic #0 (0.081): 0.024*\"ai\" + 0.008*\"human\" + 0.007*\"intelligence\" + 0.006*\"space\" + 0.006*\"articial\" + 0.005*\"community\" + 0.005*\"virtual\" + 0.005*\"medium\" + 0.005*\"car\" + 0.004*\"autonomous\"\n",
      "2023-03-12 23:09:06,953 : INFO : topic #5 (0.093): 0.009*\"planner\" + 0.007*\"role\" + 0.007*\"service\" + 0.006*\"innovation\" + 0.006*\"robot\" + 0.005*\"knowledge\" + 0.005*\"value\" + 0.005*\"different\" + 0.005*\"management\" + 0.005*\"governance\"\n",
      "2023-03-12 23:09:06,956 : INFO : topic #2 (0.095): 0.010*\"image\" + 0.007*\"value\" + 0.007*\"street\" + 0.007*\"algorithm\" + 0.007*\"walking\" + 0.005*\"figure\" + 0.005*\"satisfaction\" + 0.004*\"point\" + 0.004*\"performance\" + 0.004*\"proportion\"\n",
      "2023-03-12 23:09:06,975 : INFO : topic diff=0.391830, rho=0.447214\n",
      "2023-03-12 23:09:07,476 : INFO : -7.755 per-word bound, 216.1 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:07,476 : INFO : PROGRESS: pass 4, at document #74/74\n",
      "2023-03-12 23:09:07,787 : INFO : optimized alpha [0.07273516, 0.07167536, 0.08513563, 0.07186211, 0.0658466, 0.08466155, 0.056928128]\n",
      "2023-03-12 23:09:07,794 : INFO : topic #6 (0.057): 0.060*\"ai\" + 0.012*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.007*\"participant\" + 0.007*\"challenge\" + 0.006*\"nature\" + 0.005*\"design\" + 0.005*\"people\" + 0.005*\"table\"\n",
      "2023-03-12 23:09:07,797 : INFO : topic #4 (0.066): 0.016*\"science\" + 0.013*\"smart\" + 0.013*\"sustainable\" + 0.009*\"sustainability\" + 0.009*\"design\" + 0.008*\"urbanism\" + 0.008*\"ai\" + 0.008*\"computer\" + 0.006*\"datadriven\" + 0.006*\"big\"\n",
      "2023-03-12 23:09:07,803 : INFO : topic #0 (0.073): 0.022*\"ai\" + 0.008*\"human\" + 0.007*\"intelligence\" + 0.006*\"space\" + 0.006*\"articial\" + 0.006*\"virtual\" + 0.005*\"community\" + 0.005*\"medium\" + 0.005*\"world\" + 0.005*\"car\"\n",
      "2023-03-12 23:09:07,818 : INFO : topic #5 (0.085): 0.009*\"planner\" + 0.007*\"role\" + 0.007*\"service\" + 0.007*\"robot\" + 0.007*\"innovation\" + 0.005*\"knowledge\" + 0.005*\"automated\" + 0.005*\"different\" + 0.005*\"management\" + 0.005*\"governance\"\n",
      "2023-03-12 23:09:07,820 : INFO : topic #2 (0.085): 0.011*\"image\" + 0.008*\"value\" + 0.007*\"street\" + 0.007*\"algorithm\" + 0.007*\"walking\" + 0.005*\"figure\" + 0.005*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:09:07,822 : INFO : topic diff=0.300259, rho=0.408248\n",
      "2023-03-12 23:09:08,491 : INFO : -7.733 per-word bound, 212.7 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:08,492 : INFO : PROGRESS: pass 5, at document #74/74\n",
      "2023-03-12 23:09:08,850 : INFO : optimized alpha [0.06695892, 0.068093024, 0.07820139, 0.06727493, 0.062190406, 0.07787726, 0.053132262]\n",
      "2023-03-12 23:09:08,858 : INFO : topic #6 (0.053): 0.062*\"ai\" + 0.012*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"nature\" + 0.005*\"people\" + 0.005*\"resource\" + 0.005*\"table\"\n",
      "2023-03-12 23:09:08,860 : INFO : topic #4 (0.062): 0.017*\"science\" + 0.014*\"smart\" + 0.013*\"sustainable\" + 0.010*\"sustainability\" + 0.009*\"design\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"ai\" + 0.006*\"datadriven\" + 0.006*\"big\"\n",
      "2023-03-12 23:09:08,867 : INFO : topic #1 (0.068): 0.008*\"goal\" + 0.008*\"space\" + 0.008*\"land\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.004*\"value\" + 0.004*\"design\" + 0.004*\"growth\" + 0.004*\"noise\" + 0.004*\"human\"\n",
      "2023-03-12 23:09:08,875 : INFO : topic #5 (0.078): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"robot\" + 0.007*\"innovation\" + 0.005*\"automated\" + 0.005*\"different\" + 0.005*\"knowledge\" + 0.005*\"management\" + 0.005*\"governance\"\n",
      "2023-03-12 23:09:08,879 : INFO : topic #2 (0.078): 0.011*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.007*\"walking\" + 0.007*\"algorithm\" + 0.005*\"figure\" + 0.005*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:08,885 : INFO : topic diff=0.231286, rho=0.377964\n",
      "2023-03-12 23:09:09,505 : INFO : -7.721 per-word bound, 211.0 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:09,506 : INFO : PROGRESS: pass 6, at document #74/74\n",
      "2023-03-12 23:09:09,789 : INFO : optimized alpha [0.06298949, 0.06526808, 0.07349031, 0.0637336, 0.059714, 0.07283454, 0.05047723]\n",
      "2023-03-12 23:09:09,794 : INFO : topic #6 (0.050): 0.064*\"ai\" + 0.012*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"nature\" + 0.005*\"people\" + 0.005*\"resource\" + 0.005*\"perception\"\n",
      "2023-03-12 23:09:09,796 : INFO : topic #4 (0.060): 0.017*\"science\" + 0.015*\"smart\" + 0.013*\"sustainable\" + 0.010*\"sustainability\" + 0.009*\"design\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.006*\"datadriven\" + 0.006*\"big\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:09,800 : INFO : topic #1 (0.065): 0.009*\"goal\" + 0.008*\"space\" + 0.008*\"land\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.004*\"value\" + 0.004*\"growth\" + 0.004*\"noise\" + 0.004*\"design\" + 0.004*\"human\"\n",
      "2023-03-12 23:09:09,803 : INFO : topic #5 (0.073): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"robot\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.005*\"different\" + 0.005*\"management\" + 0.005*\"governance\" + 0.005*\"knowledge\"\n",
      "2023-03-12 23:09:09,805 : INFO : topic #2 (0.073): 0.011*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.007*\"walking\" + 0.007*\"algorithm\" + 0.005*\"figure\" + 0.005*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:09,806 : INFO : topic diff=0.180098, rho=0.353553\n",
      "2023-03-12 23:09:10,352 : INFO : -7.715 per-word bound, 210.1 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:10,353 : INFO : PROGRESS: pass 7, at document #74/74\n",
      "2023-03-12 23:09:10,636 : INFO : optimized alpha [0.05983462, 0.062568925, 0.06974742, 0.06087098, 0.05801528, 0.06887781, 0.04830416]\n",
      "2023-03-12 23:09:10,644 : INFO : topic #6 (0.048): 0.065*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"nature\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"resource\"\n",
      "2023-03-12 23:09:10,654 : INFO : topic #4 (0.058): 0.018*\"science\" + 0.015*\"smart\" + 0.013*\"sustainable\" + 0.010*\"sustainability\" + 0.009*\"design\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"datadriven\" + 0.006*\"big\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:10,659 : INFO : topic #1 (0.063): 0.009*\"goal\" + 0.008*\"space\" + 0.008*\"land\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.004*\"growth\" + 0.004*\"value\" + 0.004*\"noise\" + 0.004*\"human\" + 0.004*\"design\"\n",
      "2023-03-12 23:09:10,665 : INFO : topic #5 (0.069): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\" + 0.005*\"knowledge\"\n",
      "2023-03-12 23:09:10,682 : INFO : topic #2 (0.070): 0.012*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.007*\"algorithm\" + 0.005*\"figure\" + 0.005*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:10,688 : INFO : topic diff=0.141938, rho=0.333333\n",
      "2023-03-12 23:09:11,444 : INFO : -7.712 per-word bound, 209.7 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:11,445 : INFO : PROGRESS: pass 8, at document #74/74\n",
      "2023-03-12 23:09:11,816 : INFO : optimized alpha [0.057255007, 0.060336486, 0.06638782, 0.058509685, 0.056582127, 0.066428564, 0.04648796]\n",
      "2023-03-12 23:09:11,824 : INFO : topic #6 (0.046): 0.067*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"nature\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"resource\"\n",
      "2023-03-12 23:09:11,831 : INFO : topic #4 (0.057): 0.018*\"science\" + 0.016*\"smart\" + 0.013*\"sustainable\" + 0.010*\"design\" + 0.010*\"sustainability\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"big\" + 0.006*\"datadriven\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:11,839 : INFO : topic #1 (0.060): 0.009*\"goal\" + 0.008*\"space\" + 0.008*\"land\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.004*\"growth\" + 0.004*\"value\" + 0.004*\"noise\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:11,847 : INFO : topic #2 (0.066): 0.012*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"figure\" + 0.005*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:11,854 : INFO : topic #5 (0.066): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\" + 0.005*\"knowledge\"\n",
      "2023-03-12 23:09:11,862 : INFO : topic diff=0.113126, rho=0.316228\n",
      "2023-03-12 23:09:12,469 : INFO : -7.711 per-word bound, 209.5 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:12,470 : INFO : PROGRESS: pass 9, at document #74/74\n",
      "2023-03-12 23:09:12,762 : INFO : optimized alpha [0.05509709, 0.058451567, 0.06362322, 0.056521628, 0.05562877, 0.064381555, 0.044940535]\n",
      "2023-03-12 23:09:12,768 : INFO : topic #6 (0.045): 0.068*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.008*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"nature\" + 0.005*\"perception\" + 0.005*\"disaster\" + 0.005*\"people\"\n",
      "2023-03-12 23:09:12,773 : INFO : topic #0 (0.055): 0.017*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"virtual\" + 0.007*\"space\" + 0.006*\"articial\" + 0.006*\"world\" + 0.005*\"community\" + 0.005*\"medium\" + 0.005*\"condition\"\n",
      "2023-03-12 23:09:12,778 : INFO : topic #1 (0.058): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.004*\"noise\" + 0.004*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:12,782 : INFO : topic #2 (0.064): 0.012*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"figure\" + 0.006*\"satisfaction\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:12,784 : INFO : topic #5 (0.064): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\" + 0.005*\"automation\"\n",
      "2023-03-12 23:09:12,786 : INFO : topic diff=0.091185, rho=0.301511\n",
      "2023-03-12 23:09:13,442 : INFO : -7.710 per-word bound, 209.4 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:13,443 : INFO : PROGRESS: pass 10, at document #74/74\n",
      "2023-03-12 23:09:13,676 : INFO : optimized alpha [0.053266652, 0.057119932, 0.061311834, 0.05482783, 0.05480203, 0.06264727, 0.043807242]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:09:13,682 : INFO : topic #6 (0.044): 0.069*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"nature\" + 0.005*\"people\"\n",
      "2023-03-12 23:09:13,683 : INFO : topic #0 (0.053): 0.017*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"virtual\" + 0.007*\"space\" + 0.006*\"articial\" + 0.006*\"world\" + 0.005*\"condition\" + 0.005*\"medium\" + 0.005*\"community\"\n",
      "2023-03-12 23:09:13,687 : INFO : topic #1 (0.057): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.004*\"noise\" + 0.004*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:13,692 : INFO : topic #2 (0.061): 0.012*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:13,695 : INFO : topic #5 (0.063): 0.009*\"planner\" + 0.007*\"service\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.005*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:13,697 : INFO : topic diff=0.074414, rho=0.288675\n",
      "2023-03-12 23:09:14,247 : INFO : -7.710 per-word bound, 209.4 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:14,248 : INFO : PROGRESS: pass 11, at document #74/74\n",
      "2023-03-12 23:09:14,417 : INFO : optimized alpha [0.05168698, 0.055958487, 0.059341535, 0.053360518, 0.054070763, 0.06115015, 0.042997636]\n",
      "2023-03-12 23:09:14,425 : INFO : topic #6 (0.043): 0.070*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:14,426 : INFO : topic #0 (0.052): 0.016*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.005*\"condition\" + 0.005*\"design\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:14,429 : INFO : topic #1 (0.056): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.004*\"noise\" + 0.004*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:14,430 : INFO : topic #2 (0.059): 0.012*\"image\" + 0.008*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:14,432 : INFO : topic #5 (0.061): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:14,439 : INFO : topic diff=0.061503, rho=0.277350\n",
      "2023-03-12 23:09:15,089 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:15,091 : INFO : PROGRESS: pass 12, at document #74/74\n",
      "2023-03-12 23:09:15,443 : INFO : optimized alpha [0.050518304, 0.054935727, 0.057641327, 0.05207692, 0.053419594, 0.05984472, 0.04227694]\n",
      "2023-03-12 23:09:15,450 : INFO : topic #6 (0.042): 0.071*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:15,451 : INFO : topic #0 (0.051): 0.016*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.005*\"condition\" + 0.005*\"design\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:15,452 : INFO : topic #1 (0.055): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:15,454 : INFO : topic #2 (0.058): 0.012*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:15,457 : INFO : topic #5 (0.060): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:15,458 : INFO : topic diff=0.051455, rho=0.267261\n",
      "2023-03-12 23:09:16,201 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:16,202 : INFO : PROGRESS: pass 13, at document #74/74\n",
      "2023-03-12 23:09:16,397 : INFO : optimized alpha [0.04970617, 0.05402784, 0.05615881, 0.05094466, 0.052836407, 0.058696914, 0.041630264]\n",
      "2023-03-12 23:09:16,404 : INFO : topic #6 (0.042): 0.072*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:16,409 : INFO : topic #0 (0.050): 0.015*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.005*\"condition\" + 0.005*\"design\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:16,416 : INFO : topic #1 (0.054): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:16,420 : INFO : topic #2 (0.056): 0.012*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:16,425 : INFO : topic #5 (0.059): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:16,426 : INFO : topic diff=0.043611, rho=0.258199\n",
      "2023-03-12 23:09:16,868 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:16,869 : INFO : PROGRESS: pass 14, at document #74/74\n",
      "2023-03-12 23:09:17,070 : INFO : optimized alpha [0.04897747, 0.053210814, 0.054846406, 0.049932968, 0.05230575, 0.05767371, 0.041042723]\n",
      "2023-03-12 23:09:17,077 : INFO : topic #6 (0.041): 0.073*\"ai\" + 0.013*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:17,078 : INFO : topic #0 (0.049): 0.015*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"condition\" + 0.005*\"design\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:17,084 : INFO : topic #1 (0.053): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:17,089 : INFO : topic #2 (0.055): 0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:17,091 : INFO : topic #5 (0.058): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"role\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:17,092 : INFO : topic diff=0.037379, rho=0.250000\n",
      "2023-03-12 23:09:17,596 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:17,598 : INFO : PROGRESS: pass 15, at document #74/74\n",
      "2023-03-12 23:09:17,800 : INFO : optimized alpha [0.048312604, 0.052465007, 0.053476162, 0.04901749, 0.05181454, 0.056750074, 0.040502287]\n",
      "2023-03-12 23:09:17,806 : INFO : topic #6 (0.041): 0.074*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:17,809 : INFO : topic #0 (0.048): 0.015*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"condition\" + 0.006*\"design\" + 0.005*\"medium\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:09:17,811 : INFO : topic #1 (0.052): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"figure\" + 0.005*\"growth\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:17,832 : INFO : topic #2 (0.053): 0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:17,844 : INFO : topic #5 (0.057): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:17,851 : INFO : topic diff=0.032406, rho=0.242536\n",
      "2023-03-12 23:09:18,420 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:18,421 : INFO : PROGRESS: pass 16, at document #74/74\n",
      "2023-03-12 23:09:18,616 : INFO : optimized alpha [0.047706142, 0.051785313, 0.052254118, 0.048188277, 0.05136243, 0.055914603, 0.040005594]\n",
      "2023-03-12 23:09:18,623 : INFO : topic #6 (0.040): 0.074*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:18,625 : INFO : topic #0 (0.048): 0.015*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + 0.006*\"condition\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:18,627 : INFO : topic #1 (0.052): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:18,630 : INFO : topic #2 (0.052): 0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:18,639 : INFO : topic #5 (0.056): 0.009*\"planner\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:18,646 : INFO : topic diff=0.028339, rho=0.235702\n",
      "2023-03-12 23:09:19,376 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:19,377 : INFO : PROGRESS: pass 17, at document #74/74\n",
      "2023-03-12 23:09:19,588 : INFO : optimized alpha [0.047167875, 0.05136905, 0.051178157, 0.04760796, 0.051148996, 0.055361092, 0.039559674]\n",
      "2023-03-12 23:09:19,594 : INFO : topic #6 (0.040): 0.075*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:19,595 : INFO : topic #0 (0.047): 0.014*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.007*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + 0.006*\"condition\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:19,596 : INFO : topic #2 (0.051): 0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:19,599 : INFO : topic #1 (0.051): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"noise\" + 0.005*\"value\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:19,601 : INFO : topic #5 (0.055): 0.010*\"planner\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:19,603 : INFO : topic diff=0.025054, rho=0.229416\n",
      "2023-03-12 23:09:20,161 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:20,162 : INFO : PROGRESS: pass 18, at document #74/74\n",
      "2023-03-12 23:09:20,430 : INFO : optimized alpha [0.046674274, 0.05098787, 0.05020847, 0.04708921, 0.050953187, 0.054874778, 0.039148014]\n",
      "2023-03-12 23:09:20,437 : INFO : topic #6 (0.039): 0.075*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"perception\" + 0.005*\"people\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:20,439 : INFO : topic #0 (0.047): 0.014*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.008*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + 0.006*\"condition\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:20,446 : INFO : topic #4 (0.051): 0.017*\"science\" + 0.017*\"smart\" + 0.012*\"sustainable\" + 0.011*\"design\" + 0.009*\"sustainability\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"big\" + 0.006*\"datadriven\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:20,450 : INFO : topic #1 (0.051): 0.009*\"goal\" + 0.008*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"value\" + 0.005*\"noise\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:20,452 : INFO : topic #5 (0.055): 0.010*\"planner\" + 0.007*\"robot\" + 0.007*\"role\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"different\" + 0.005*\"governance\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:20,453 : INFO : topic diff=0.022346, rho=0.223607\n",
      "2023-03-12 23:09:21,023 : INFO : -7.710 per-word bound, 209.3 perplexity estimate based on a held-out corpus of 74 documents with 153230 words\n",
      "2023-03-12 23:09:21,023 : INFO : PROGRESS: pass 19, at document #74/74\n",
      "2023-03-12 23:09:21,242 : INFO : optimized alpha [0.04621907, 0.050635267, 0.049328994, 0.04661187, 0.050770536, 0.05443121, 0.038766187]\n",
      "2023-03-12 23:09:21,248 : INFO : topic #6 (0.039): 0.076*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"people\" + 0.005*\"perception\" + 0.005*\"help\"\n",
      "2023-03-12 23:09:21,250 : INFO : topic #0 (0.046): 0.014*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.008*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + 0.006*\"condition\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:21,252 : INFO : topic #1 (0.051): 0.009*\"goal\" + 0.009*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"value\" + 0.005*\"noise\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:21,256 : INFO : topic #4 (0.051): 0.017*\"science\" + 0.017*\"smart\" + 0.012*\"sustainable\" + 0.011*\"design\" + 0.009*\"sustainability\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"big\" + 0.006*\"datadriven\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:21,261 : INFO : topic #5 (0.054): 0.010*\"planner\" + 0.007*\"role\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"governance\" + 0.005*\"different\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:21,263 : INFO : topic diff=0.020086, rho=0.218218\n",
      "2023-03-12 23:09:21,282 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=7230, num_topics=7, decay=0.5, chunksize=2000> in 19.36s', 'datetime': '2023-03-12T23:09:21.282168', 'gensim': '4.3.0', 'python': '3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "#run model\n",
    "model = models.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',\n",
    "        eta='auto',\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,\n",
    "        passes=passes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:09:21,317 : INFO : topic #0 (0.046): 0.014*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.008*\"space\" + 0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + 0.006*\"condition\" + 0.005*\"medium\"\n",
      "2023-03-12 23:09:21,323 : INFO : topic #1 (0.051): 0.009*\"goal\" + 0.009*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + 0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"value\" + 0.005*\"noise\" + 0.004*\"human\" + 0.004*\"ai\"\n",
      "2023-03-12 23:09:21,326 : INFO : topic #2 (0.049): 0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + 0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + 0.005*\"proportion\" + 0.005*\"performance\"\n",
      "2023-03-12 23:09:21,328 : INFO : topic #3 (0.047): 0.011*\"learning\" + 0.006*\"paper\" + 0.006*\"clustering\" + 0.005*\"ml\" + 0.005*\"anns\" + 0.005*\"prediction\" + 0.005*\"deep\" + 0.004*\"unsupervised\" + 0.004*\"review\" + 0.004*\"trafc\"\n",
      "2023-03-12 23:09:21,330 : INFO : topic #4 (0.051): 0.017*\"science\" + 0.017*\"smart\" + 0.012*\"sustainable\" + 0.011*\"design\" + 0.009*\"sustainability\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"big\" + 0.006*\"datadriven\" + 0.006*\"field\"\n",
      "2023-03-12 23:09:21,332 : INFO : topic #5 (0.054): 0.010*\"planner\" + 0.007*\"role\" + 0.007*\"robot\" + 0.007*\"service\" + 0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + 0.005*\"governance\" + 0.005*\"different\" + 0.005*\"management\"\n",
      "2023-03-12 23:09:21,336 : INFO : topic #6 (0.039): 0.076*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + 0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"people\" + 0.005*\"perception\" + 0.005*\"help\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.014*\"ai\" + 0.008*\"human\" + 0.008*\"intelligence\" + 0.008*\"space\" + '\n",
      "  '0.007*\"virtual\" + 0.006*\"articial\" + 0.006*\"world\" + 0.006*\"design\" + '\n",
      "  '0.006*\"condition\" + 0.005*\"medium\"'),\n",
      " (1,\n",
      "  '0.009*\"goal\" + 0.009*\"land\" + 0.008*\"space\" + 0.006*\"spatial\" + '\n",
      "  '0.005*\"growth\" + 0.005*\"figure\" + 0.005*\"value\" + 0.005*\"noise\" + '\n",
      "  '0.004*\"human\" + 0.004*\"ai\"'),\n",
      " (2,\n",
      "  '0.013*\"image\" + 0.009*\"value\" + 0.008*\"street\" + 0.008*\"walking\" + '\n",
      "  '0.008*\"algorithm\" + 0.006*\"satisfaction\" + 0.006*\"figure\" + 0.005*\"point\" + '\n",
      "  '0.005*\"proportion\" + 0.005*\"performance\"'),\n",
      " (3,\n",
      "  '0.011*\"learning\" + 0.006*\"paper\" + 0.006*\"clustering\" + 0.005*\"ml\" + '\n",
      "  '0.005*\"anns\" + 0.005*\"prediction\" + 0.005*\"deep\" + 0.004*\"unsupervised\" + '\n",
      "  '0.004*\"review\" + 0.004*\"trafc\"'),\n",
      " (4,\n",
      "  '0.017*\"science\" + 0.017*\"smart\" + 0.012*\"sustainable\" + 0.011*\"design\" + '\n",
      "  '0.009*\"sustainability\" + 0.008*\"urbanism\" + 0.007*\"computer\" + 0.007*\"big\" '\n",
      "  '+ 0.006*\"datadriven\" + 0.006*\"field\"'),\n",
      " (5,\n",
      "  '0.010*\"planner\" + 0.007*\"role\" + 0.007*\"robot\" + 0.007*\"service\" + '\n",
      "  '0.007*\"innovation\" + 0.006*\"automated\" + 0.006*\"automation\" + '\n",
      "  '0.005*\"governance\" + 0.005*\"different\" + 0.005*\"management\"'),\n",
      " (6,\n",
      "  '0.076*\"ai\" + 0.014*\"service\" + 0.009*\"local\" + 0.009*\"government\" + '\n",
      "  '0.008*\"participant\" + 0.007*\"challenge\" + 0.005*\"disaster\" + 0.005*\"people\" '\n",
      "  '+ 0.005*\"perception\" + 0.005*\"help\"')]\n"
     ]
    }
   ],
   "source": [
    "#print it out\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(model.print_topics(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results are getting better with a larger corpus + higher # of passes + smaller number of topics\n",
    "- Try bigrams.\n",
    "- Let's see if scikit-learn does any better, and if not, what we might do to tune our data and parameters to highlight the sorts of patterns that might tell us something *new* about the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional File Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for f in glob.glob(\"Document_*\"):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vt_tm] *",
   "language": "python",
   "name": "conda-env-vt_tm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
